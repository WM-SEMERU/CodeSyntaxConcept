[
  {
    "objectID": "extractor.html",
    "href": "extractor.html",
    "title": "Extractor",
    "section": "",
    "text": "A Libraray to extract logits from the last layer of a hugginface transformer.\n\n\nLogits Extractor\n\nExtracting Tensor Logits from a given Neural Code Model\n\n\nsource\n\ninit_model_args\n\n init_model_args (current_case='c1', returnModel=False)\n\n\nsource\n\n\nc_eleuther\n\n c_eleuther (model_type, returnModel=False, cache_path='../datax/cache')\n\nEleuther and Salesforce and Parrot uses the same importation\n\n\n\nInit Parameters\n\nLoading Models and Testbeds\n\n\n\nExtracting Logits From a Given Model\n\nCreating data tensors\n\n\nLoading Model to Memory\n\n\nExecuting Logits\n\nsource\n\n\ncreate_folder\n\n create_folder (path)\n\n\nsource\n\n\nlogit_extractor\n\n logit_extractor (batch, input, from_index=0)\n\nOutput is the class CausalLMOutputWithPast (https://huggingface.co/transformers/v4.10.1/main_classes/output.html?highlight=causallmoutputwithpast)” logits (torch.FloatTensor of shape (batch_size, sequence_length, config.vocab_size)) – Prediction scores of the language modeling head (scores for each vocabulary token before SoftMax). The expression i.type(torch.LongTensor).to(device) is for casting labels for the loss"
  },
  {
    "objectID": "evaluator.html",
    "href": "evaluator.html",
    "title": "Evaluation Module",
    "section": "",
    "text": "source\n\nEvaluator\n\n Evaluator (checkpoint:str, language)\n\nInitialize self. See help(type(self)) for accurate signature.\n\n\nTesting"
  },
  {
    "objectID": "parser.html",
    "href": "parser.html",
    "title": "Parser",
    "section": "",
    "text": "source\n\nTreeSitterParser\n\n TreeSitterParser (tokenizer:CodeSyntaxConcept.tokenizer.CodeTokenizer)\n\nInitialize self. See help(type(self)) for accurate signature.\n\n\nTesting"
  },
  {
    "objectID": "utils.html",
    "href": "utils.html",
    "title": "Utility Methods",
    "section": "",
    "text": "source\n\ntraverse\n\n traverse (node, results)\n\nTraverse in a recursive way, a tree-sitter node and append results to a list.\n\n\n\n\nType\nDetails\n\n\n\n\nnode\n\ntree-sitter node\n\n\nresults\n\nlist to append results to\n\n\nReturns\nNone\n\n\n\n\n\nsource\n\n\nfind_nodes\n\n find_nodes (node, target_node_type, results)\n\nTraverses the tree and find the specified node type\n\n\n\n\nType\nDetails\n\n\n\n\nnode\n\nTree sitter ast tree\n\n\ntarget_node_type\n\nTarget node type to search in the tree\n\n\nresults\n\nList to append the resutls to\n\n\nReturns\nNone\n\n\n\n\n\nsource\n\n\nfind_parent_nodes\n\n find_parent_nodes (node, results)\n\nTraverses the tree and find the parent nodes\n\n\n\n\nType\nDetails\n\n\n\n\nnode\n\nTree sitter ast tree\n\n\nresults\n\nList to append the resutls to\n\n\nReturns\nNone\n\n\n\n\n\nsource\n\n\nunroll_node_types\n\n unroll_node_types (nested_node_types:dict)\n\n\n\n\n\nType\nDetails\n\n\n\n\nnested_node_types\ndict\nnode_types from tree-sitter\n\n\nReturns\nlist\nlist of node types\n\n\n\n\nsource\n\n\nconvert_to_offset\n\n convert_to_offset (point, lines:list)\n\nConvert the point to an offset\n\n\n\n\nType\nDetails\n\n\n\n\npoint\n\npoint to convert\n\n\nlines\nlist\nlist of lines in the source code\n\n\n\n\nsource\n\n\nget_test_sets\n\n get_test_sets (test_set, language, max_token_number, model_tokenizer,\n                with_ranks=False, num_proc=1)\n\n\nsource\n\n\nget_sub_set_test_set\n\n get_sub_set_test_set (test_set, test_size:int)\n\n\nsource\n\n\nget_random_sub_set_test_set\n\n get_random_sub_set_test_set (test_set, test_size:int)\n\n\nsource\n\n\nbootstrapping\n\n bootstrapping (np_data, np_func, size)\n\nCreate a bootstrap sample given data and a function For instance, a bootstrap sample of means, or mediands. The bootstrap replicates are a long as the original size we can choose any observation more than once (resampling with replacement:np.random.choice)"
  },
  {
    "objectID": "loader.html",
    "href": "loader.html",
    "title": "CLI Module",
    "section": "",
    "text": "source\n\ndownload_grammars\n\n download_grammars (languages)\n\nDownload Tree-sitter grammars\n\n\n\n\n\n\n\n\nDetails\n\n\n\n\nlanguages\nlanguages: Param(“Languages to download”, str, nargs=“+”) = “all”,"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "https://github.com/WM-SEMERU/CodeSyntaxConcept",
    "section": "",
    "text": "This file will become your README and also the index of your documentation."
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "https://github.com/WM-SEMERU/CodeSyntaxConcept",
    "section": "Install",
    "text": "Install\npip install https://github.com/WM_SEMERU/CodeSyntaxConcept\n\nSetup\nStep 1 - create a conda virtual Enviroment:\nconda create -n CodeSyntaxConcept\nconda activate CodeSyntaxConcept\nStep 2 - install nbdev\nconda install -c fastai nbdev\nStep 3 - build the library\nnbdev_export\nStep 4 - install dependencies\npip install .\n\n\nDownloading the grammar\n\nfrom CodeSyntaxConcept.loader import *\n\ndownload_grammars(['python'])\n\n/scratch1/svelascodimate/CodeSyntaxConcept/CodeSyntaxConcept/grammars"
  },
  {
    "objectID": "tokenizer.html",
    "href": "tokenizer.html",
    "title": "Core Module Tokenizer",
    "section": "",
    "text": "source\n\nget_token_type\n\n get_token_type (tok_span:tuple, nodes:list, lines:list)\n\nGet the parent AST type and token AST type of a token.\n\n\n\n\nType\nDetails\n\n\n\n\ntok_span\ntuple\n(start, end) position of a token in tokenizer\n\n\nnodes\nlist\nlist of tree-sitter nodes\n\n\nlines\nlist\nlist of lines in the code\n\n\nReturns\ntuple\n(parent_type, token_type) of the token\n\n\n\n\nsource\n\n\nCodeTokenizer\n\n CodeTokenizer (tokenizer, parser, node_types)\n\nA tokenizer for code, which aligns the tokens with the AST nodes.\n\n\nTesting"
  },
  {
    "objectID": "bootstrapping.html",
    "href": "bootstrapping.html",
    "title": "Statistical Module (Bootstrapping)",
    "section": "",
    "text": "Aggregation Module with Bootstrapping Algorihtms."
  },
  {
    "objectID": "bootstrapping.html#init-parameters",
    "href": "bootstrapping.html#init-parameters",
    "title": "Statistical Module (Bootstrapping)",
    "section": "Init Parameters",
    "text": "Init Parameters"
  },
  {
    "objectID": "bootstrapping.html#logit-uploading-and-flattening",
    "href": "bootstrapping.html#logit-uploading-and-flattening",
    "title": "Statistical Module (Bootstrapping)",
    "section": "Logit Uploading and Flattening",
    "text": "Logit Uploading and Flattening\n\nsource\n\nactual_logit\n\n actual_logit (logit_vocab_sample_tensor, tokenized_prompt, tokenizer_fn)\n\nCompute actual logits for a sample\n\nsource\n\n\nmin_max_logits\n\n min_max_logits (logit_vocab_sample_tensor, tokenizer_fn)\n\nCompute min_max for a sample\n\nsource\n\n\ntopk_tuple\n\n topk_tuple (logit_vocab_tensor, largest, tokenizer_fn)\n\nRun topk for a token"
  },
  {
    "objectID": "bootstrapping.html#loss-retrieval",
    "href": "bootstrapping.html#loss-retrieval",
    "title": "Statistical Module (Bootstrapping)",
    "section": "Loss Retrieval",
    "text": "Loss Retrieval\n\nsource\n\nbatching_loss\n\n batching_loss (size)"
  },
  {
    "objectID": "bootstrapping.html#combining-all-datasets",
    "href": "bootstrapping.html#combining-all-datasets",
    "title": "Statistical Module (Bootstrapping)",
    "section": "Combining all datasets",
    "text": "Combining all datasets"
  },
  {
    "objectID": "bootstrapping.html#median-bootstrapping",
    "href": "bootstrapping.html#median-bootstrapping",
    "title": "Statistical Module (Bootstrapping)",
    "section": "Median Bootstrapping",
    "text": "Median Bootstrapping\n\nsource\n\nbootstrapping\n\n bootstrapping (np_data, np_func, size)\n\nCreate a bootstrap sample given data and a function For instance, a bootstrap sample of means, or mediands. The bootstrap replicates are a long as the original size we can choose any observation more than once (resampling with replacement:np.random.choice)\n\nsource\n\n\nconfidence_intervals_v2\n\n confidence_intervals_v2 (data, confidence=0.95)\n\n\nsource\n\n\nstandard_error\n\n standard_error (bootstrapped_data)"
  },
  {
    "objectID": "bootstrapping.html#local-combination",
    "href": "bootstrapping.html#local-combination",
    "title": "Statistical Module (Bootstrapping)",
    "section": "Local Combination",
    "text": "Local Combination"
  }
]