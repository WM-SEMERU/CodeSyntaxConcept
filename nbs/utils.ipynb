{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import CodeSyntaxConcept\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# From: https://github.com/github/CodeSearchNet/tree/master/function_parser\n",
    "def traverse(\n",
    "    node,       # tree-sitter node\n",
    "    results,    # list to append results to\n",
    ") -> None:\n",
    "    \"\"\"Traverse in a recursive way, a tree-sitter node and append results to a list.\"\"\"\n",
    "    if node.type == 'string':\n",
    "        results.append(node)\n",
    "        return\n",
    "    for n in node.children:\n",
    "        traverse(n, results)\n",
    "    if not node.children:\n",
    "        results.append(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "def find_nodes(\n",
    "    node,               #Tree sitter ast tree\n",
    "    target_node_type,   #Target node type to search in the tree\n",
    "    results,            #List to append the resutls to\n",
    ") -> None: \n",
    "    \"\"\"Traverses the tree and find the specified node type\"\"\"\n",
    "    if node.type == target_node_type:\n",
    "        results.append(node)\n",
    "        return\n",
    "    for n in node.children:\n",
    "        find_nodes(n, target_node_type, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "def find_parent_nodes(\n",
    "    node,               #Tree sitter ast tree\n",
    "    results,            #List to append the resutls to\n",
    ") -> None: \n",
    "    \"\"\"Traverses the tree and find the parent nodes\"\"\"\n",
    "    if node.children:\n",
    "        results.append(node)\n",
    "        for n in node.children:\n",
    "            find_parent_nodes(n, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def unroll_node_types(\n",
    "    nested_node_types: dict  # node_types from tree-sitter\n",
    ") -> list: # list of node types\n",
    "    def iterate_and_unroll_dict(nested_node_types: dict, all_node_types: set):\n",
    "        for key, value in nested_node_types.items():\n",
    "            if key == 'type' and type(value) == str:\n",
    "                all_node_types.add(value)\n",
    "            if type(value) == dict:\n",
    "                iterate_and_unroll_dict(value, all_node_types)\n",
    "            if type(value) == list:\n",
    "                for element in value:\n",
    "                    iterate_and_unroll_dict(element, all_node_types) \n",
    "    all_node_types = set()\n",
    "    for dictionary in nested_node_types:\n",
    "        iterate_and_unroll_dict(dictionary, all_node_types)\n",
    "    all_node_types.add('ERROR')\n",
    "    return list(all_node_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def convert_to_offset(\n",
    "    point,              #point to convert\n",
    "    lines: list         #list of lines in the source code\n",
    "    ):\n",
    "        \"\"\"Convert the point to an offset\"\"\"\n",
    "        row, column = point\n",
    "        chars_in_rows = sum(map(len, lines[:row])) + row\n",
    "        chars_in_columns = len(lines[row][:column])\n",
    "        offset = chars_in_rows + chars_in_columns\n",
    "        return offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_test_sets(test_set, language, max_token_number, model_tokenizer, with_ranks=False, num_proc=1):\n",
    "    subset = test_set.filter(lambda sample: True if sample['language']== language \n",
    "            and len(sample['func_code_tokens']) < max_token_number\n",
    "            and len(model_tokenizer.tokenizer(sample['whole_func_string'])['input_ids']) <= max_token_number\n",
    "            else False, num_proc=num_proc)\n",
    "    return subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_sub_set_test_set(test_set, test_size:int):\n",
    "    sub_samples = []\n",
    "    for sample in test_set:\n",
    "        sub_samples.append(sample)\n",
    "        if len(sub_samples)>=test_size:\n",
    "            break\n",
    "    return sub_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_random_sub_set_test_set(test_set, test_size:int):\n",
    "    sub_samples = []\n",
    "    while len(sub_samples)<test_size:\n",
    "        random_index = random.randrange(0,len(test_set))\n",
    "        sub_samples.append(test_set[random_index])\n",
    "    return sub_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def bootstrapping( np_data, np_func, size ):\n",
    "    \"\"\"Create a bootstrap sample given data and a function\n",
    "    For instance, a bootstrap sample of means, or mediands. \n",
    "    The bootstrap replicates are a long as the original size\n",
    "    we can choose any observation more than once (resampling with replacement:np.random.choice)\n",
    "    \"\"\"\n",
    "    \n",
    "    #Cleaning NaNs\n",
    "    #np_data_clean = np_data[ np.logical_not( np.isnan(np_data) ) ] \n",
    "    \n",
    "    #The size of the bootstrap replicate is as big as size\n",
    "    #Creating the boostrap replicates as long as the orignal data size\n",
    "    #This strategy might work as imputation \n",
    "    bootstrap_repl = [ np_func( np.random.choice( np_data, size=len(np_data) ) ) for i in range( size ) ]\n",
    "    \n",
    "    #logging.info(\"Covariate: \" + cov) #Empirical Mean\n",
    "    #logging.info(\"Empirical Mean: \" + str(np.mean(np_data_clean))) #Empirical Mean\n",
    "    #logging.info(\"Bootstrapped Mean: \" + str( np.mean(bootstrap_repl) ) ) #Bootstrapped Mean\n",
    "    \n",
    "    return np.array( bootstrap_repl )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "49b68b9c38357b2088122ab1ddc655dffe83bd2309642e44c64d6d94a1d66aec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
