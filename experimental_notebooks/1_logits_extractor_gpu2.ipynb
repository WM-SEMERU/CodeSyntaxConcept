{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/66116155/how-to-tell-pytorch-which-cuda-version-to-take\n",
    "# https://github.com/pytorch/pytorch/issues/75992\n",
    "\n",
    "# Previous Versions of Pytorch avaiable here: https://pytorch.org/get-started/previous-versions/\n",
    "#! pip install --upgrade torch==1.11.0 torchvision==0.12.0 torchaudio==0.11.0\n",
    "#! pip install --upgrade torch==1.12.0 torchvision==0.13.0 torchaudio==0.12.0\n",
    "#! pip install --upgrade torch==1.12.1 --extra-index-url https://download.pytorch.org/whl/cu113 #<--This version works for CUDA 11.4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install --upgrade torch==1.12.1 --extra-index-url https://download.pytorch.org/whl/cu113 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from statistics import NormalDist\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.1+cu113'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__\n",
    "#'1.12.0+cu111'\n",
    "#'1.9.0+cu111' This is the version by default\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#physical_devices = tf.config.list_physical_devices('CPU')\n",
    "physical_devices = tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)\n",
    "physical_devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device\n",
    "device = 'cuda'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "x = torch.rand(5, 3, \n",
    "               device=device#'cpu'\n",
    "               )\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deleting tensor to free memory\n",
    "del x\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! conda install pytorch torchvision torchaudio cudatoolkit=10.1 -c pytorch\n",
    "#! pip3 install torch==1.7.0 torchvision==0.8.1 -f https://download.pytorch.org/whl/cu101/torch_stable.html\n",
    "#! pip install tensorflow\n",
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logits Extractor\n",
    ">\n",
    "> Extracting Tensor Logits from a given Neural Code Model @xxxxxp\n",
    ">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Available Datasets\n",
    "\n",
    "def params(): \n",
    "    \n",
    "    code_models = {\n",
    "        'Case1':('EleutherAI/gpt-neo-125M','codesearch_tesbed_EleutherAI-gpt-neo-125M_10000.csv','EleutherAI-gpt-neo-125M_10000_','callbacks-EleutherAI-gpt-neo-125M_10000_'),\n",
    "        'Case2':('EleutherAI/gpt-neo-2.7B','codesearch_tesbed_EleutherAI-gpt-neo-2.7B_10000.csv','EleutherAI-gpt-neo-2.7B_10000_','callbacks-EleutherAI-gpt-neo-2.7B_10000_'),    \n",
    "        'Case3':('EleutherAI/gpt-neo-1.3B','codesearch_tesbed_EleutherAI-gpt-neo-1.3B_10000.csv','EleutherAI-gpt-neo-1.3B_10000_','callbacks-EleutherAI-gpt-neo-1.3B_10000_'),\n",
    "        'Case4':('microsoft/CodeGPT-small-py','codesearch_tesbed_microsoft-CodeGPT-small-py_1024_10000.csv','CodeGPT-small-py_10000_','callbacks-CodeGPT-small-py_10000_'),\n",
    "        'Case5':('microsoft/CodeGPT-small-py-adaptedGPT2','codesearch_tesbed_microsoft-CodeGPT-small-py-adaptedGPT2_1024_10000.csv','CodeGPT-small-py-adaptedGPT2_10000_','callbacks-CodeGPT-small-py-adaptedGPT2_10000_'),\n",
    "        'Case6':('Salesforce/codegen-2B-multi','codesearch_tesbed_Salesforce-codegen-2B-multi_1024_10000.csv','Salesforce-codegen-2B-multi_1024_10000_','callbacks-Salesforce-codegen-2B-multi_1024_10000_'),\n",
    "        'Case7':('eleutherai/gpt-neox-20b','codesearch_tesbed_EleutherAI-gpt-neox-20b_1024_10000.csv','EleutherAI-gpt-neoX-20b_1024_10000_','callbacks-EleutherAI-gpt-neoX_1024_10000_')\n",
    "    }\n",
    "    current_case = 'Case7' #<----[Hyper]\n",
    "    \n",
    "    #print(code_models[current_case][1])\n",
    "    \n",
    "    return {\n",
    "            'big_table_path' : '../data/concept_tables/' + code_models[current_case][1],\n",
    "            'hf_model' :  code_models[current_case][0],\n",
    "            'model_name': code_models[current_case][2],\n",
    "            'callbacks' : '../datax/' + code_models[current_case][3],\n",
    "            'wpe':2048#1024  #<----[Hyper]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/concept_tables/codesearch_tesbed_EleutherAI-gpt-neox-20b_1024_10000.csv'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pwd\n",
    "parameters = params()\n",
    "parameters['big_table_path']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pd = pd.read_csv( \n",
    "                      parameters['big_table_path'] , \n",
    "                      index_col=0\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_total_input_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>247.111600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>191.178002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>34.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>111.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>184.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>321.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1024.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       model_total_input_ids\n",
       "count           10000.000000\n",
       "mean              247.111600\n",
       "std               191.178002\n",
       "min                34.000000\n",
       "25%               111.000000\n",
       "50%               184.000000\n",
       "75%               321.000000\n",
       "max              1024.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pd.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>whole_func_string</th>\n",
       "      <th>ast_concepts</th>\n",
       "      <th>model_tokenizer_concepts</th>\n",
       "      <th>model_input_ids</th>\n",
       "      <th>model_total_input_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>def auth(self, skypeToken):\\n        \"\"\"\\n    ...</td>\n",
       "      <td>[('def', 'def', 'function_definition'), ('auth...</td>\n",
       "      <td>[(1545, 'def', 'function_definition'), (24896,...</td>\n",
       "      <td>[1545, 24896, 9, 1286, 13, 1629, 1692, 11200, ...</td>\n",
       "      <td>711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>def template_tag(library, name):\\n    \"\"\"\\n   ...</td>\n",
       "      <td>[('def', 'def', 'function_definition'), ('temp...</td>\n",
       "      <td>[(1545, 'def', 'function_definition'), (7646, ...</td>\n",
       "      <td>[1545, 7646, 64, 7784, 9, 17921, 13, 1416, 226...</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>def _search_tree_backwards(self, template, par...</td>\n",
       "      <td>[('def', 'def', 'function_definition'), ('_sea...</td>\n",
       "      <td>[(1545, 'def', 'function_definition'), (795, '...</td>\n",
       "      <td>[1545, 795, 8716, 64, 12588, 64, 2135, 4515, 9...</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>def get_upcoming_events(self):\\n        \"\"\"\\n ...</td>\n",
       "      <td>[('def', 'def', 'function_definition'), ('get_...</td>\n",
       "      <td>[(1545, 'def', 'function_definition'), (755, '...</td>\n",
       "      <td>[1545, 755, 64, 484, 4202, 64, 20969, 9, 1286,...</td>\n",
       "      <td>274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>def  get_markup( self, tag_name ):\\n        \"\"...</td>\n",
       "      <td>[('def', 'def', 'function_definition'), ('get_...</td>\n",
       "      <td>[(1545, 'def', 'function_definition'), (50276,...</td>\n",
       "      <td>[1545, 50276, 788, 64, 4698, 484, 9, 1881, 13,...</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   whole_func_string  \\\n",
       "0  def auth(self, skypeToken):\\n        \"\"\"\\n    ...   \n",
       "1  def template_tag(library, name):\\n    \"\"\"\\n   ...   \n",
       "2  def _search_tree_backwards(self, template, par...   \n",
       "3  def get_upcoming_events(self):\\n        \"\"\"\\n ...   \n",
       "4  def  get_markup( self, tag_name ):\\n        \"\"...   \n",
       "\n",
       "                                        ast_concepts  \\\n",
       "0  [('def', 'def', 'function_definition'), ('auth...   \n",
       "1  [('def', 'def', 'function_definition'), ('temp...   \n",
       "2  [('def', 'def', 'function_definition'), ('_sea...   \n",
       "3  [('def', 'def', 'function_definition'), ('get_...   \n",
       "4  [('def', 'def', 'function_definition'), ('get_...   \n",
       "\n",
       "                            model_tokenizer_concepts  \\\n",
       "0  [(1545, 'def', 'function_definition'), (24896,...   \n",
       "1  [(1545, 'def', 'function_definition'), (7646, ...   \n",
       "2  [(1545, 'def', 'function_definition'), (795, '...   \n",
       "3  [(1545, 'def', 'function_definition'), (755, '...   \n",
       "4  [(1545, 'def', 'function_definition'), (50276,...   \n",
       "\n",
       "                                     model_input_ids  model_total_input_ids  \n",
       "0  [1545, 24896, 9, 1286, 13, 1629, 1692, 11200, ...                    711  \n",
       "1  [1545, 7646, 64, 7784, 9, 17921, 13, 1416, 226...                    223  \n",
       "2  [1545, 795, 8716, 64, 12588, 64, 2135, 4515, 9...                    181  \n",
       "3  [1545, 755, 64, 484, 4202, 64, 20969, 9, 1286,...                    274  \n",
       "4  [1545, 50276, 788, 64, 4698, 484, 9, 1881, 13,...                     63  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pd.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[(\\'def\\', \\'def\\', \\'function_definition\\'), (\\'set_server_admin_password\\', \\'identifier\\', \\'function_definition\\'), (\\'(\\', \\'(\\', \\'parameters\\'), (\\'self\\', \\'identifier\\', \\'parameters\\'), (\\',\\', \\',\\', \\'parameters\\'), (\\'server_name\\', \\'identifier\\', \\'parameters\\'), (\\',\\', \\',\\', \\'parameters\\'), (\\'admin_password\\', \\'identifier\\', \\'parameters\\'), (\\')\\', \\')\\', \\'parameters\\'), (\\':\\', \\':\\', \\'function_definition\\'), (\"\\'\\'\\'\\\\n        Reset the administrator password for a server.\\\\n\\\\n        server_name:\\\\n            Name of the server to change the password.\\\\n        admin_password:\\\\n            The new administrator password for the server.\\\\n        \\'\\'\\'\", \\'string\\', \\'expression_statement\\'), (\\'_validate_not_none\\', \\'identifier\\', \\'call\\'), (\\'(\\', \\'(\\', \\'argument_list\\'), (\"\\'server_name\\'\", \\'string\\', \\'argument_list\\'), (\\',\\', \\',\\', \\'argument_list\\'), (\\'server_name\\', \\'identifier\\', \\'argument_list\\'), (\\')\\', \\')\\', \\'argument_list\\'), (\\'_validate_not_none\\', \\'identifier\\', \\'call\\'), (\\'(\\', \\'(\\', \\'argument_list\\'), (\"\\'admin_password\\'\", \\'string\\', \\'argument_list\\'), (\\',\\', \\',\\', \\'argument_list\\'), (\\'admin_password\\', \\'identifier\\', \\'argument_list\\'), (\\')\\', \\')\\', \\'argument_list\\'), (\\'return\\', \\'return\\', \\'return_statement\\'), (\\'self\\', \\'identifier\\', \\'attribute\\'), (\\'.\\', \\'.\\', \\'attribute\\'), (\\'_perform_post\\', \\'identifier\\', \\'attribute\\'), (\\'(\\', \\'(\\', \\'argument_list\\'), (\\'self\\', \\'identifier\\', \\'attribute\\'), (\\'.\\', \\'.\\', \\'attribute\\'), (\\'_get_servers_path\\', \\'identifier\\', \\'attribute\\'), (\\'(\\', \\'(\\', \\'argument_list\\'), (\\'server_name\\', \\'identifier\\', \\'argument_list\\'), (\\')\\', \\')\\', \\'argument_list\\'), (\\'+\\', \\'+\\', \\'binary_operator\\'), (\"\\'?op=ResetPassword\\'\", \\'string\\', \\'binary_operator\\'), (\\',\\', \\',\\', \\'argument_list\\'), (\\'_SqlManagementXmlSerializer\\', \\'identifier\\', \\'attribute\\'), (\\'.\\', \\'.\\', \\'attribute\\'), (\\'set_server_admin_password_to_xml\\', \\'identifier\\', \\'attribute\\'), (\\'(\\', \\'(\\', \\'argument_list\\'), (\\'admin_password\\', \\'identifier\\', \\'argument_list\\'), (\\')\\', \\')\\', \\'argument_list\\'), (\\')\\', \\')\\', \\'argument_list\\')]'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pd.iat[243, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer = AutoTokenizer.from_pretrained(\"Salesforce/codegen-2B-mono\")\n",
    "#tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-j-6B\")\n",
    "#generator = pipeline('text-generation', model='EleutherAI/gpt-neo-1.3B')\n",
    "#model = AutoModelForCausalLM.from_pretrained(\"EleutherAI/gpt-j-6B\")\n",
    "#pip list\n",
    "#! pip install git+https://github.com/huggingface/transfomers.git\n",
    "\n",
    "def testing_1():\n",
    "    #! pip install transformers\n",
    "    from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "    from transformers import pipeline\n",
    "    # This is for 'EleutherAI/gpt-neo-125M'\n",
    "    tokenizer = AutoTokenizer.from_pretrained(parameters['hf_model'])\n",
    "    generator = pipeline(\n",
    "        'text-generation', \n",
    "        model= parameters['hf_model'] )\n",
    "    \n",
    "    #TEST: Example 1: generation\n",
    "    generator(\n",
    "        \"EleutherAI has\", \n",
    "        do_sample=True, \n",
    "        max_new_tokens=20, \n",
    "        pad_token_id = tokenizer.eos_token_id\n",
    "        )\n",
    "    \n",
    "    #TEST: Example 2: generation\n",
    "\n",
    "    generator( \n",
    "        data_pd.whole_func_string.values[0][:100], #<-- Code data\n",
    "        do_sample=True, \n",
    "        max_new_tokens=20,\n",
    "        pad_token_id = tokenizer.eos_token_id \n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Logits From a Given Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code works for GPT-Neo\n",
    "from transformers import GPTNeoForCausalLM, GPT2Tokenizer\n",
    "model = GPTNeoForCausalLM.from_pretrained( parameters['hf_model'], ignore_mismatched_sizes=True )\n",
    "tokenizer = GPT2Tokenizer.from_pretrained( parameters['hf_model'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eleutherai/gpt-neox-20b'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters['hf_model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4844e38ea6c24ab0b87011658e85e44b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/46 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#This code works for CodeGPT, Salesforce and GPTNeoX\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(parameters['hf_model'])\n",
    "model = AutoModelForCausalLM.from_pretrained(parameters['hf_model'],device_map=\"auto\", torch_dtype=torch.float16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to( device )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer.get_vocab()\n",
    "#len( tokenizer.get_vocab() ) #todo an assert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prompts = data_pd.whole_func_string.values[:2]\n",
    "prompts = data_pd.whole_func_string.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making space for the tensors\n",
    "#input_ids_list = tokenizer.batch_encode_plus( prompts ) #<-- Do not return as a Tensor\n",
    "input_ids_list = tokenizer.batch_encode_plus( list(prompts) ) #<-- Do not return as a Tensor [cast to list]\n",
    "#input_ids_list = tokenizer.batch_encode_plus( prompts , return_tensors=\"pt\") #<-- \"pt\" returns as a Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Casting Integers to Tensor Integers. Make sure the tesor is created in a device\n",
    "#We ignored the parameter attention_mask since we are not using masking here [https://huggingface.co/transformers/v4.10.1/glossary.html#attention-mask]\n",
    "\n",
    "#input_ids_list = [torch.Tensor( np.array( input_ids ) ) for input_ids in input_ids_list.input_ids if len(input_ids) <= 2048]\n",
    "#input_ids_list = [ input_ids for input_ids in input_ids_list.input_ids if len(input_ids) <= 2048]\n",
    "input_ids_list = [torch.tensor(  input_ids, dtype = torch.int, device=device ) for input_ids in input_ids_list.input_ids if len(input_ids) <= 2048]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1545, 24896,     9,  1286,    13,  1629,  1692, 11200,  2262,   187,\n",
       "        50270, 32488,   187, 50270,  6825,   247,   747, 12960, 10669,   970,\n",
       "          247,  1655, 45385, 10669,    15,   535, 50270, 16523,    27,   187,\n",
       "        50266,  3319,  1692, 11200,   313,  1344,  2262,  5368, 45385, 10669,\n",
       "          535, 50270, 34551,    27,   187, 50266,     9,  1344,    13, 36743,\n",
       "           15, 36377,    13,  1213,    13, 45385, 36997,    10, 31343,    27,\n",
       "        12960, 10669,    13,  2330,   866, 11028,   604,  1929,    13,   187,\n",
       "        50254, 50254, 50262,  6870,   272, 21229,  3167,  1590,    13, 21229,\n",
       "          604,  2530,   535, 50270, 21328,  3013,    27,   187, 50266,    15,\n",
       "        15992,  1692, 15714,  5330,    27,   604,   253, 16164,  2748,   310,\n",
       "        10945,   187, 50266,    15, 15992,  1692, 22444,  5330,    27,   604,\n",
       "          253, 16164,   830,   476,   626,   320, 11742,   187, 50270, 32488,\n",
       "          187, 50270, 13763,   426,   866, 11028,   426, 21229,   426,  8256,\n",
       "          187, 50270,  4856,    84, 15310,   426, 45385, 13457,    15, 11252,\n",
       "           64, 24691,  5648, 13792,   187, 50270,  6050,   417, 10669,    27,\n",
       "          187, 50266,  1704,    84,   426,   540,     9,  2606,    15,  2606,\n",
       "         6649,   187, 50266, 13362,   426,  1881,    15,   788, 13815,  9726,\n",
       "        16850,     9,  1344,     9,  1704,    84,  1228,   187, 50266, 27641,\n",
       "          426, 17579, 18703,  1898,  4814,  1381,   346,  1212,  2618,    30,\n",
       "          983,  4856,    84,    33,   983,    79,   983,   737,    15,   681,\n",
       "           28,   673, 11787,    17,  4718,  5569,  1898,  4814,  9604, 11787,\n",
       "           18,    94,  3446,  8124,     9,  1704,    84,    13, 13283,   582,\n",
       "          187, 50255,     3, 38305,  1381,   346,  3319,  3170,   292,  5097,\n",
       "          568,   559,  1629,  1692, 11200,    13,   346, 38066,  9677,  1381,\n",
       "          346, 41794,  1909, 20611,   986,   187, 50266, 42882, 23450,   426,\n",
       "         1881,    15, 22670,  1587, 15743,   995, 36028,    17,  9228, 15987,\n",
       "           16,  5288,    16,   423, 10801,  3446,  8124,     9,  4856,    84,\n",
       "        15310,   582, 11646, 10190,  1518,    13,   848,    13, 21566,   582,\n",
       "          187, 50254, 50265, 27641,    30, 27641,    13, 14113,    30,  9819,\n",
       "        42882, 30880,  1381,   346, 28172,  7547,   187, 50266,  1747, 11200,\n",
       "        22893,   426, 21229, 23450,    15, 27641,    15,   788,  1587,  4531,\n",
       "           14, 46563, 11200,  2807,   187, 50266,  9450, 22893,   426, 21229,\n",
       "        23450,    15, 27641,    15,   788,  1587, 11930,  2807,   187, 50266,\n",
       "          338,  1150, 22893,    27,   187, 50262,  9450, 49563,   426,   294,\n",
       "           15,  8716,     9,    83, 31770,  3614,  1358,  5180,    16, 20871,\n",
       "           16,    87,    18,  1933, 15987,    16,  5288,    16,   423, 10801,\n",
       "            9,  5624,     6,    24,    35,    60,    66,    14,    91,    17,\n",
       "           14,    26, 23671, 20871,     6,    24,    37,  1228, 46607,  1150,\n",
       "        22893,   481, 12896,  1082,   187, 50262,   338,  1150, 49563,    60,\n",
       "           19,  5218,   187, 50258, 42882,   426, 45385, 36997,     9,  1286,\n",
       "           15, 22670,    13,  1150, 49563,    60,    19,  1570, 13481, 22219,\n",
       "           24,    35,   995, 36028,  6788, 13481, 22219,    24,    37,   995,\n",
       "          346, 13272,  1228,   187, 50262,   338,   417,  1150, 49563,    60,\n",
       "           17,    62,  2295, 13818,  5943, 15310,    27,   187, 50258,     4,\n",
       "        45385,   310, 10568,   253,   897,   273,   247,  1027,  3167,  1590,\n",
       "           15,   187, 50258,  4856,    84, 15310,   426,  1150, 22893,    15,\n",
       "         2967,  4403, 28229,   995,   577,   604,  1150, 49563,    60,    19,\n",
       "           62,  2010,   495,  6904,    17,    62,   187, 50258,     4,  5037,\n",
       "          626,  2997,   253, 10669,   604,  1246,    13,   359,   878,   281,\n",
       "          294,    14, 15905,   806,    15,   187, 50258, 25674,   187, 50266,\n",
       "          338,   810, 11200, 22893,    27,   187, 50262, 13763,   426,   294,\n",
       "           15,  8716,     9,    83, 31770, 46818, 11200, 20879,    66,    14,\n",
       "           91,    17,    14,    26,    61, 34554,    30,    62, 15020,   995,\n",
       "          810, 11200, 22893,    13,   294,    15,    42,   481,  4399,     9,\n",
       "           18,    10,   187, 50262,  1747,  1672,  5378,    90,   426,   294,\n",
       "           15,  8716,     9,    83,     3,   911, 31659, 36864,    69, 15020,\n",
       "          995,   810, 11200, 22893,   481,  4399,     9,    18,    10,   187,\n",
       "        50262,  4347, 11028,   426, 36743,    15,  4064, 32549,     9,   565,\n",
       "            9,  1747,  1672,  5378,    90,  1228,   187, 50262,  1747,  7689,\n",
       "        21008,   426,   294,    15,  8716,     9,    83,     3, 42882,  2618,\n",
       "           30,  7506,    60,    66,    14,    91,    17,    14,    26, 23671,\n",
       "        20871,  2311,   995,   810, 11200, 22893,    10,   187, 50262,   338,\n",
       "          810,  7689, 21008,    27,   187, 50258, 42882,   426, 45385, 36997,\n",
       "            9,  1286,    15, 22670,    13,   810,  7689, 21008,    15,  4399,\n",
       "            9,    18,  1228,   187, 50266,   338,   417, 21229,   285, 21229,\n",
       "        23450,    15,  8581,    64,  3211,  2295,  1052,   285, 21229, 23450,\n",
       "           15,  8456, 14850,   187, 50262,     4,  7890,   253,   954,  3332,\n",
       "        21229,  7117,   275,   253, 13922,  2380,    15,   187, 50262, 42882,\n",
       "          426, 45385, 36997,     9,  1286,    15, 22670,    13, 21229, 23450,\n",
       "           15,  8456, 43144,    17,  7082,     3,   301, 45564,   187, 50270,\n",
       "         2309, 10669,    13,   866, 11028,    13, 13818,  5943, 15310,    13,\n",
       "        21229], device='cuda:0', dtype=torch.int32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 10000\n"
     ]
    }
   ],
   "source": [
    "#It should be same size\n",
    "print(len(input_ids_list),len(prompts))\n",
    "assert len(input_ids_list) == len(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[1545, 24896, 9, 1286, 13, 1629, 1692, 11200, 2262, 187, 50270, 32488, 187, 50270, 6825, 247, 747, 12960, 10669, 970, 247, 1655, 45385, 10669, 15, 535, 50270, 16523, 27, 187, 50266, 3319, 1692, 11200, 313, 1344, 2262, 5368, 45385, 10669, 535, 50270, 34551, 27, 187, 50266, 9, 1344, 13, 36743, 15, 36377, 13, 1213, 13, 45385, 36997, 10, 31343, 27, 12960, 10669, 13, 2330, 866, 11028, 604, 1929, 13, 187, 50254, 50254, 50262, 6870, 272, 21229, 3167, 1590, 13, 21229, 604, 2530, 535, 50270, 21328, 3013, 27, 187, 50266, 15, 15992, 1692, 15714, 5330, 27, 604, 253, 16164, 2748, 310, 10945, 187, 50266, 15, 15992, 1692, 22444, 5330, 27, 604, 253, 16164, 830, 476, 626, 320, 11742, 187, 50270, 32488, 187, 50270, 13763, 426, 866, 11028, 426, 21229, 426, 8256, 187, 50270, 4856, 84, 15310, 426, 45385, 13457, 15, 11252, 64, 24691, 5648, 13792, 187, 50270, 6050, 417, 10669, 27, 187, 50266, 1704, 84, 426, 540, 9, 2606, 15, 2606, 6649, 187, 50266, 13362, 426, 1881, 15, 788, 13815, 9726, 16850, 9, 1344, 9, 1704, 84, 1228, 187, 50266, 27641, 426, 17579, 18703, 1898, 4814, 1381, 346, 1212, 2618, 30, 983, 4856, 84, 33, 983, 79, 983, 737, 15, 681, 28, 673, 11787, 17, 4718, 5569, 1898, 4814, 9604, 11787, 18, 94, 3446, 8124, 9, 1704, 84, 13, 13283, 582, 187, 50255, 3, 38305, 1381, 346, 3319, 3170, 292, 5097, 568, 559, 1629, 1692, 11200, 13, 346, 38066, 9677, 1381, 346, 41794, 1909, 20611, 986, 187, 50266, 42882, 23450, 426, 1881, 15, 22670, 1587, 15743, 995, 36028, 17, 9228, 15987, 16, 5288, 16, 423, 10801, 3446, 8124, 9, 4856, 84, 15310, 582, 11646, 10190, 1518, 13, 848, 13, 21566, 582, 187, 50254, 50265, 27641, 30, 27641, 13, 14113, 30, 9819, 42882, 30880, 1381, 346, 28172, 7547, 187, 50266, 1747, 11200, 22893, 426, 21229, 23450, 15, 27641, 15, 788, 1587, 4531, 14, 46563, 11200, 2807, 187, 50266, 9450, 22893, 426, 21229, 23450, 15, 27641, 15, 788, 1587, 11930, 2807, 187, 50266, 338, 1150, 22893, 27, 187, 50262, 9450, 49563, 426, 294, 15, 8716, 9, 83, 31770, 3614, 1358, 5180, 16, 20871, 16, 87, 18, 1933, 15987, 16, 5288, 16, 423, 10801, 9, 5624, 6, 24, 35, 60, 66, 14, 91, 17, 14, 26, 23671, 20871, 6, 24, 37, 1228, 46607, 1150, 22893, 481, 12896, 1082, 187, 50262, 338, 1150, 49563, 60, 19, 5218, 187, 50258, 42882, 426, 45385, 36997, 9, 1286, 15, 22670, 13, 1150, 49563, 60, 19, 1570, 13481, 22219, 24, 35, 995, 36028, 6788, 13481, 22219, 24, 37, 995, 346, 13272, 1228, 187, 50262, 338, 417, 1150, 49563, 60, 17, 62, 2295, 13818, 5943, 15310, 27, 187, 50258, 4, 45385, 310, 10568, 253, 897, 273, 247, 1027, 3167, 1590, 15, 187, 50258, 4856, 84, 15310, 426, 1150, 22893, 15, 2967, 4403, 28229, 995, 577, 604, 1150, 49563, 60, 19, 62, 2010, 495, 6904, 17, 62, 187, 50258, 4, 5037, 626, 2997, 253, 10669, 604, 1246, 13, 359, 878, 281, 294, 14, 15905, 806, 15, 187, 50258, 25674, 187, 50266, 338, 810, 11200, 22893, 27, 187, 50262, 13763, 426, 294, 15, 8716, 9, 83, 31770, 46818, 11200, 20879, 66, 14, 91, 17, 14, 26, 61, 34554, 30, 62, 15020, 995, 810, 11200, 22893, 13, 294, 15, 42, 481, 4399, 9, 18, 10, 187, 50262, 1747, 1672, 5378, 90, 426, 294, 15, 8716, 9, 83, 3, 911, 31659, 36864, 69, 15020, 995, 810, 11200, 22893, 481, 4399, 9, 18, 10, 187, 50262, 4347, 11028, 426, 36743, 15, 4064, 32549, 9, 565, 9, 1747, 1672, 5378, 90, 1228, 187, 50262, 1747, 7689, 21008, 426, 294, 15, 8716, 9, 83, 3, 42882, 2618, 30, 7506, 60, 66, 14, 91, 17, 14, 26, 23671, 20871, 2311, 995, 810, 11200, 22893, 10, 187, 50262, 338, 810, 7689, 21008, 27, 187, 50258, 42882, 426, 45385, 36997, 9, 1286, 15, 22670, 13, 810, 7689, 21008, 15, 4399, 9, 18, 1228, 187, 50266, 338, 417, 21229, 285, 21229, 23450, 15, 8581, 64, 3211, 2295, 1052, 285, 21229, 23450, 15, 8456, 14850, 187, 50262, 4, 7890, 253, 954, 3332, 21229, 7117, 275, 253, 13922, 2380, 15, 187, 50262, 42882, 426, 45385, 36997, 9, 1286, 15, 22670, 13, 21229, 23450, 15, 8456, 43144, 17, 7082, 3, 301, 45564, 187, 50270, 2309, 10669, 13, 866, 11028, 13, 13818, 5943, 15310, 13, 21229]'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pd.model_input_ids.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1545, 24896,     9,  1286,    13,  1629,  1692, 11200,  2262,   187,\n",
       "        50270, 32488,   187, 50270,  6825,   247,   747, 12960, 10669,   970,\n",
       "          247,  1655, 45385, 10669,    15,   535, 50270, 16523,    27,   187,\n",
       "        50266,  3319,  1692, 11200,   313,  1344,  2262,  5368, 45385, 10669,\n",
       "          535, 50270, 34551,    27,   187, 50266,     9,  1344,    13, 36743,\n",
       "           15, 36377,    13,  1213,    13, 45385, 36997,    10, 31343,    27,\n",
       "        12960, 10669,    13,  2330,   866, 11028,   604,  1929,    13,   187,\n",
       "        50254, 50254, 50262,  6870,   272, 21229,  3167,  1590,    13, 21229,\n",
       "          604,  2530,   535, 50270, 21328,  3013,    27,   187, 50266,    15,\n",
       "        15992,  1692, 15714,  5330,    27,   604,   253, 16164,  2748,   310,\n",
       "        10945,   187, 50266,    15, 15992,  1692, 22444,  5330,    27,   604,\n",
       "          253, 16164,   830,   476,   626,   320, 11742,   187, 50270, 32488,\n",
       "          187, 50270, 13763,   426,   866, 11028,   426, 21229,   426,  8256,\n",
       "          187, 50270,  4856,    84, 15310,   426, 45385, 13457,    15, 11252,\n",
       "           64, 24691,  5648, 13792,   187, 50270,  6050,   417, 10669,    27,\n",
       "          187, 50266,  1704,    84,   426,   540,     9,  2606,    15,  2606,\n",
       "         6649,   187, 50266, 13362,   426,  1881,    15,   788, 13815,  9726,\n",
       "        16850,     9,  1344,     9,  1704,    84,  1228,   187, 50266, 27641,\n",
       "          426, 17579, 18703,  1898,  4814,  1381,   346,  1212,  2618,    30,\n",
       "          983,  4856,    84,    33,   983,    79,   983,   737,    15,   681,\n",
       "           28,   673, 11787,    17,  4718,  5569,  1898,  4814,  9604, 11787,\n",
       "           18,    94,  3446,  8124,     9,  1704,    84,    13, 13283,   582,\n",
       "          187, 50255,     3, 38305,  1381,   346,  3319,  3170,   292,  5097,\n",
       "          568,   559,  1629,  1692, 11200,    13,   346, 38066,  9677,  1381,\n",
       "          346, 41794,  1909, 20611,   986,   187, 50266, 42882, 23450,   426,\n",
       "         1881,    15, 22670,  1587, 15743,   995, 36028,    17,  9228, 15987,\n",
       "           16,  5288,    16,   423, 10801,  3446,  8124,     9,  4856,    84,\n",
       "        15310,   582, 11646, 10190,  1518,    13,   848,    13, 21566,   582,\n",
       "          187, 50254, 50265, 27641,    30, 27641,    13, 14113,    30,  9819,\n",
       "        42882, 30880,  1381,   346, 28172,  7547,   187, 50266,  1747, 11200,\n",
       "        22893,   426, 21229, 23450,    15, 27641,    15,   788,  1587,  4531,\n",
       "           14, 46563, 11200,  2807,   187, 50266,  9450, 22893,   426, 21229,\n",
       "        23450,    15, 27641,    15,   788,  1587, 11930,  2807,   187, 50266,\n",
       "          338,  1150, 22893,    27,   187, 50262,  9450, 49563,   426,   294,\n",
       "           15,  8716,     9,    83, 31770,  3614,  1358,  5180,    16, 20871,\n",
       "           16,    87,    18,  1933, 15987,    16,  5288,    16,   423, 10801,\n",
       "            9,  5624,     6,    24,    35,    60,    66,    14,    91,    17,\n",
       "           14,    26, 23671, 20871,     6,    24,    37,  1228, 46607,  1150,\n",
       "        22893,   481, 12896,  1082,   187, 50262,   338,  1150, 49563,    60,\n",
       "           19,  5218,   187, 50258, 42882,   426, 45385, 36997,     9,  1286,\n",
       "           15, 22670,    13,  1150, 49563,    60,    19,  1570, 13481, 22219,\n",
       "           24,    35,   995, 36028,  6788, 13481, 22219,    24,    37,   995,\n",
       "          346, 13272,  1228,   187, 50262,   338,   417,  1150, 49563,    60,\n",
       "           17,    62,  2295, 13818,  5943, 15310,    27,   187, 50258,     4,\n",
       "        45385,   310, 10568,   253,   897,   273,   247,  1027,  3167,  1590,\n",
       "           15,   187, 50258,  4856,    84, 15310,   426,  1150, 22893,    15,\n",
       "         2967,  4403, 28229,   995,   577,   604,  1150, 49563,    60,    19,\n",
       "           62,  2010,   495,  6904,    17,    62,   187, 50258,     4,  5037,\n",
       "          626,  2997,   253, 10669,   604,  1246,    13,   359,   878,   281,\n",
       "          294,    14, 15905,   806,    15,   187, 50258, 25674,   187, 50266,\n",
       "          338,   810, 11200, 22893,    27,   187, 50262, 13763,   426,   294,\n",
       "           15,  8716,     9,    83, 31770, 46818, 11200, 20879,    66,    14,\n",
       "           91,    17,    14,    26,    61, 34554,    30,    62, 15020,   995,\n",
       "          810, 11200, 22893,    13,   294,    15,    42,   481,  4399,     9,\n",
       "           18,    10,   187, 50262,  1747,  1672,  5378,    90,   426,   294,\n",
       "           15,  8716,     9,    83,     3,   911, 31659, 36864,    69, 15020,\n",
       "          995,   810, 11200, 22893,   481,  4399,     9,    18,    10,   187,\n",
       "        50262,  4347, 11028,   426, 36743,    15,  4064, 32549,     9,   565,\n",
       "            9,  1747,  1672,  5378,    90,  1228,   187, 50262,  1747,  7689,\n",
       "        21008,   426,   294,    15,  8716,     9,    83,     3, 42882,  2618,\n",
       "           30,  7506,    60,    66,    14,    91,    17,    14,    26, 23671,\n",
       "        20871,  2311,   995,   810, 11200, 22893,    10,   187, 50262,   338,\n",
       "          810,  7689, 21008,    27,   187, 50258, 42882,   426, 45385, 36997,\n",
       "            9,  1286,    15, 22670,    13,   810,  7689, 21008,    15,  4399,\n",
       "            9,    18,  1228,   187, 50266,   338,   417, 21229,   285, 21229,\n",
       "        23450,    15,  8581,    64,  3211,  2295,  1052,   285, 21229, 23450,\n",
       "           15,  8456, 14850,   187, 50262,     4,  7890,   253,   954,  3332,\n",
       "        21229,  7117,   275,   253, 13922,  2380,    15,   187, 50262, 42882,\n",
       "          426, 45385, 36997,     9,  1286,    15, 22670,    13, 21229, 23450,\n",
       "           15,  8456, 43144,    17,  7082,     3,   301, 45564,   187, 50270,\n",
       "         2309, 10669,    13,   866, 11028,    13, 13818,  5943, 15310,    13,\n",
       "        21229], device='cuda:0', dtype=torch.int32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.decode( input_ids_list[0] ) #Decoding IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50254"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab_size #Check this value with WTE in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.to( 'cpu' ) #WARNING, \n",
    "model.to( device ) #WARNING, Verify the device before assigning to memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'big_table_path': '../data/concept_tables/codesearch_tesbed_EleutherAI-gpt-neox-20b_1024_10000.csv',\n",
       " 'hf_model': 'eleutherai/gpt-neox-20b',\n",
       " 'model_name': 'EleutherAI-gpt-neoX-20b_1024_10000_',\n",
       " 'callbacks': '../datax/callbacks-EleutherAI-gpt-neoX_1024_10000_',\n",
       " 'wpe': 2048}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters #Verification Point of Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit_extractor(batch, input, from_index=0):\n",
    "    \"\"\"\n",
    "    Output is the class CausalLMOutputWithPast (https://huggingface.co/transformers/v4.10.1/main_classes/output.html?highlight=causallmoutputwithpast)\"\n",
    "    logits (torch.FloatTensor of shape (batch_size, sequence_length, config.vocab_size)) – Prediction scores of the language modeling head (scores for each vocabulary token before SoftMax).\n",
    "    The expression i.type(torch.LongTensor).to(device) is for casting labels for the loss\n",
    "    \"\"\"\n",
    "    #Output is in CausalLMOutputWithPast\n",
    "\n",
    "    for idx, n in enumerate( range( from_index, len(input), batch) ):\n",
    "        \n",
    "        #output = [ model( \n",
    "        #    input_ids = i, \n",
    "        #    labels = i.type(torch.LongTensor).to(device) \n",
    "        #    ) for i in input[n:n+batch] ] #Labels must be provided to compute loss\n",
    "        output = []\n",
    "        for i in input[n:n+batch]:\n",
    "            #print(i)\n",
    "            output.append( \n",
    "                model( \n",
    "                    input_ids = i, \n",
    "                    labels = i.to(torch.long).to(device) \n",
    "                )\n",
    "            )\n",
    "        \n",
    "        #print(output)\n",
    "        \n",
    "        output_logits = [ o.logits.detach().to('cpu').numpy() for o in output ]  #Logits Extraction\n",
    "        ###Acuracy\n",
    "        output_loss = np.array([ o.loss.detach().to('cpu').numpy() for o in output ])  #Language modeling loss (for next-token prediction).\n",
    "        #Saving Callbacks\n",
    "        current_batch = idx + (from_index//batch)\n",
    "        for jdx, o_logits in enumerate( output_logits ):\n",
    "            np.save( parameters['callbacks']+ '/'+parameters['model_name']  + f'_logits_tensor[{jdx+n}]_batch[{current_batch}].npy', o_logits)\n",
    "        np.save( parameters['callbacks']+ '/'+parameters['model_name']+f'_loss_batch[{current_batch}].npy', output_loss)\n",
    "        \n",
    "        print(f\"Batch [{current_batch}] Completed\")\n",
    "        \n",
    "        #Memory Released\n",
    "        for out in output:         \n",
    "            del out\n",
    "            torch.cuda.empty_cache()\n",
    "        for out in output_logits:\n",
    "            del out\n",
    "            torch.cuda.empty_cache()\n",
    "        for out in output_loss:\n",
    "            del out\n",
    "            torch.cuda.empty_cache()\n",
    "        del output\n",
    "        del output_logits\n",
    "        del output_loss\n",
    "            \n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:512\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">logit_extractor</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.8/dist-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1130</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1127 │   │   # this function, and just call forward.</span>                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1128 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">o</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1129 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1130 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, **kwargs)                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1131 │   │   # Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1132 │   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1133 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks:                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.8/dist-packages/accelerate/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">hooks.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">165</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">new_forward</span>                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">162 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> torch.no_grad():                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">163 │   │   │   │   </span>output = old_forward(*args, **kwargs)                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">164 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>165 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>output = old_forward(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">166 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> module._hf_hook.post_forward(module, output)                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">167 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">168 │   </span>module.forward = new_forward                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.8/dist-packages/transformers/models/gpt_neox/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_gpt_neox.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">654</span> in  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">651 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">```\"\"\"</span>                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">652 │   │   </span>return_dict = return_dict <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> return_dict <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.config.use_return   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">653 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>654 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>outputs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.gpt_neox(                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">655 │   │   │   </span>input_ids,                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">656 │   │   │   </span>attention_mask=attention_mask,                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">657 │   │   │   </span>head_mask=head_mask,                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.8/dist-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1130</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1127 │   │   # this function, and just call forward.</span>                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1128 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">o</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1129 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1130 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, **kwargs)                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1131 │   │   # Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1132 │   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1133 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks:                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.8/dist-packages/transformers/models/gpt_neox/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_gpt_neox.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">481</span> in  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">478 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">479 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">ValueError</span>(<span style=\"color: #808000; text-decoration-color: #808000\">\"You have to specify either input_ids or inputs_embeds\"</span>)      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">480 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>481 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>batch_size, seq_length = input_shape                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">482 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">483 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> past_key_values <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">484 │   │   │   </span>past_key_values = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">tuple</span>([<span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>] * <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.config.num_hidden_layers)                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">ValueError: </span>not enough values to unpack <span style=\"font-weight: bold\">(</span>expected <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, got <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92mlogit_extractor\u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1130\u001b[0m in \u001b[92m_call_impl\u001b[0m             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1127 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# this function, and just call forward.\u001b[0m                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1128 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_pre_hooks \u001b[95mo\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1129 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1130 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*\u001b[96minput\u001b[0m, **kwargs)                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1131 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1132 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1133 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m _global_backward_hooks:                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.8/dist-packages/accelerate/\u001b[0m\u001b[1;33mhooks.py\u001b[0m:\u001b[94m165\u001b[0m in \u001b[92mnew_forward\u001b[0m                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m162 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mwith\u001b[0m torch.no_grad():                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m163 \u001b[0m\u001b[2m│   │   │   │   \u001b[0moutput = old_forward(*args, **kwargs)                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m164 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m165 \u001b[2m│   │   │   \u001b[0moutput = old_forward(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m166 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m module._hf_hook.post_forward(module, output)                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m167 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m168 \u001b[0m\u001b[2m│   \u001b[0mmodule.forward = new_forward                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.8/dist-packages/transformers/models/gpt_neox/\u001b[0m\u001b[1;33mmodeling_gpt_neox.py\u001b[0m:\u001b[94m654\u001b[0m in  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mforward\u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m651 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m```\"\"\"\u001b[0m                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m652 \u001b[0m\u001b[2m│   │   \u001b[0mreturn_dict = return_dict \u001b[94mif\u001b[0m return_dict \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m \u001b[94melse\u001b[0m \u001b[96mself\u001b[0m.config.use_return   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m653 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m654 \u001b[2m│   │   \u001b[0moutputs = \u001b[96mself\u001b[0m.gpt_neox(                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m655 \u001b[0m\u001b[2m│   │   │   \u001b[0minput_ids,                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m656 \u001b[0m\u001b[2m│   │   │   \u001b[0mattention_mask=attention_mask,                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m657 \u001b[0m\u001b[2m│   │   │   \u001b[0mhead_mask=head_mask,                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1130\u001b[0m in \u001b[92m_call_impl\u001b[0m             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1127 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# this function, and just call forward.\u001b[0m                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1128 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_pre_hooks \u001b[95mo\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1129 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1130 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*\u001b[96minput\u001b[0m, **kwargs)                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1131 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1132 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1133 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m _global_backward_hooks:                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.8/dist-packages/transformers/models/gpt_neox/\u001b[0m\u001b[1;33mmodeling_gpt_neox.py\u001b[0m:\u001b[94m481\u001b[0m in  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mforward\u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m478 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m479 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mValueError\u001b[0m(\u001b[33m\"\u001b[0m\u001b[33mYou have to specify either input_ids or inputs_embeds\u001b[0m\u001b[33m\"\u001b[0m)      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m480 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m481 \u001b[2m│   │   \u001b[0mbatch_size, seq_length = input_shape                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m482 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m483 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m past_key_values \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m:                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m484 \u001b[0m\u001b[2m│   │   │   \u001b[0mpast_key_values = \u001b[96mtuple\u001b[0m([\u001b[94mNone\u001b[0m] * \u001b[96mself\u001b[0m.config.num_hidden_layers)                \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mValueError: \u001b[0mnot enough values to unpack \u001b[1m(\u001b[0mexpected \u001b[1;36m2\u001b[0m, got \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## ACTUAL EXPERIMENT\n",
    "## TIME AND MEMORY CONSUMING\n",
    "logit_extractor(batch = 1, input= input_ids_list, from_index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#logit_extractor(batch =2, input= input_ids_list[:2]) #<---- [WARNING TIME AND MEMORY CONSUMING]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_list[245].shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = torch.rand(1000)\n",
    "i = i.to(int)\n",
    "i.shape\n",
    "#i.type(torch.LongTensor).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del i \n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model( input_ids = i, labels = i.to(torch.long).to(device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i =input_ids_list[243]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i.to(torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_logits = np.load('../data/callbacks/logits_tensor[0]_batch[0].npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assert output_logits.shape[0] == len(input_ids_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_loss = np.load('../data/callbacks/loss_batch[0].npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
