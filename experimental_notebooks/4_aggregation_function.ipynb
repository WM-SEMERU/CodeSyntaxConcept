{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import load_dataset \n",
    "from CodeSyntaxConcept.tokenizer import CodeTokenizer\n",
    "import CodeSyntaxConcept.utils as utils\n",
    "from statistics import mean, median\n",
    "import json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"EleutherAI/gpt-neo-125M\"\n",
    "file_path = \"output/testbed_base_EleutherAI-gpt-neo-125M.csv\"\n",
    "language = \"python\"\n",
    "aggregates_path = \"output/aggregation_function/\" + file_path.split('/')[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = CodeTokenizer.from_pretrained(checkpoint, language)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual Token Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_actual_ntp = pd.read_csv(file_path, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>whole_func_string</th>\n",
       "      <th>ast_concepts</th>\n",
       "      <th>model_tokenizer_concepts</th>\n",
       "      <th>model_input_ids</th>\n",
       "      <th>model_total_input_ids</th>\n",
       "      <th>max_prob_case</th>\n",
       "      <th>min_prob_case</th>\n",
       "      <th>actual_prob_case</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>def get_node(self, label):\\n        \"\"\"\\n     ...</td>\n",
       "      <td>[('def', 'def', 'function_definition'), ('get_...</td>\n",
       "      <td>[(4299, 'def', 'function_definition'), (651, '...</td>\n",
       "      <td>[4299, 651, 62, 17440, 7, 944, 11, 6167, 2599,...</td>\n",
       "      <td>115</td>\n",
       "      <td>[('ers', 0.03083181567490101), ('_', 0.2419087...</td>\n",
       "      <td>[('anwhile', 1.03836617568492e-16), ('ousy', 3...</td>\n",
       "      <td>[('Ġget', 0.0024285861290991306), ('_', 0.2419...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>def execute_pipeline(pipeline, environment_dic...</td>\n",
       "      <td>[('def', 'def', 'function_definition'), ('exec...</td>\n",
       "      <td>[(4299, 'def', 'function_definition'), (12260,...</td>\n",
       "      <td>[4299, 12260, 62, 79, 541, 4470, 7, 79, 541, 4...</td>\n",
       "      <td>492</td>\n",
       "      <td>[('ers', 0.03083181567490101), ('_', 0.1853068...</td>\n",
       "      <td>[('anwhile', 1.03836617568492e-16), ('icester'...</td>\n",
       "      <td>[('Ġexecute', 5.97450380155351e-05), ('_', 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>def _decode(self, data):\\n        '''\\n       ...</td>\n",
       "      <td>[('def', 'def', 'function_definition'), ('_dec...</td>\n",
       "      <td>[(4299, 'def', 'function_definition'), (4808, ...</td>\n",
       "      <td>[4299, 4808, 12501, 1098, 7, 944, 11, 1366, 25...</td>\n",
       "      <td>583</td>\n",
       "      <td>[('ers', 0.03083181567490101), ('(', 0.0166473...</td>\n",
       "      <td>[('anwhile', 1.03836617568492e-16), ('ousy', 4...</td>\n",
       "      <td>[('Ġ_', 0.001834857277572155), ('dec', 0.00133...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>def _repr_html_(self):\\n        \"\"\"\\n        J...</td>\n",
       "      <td>[('def', 'def', 'function_definition'), ('_rep...</td>\n",
       "      <td>[(4299, 'def', 'function_definition'), (4808, ...</td>\n",
       "      <td>[4299, 4808, 260, 1050, 62, 6494, 41052, 944, ...</td>\n",
       "      <td>221</td>\n",
       "      <td>[('ers', 0.03083181567490101), ('(', 0.0166473...</td>\n",
       "      <td>[('anwhile', 1.03836617568492e-16), ('ousy', 4...</td>\n",
       "      <td>[('Ġ_', 0.001834857277572155), ('re', 0.001378...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>def build_shape(relation, nodes, ways):\\n    \"...</td>\n",
       "      <td>[('def', 'def', 'function_definition'), ('buil...</td>\n",
       "      <td>[(4299, 'def', 'function_definition'), (1382, ...</td>\n",
       "      <td>[4299, 1382, 62, 43358, 7, 49501, 11, 13760, 1...</td>\n",
       "      <td>454</td>\n",
       "      <td>[('ers', 0.03083181567490101), ('_', 0.2842166...</td>\n",
       "      <td>[('anwhile', 1.03836617568492e-16), ('buquerqu...</td>\n",
       "      <td>[('Ġbuild', 0.0005856865900568664), ('_', 0.28...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   whole_func_string  \\\n",
       "0  def get_node(self, label):\\n        \"\"\"\\n     ...   \n",
       "1  def execute_pipeline(pipeline, environment_dic...   \n",
       "2  def _decode(self, data):\\n        '''\\n       ...   \n",
       "3  def _repr_html_(self):\\n        \"\"\"\\n        J...   \n",
       "4  def build_shape(relation, nodes, ways):\\n    \"...   \n",
       "\n",
       "                                        ast_concepts  \\\n",
       "0  [('def', 'def', 'function_definition'), ('get_...   \n",
       "1  [('def', 'def', 'function_definition'), ('exec...   \n",
       "2  [('def', 'def', 'function_definition'), ('_dec...   \n",
       "3  [('def', 'def', 'function_definition'), ('_rep...   \n",
       "4  [('def', 'def', 'function_definition'), ('buil...   \n",
       "\n",
       "                            model_tokenizer_concepts  \\\n",
       "0  [(4299, 'def', 'function_definition'), (651, '...   \n",
       "1  [(4299, 'def', 'function_definition'), (12260,...   \n",
       "2  [(4299, 'def', 'function_definition'), (4808, ...   \n",
       "3  [(4299, 'def', 'function_definition'), (4808, ...   \n",
       "4  [(4299, 'def', 'function_definition'), (1382, ...   \n",
       "\n",
       "                                     model_input_ids  model_total_input_ids  \\\n",
       "0  [4299, 651, 62, 17440, 7, 944, 11, 6167, 2599,...                    115   \n",
       "1  [4299, 12260, 62, 79, 541, 4470, 7, 79, 541, 4...                    492   \n",
       "2  [4299, 4808, 12501, 1098, 7, 944, 11, 1366, 25...                    583   \n",
       "3  [4299, 4808, 260, 1050, 62, 6494, 41052, 944, ...                    221   \n",
       "4  [4299, 1382, 62, 43358, 7, 49501, 11, 13760, 1...                    454   \n",
       "\n",
       "                                       max_prob_case  \\\n",
       "0  [('ers', 0.03083181567490101), ('_', 0.2419087...   \n",
       "1  [('ers', 0.03083181567490101), ('_', 0.1853068...   \n",
       "2  [('ers', 0.03083181567490101), ('(', 0.0166473...   \n",
       "3  [('ers', 0.03083181567490101), ('(', 0.0166473...   \n",
       "4  [('ers', 0.03083181567490101), ('_', 0.2842166...   \n",
       "\n",
       "                                       min_prob_case  \\\n",
       "0  [('anwhile', 1.03836617568492e-16), ('ousy', 3...   \n",
       "1  [('anwhile', 1.03836617568492e-16), ('icester'...   \n",
       "2  [('anwhile', 1.03836617568492e-16), ('ousy', 4...   \n",
       "3  [('anwhile', 1.03836617568492e-16), ('ousy', 4...   \n",
       "4  [('anwhile', 1.03836617568492e-16), ('buquerqu...   \n",
       "\n",
       "                                    actual_prob_case  \n",
       "0  [('Ġget', 0.0024285861290991306), ('_', 0.2419...  \n",
       "1  [('Ġexecute', 5.97450380155351e-05), ('_', 0.1...  \n",
       "2  [('Ġ_', 0.001834857277572155), ('dec', 0.00133...  \n",
       "3  [('Ġ_', 0.001834857277572155), ('re', 0.001378...  \n",
       "4  [('Ġbuild', 0.0005856865900568664), ('_', 0.28...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_actual_ntp.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Token Binding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bind_bpe_tokens(\n",
    "    node,              #Tree sitter ast tree\n",
    "    encoding,          #Token encoding\n",
    "    actual_probs,      #Actual probabilities\n",
    "    lines              #Source code Snippet\n",
    "): \n",
    "    \"\"\"Traverses the tree and bind the leaves with the corresponding node\"\"\"\n",
    "    tree_node = {}\n",
    "    tree_node['type'] = node.type\n",
    "    tree_node['children'] = []\n",
    "    tree_node['bindings'] = []\n",
    "\n",
    "    node_span = [utils.convert_to_offset(node.start_point, lines), utils.convert_to_offset(node.end_point, lines)]\n",
    "    for encoding_index, token_span in enumerate(encoding.offset_mapping):\n",
    "        if (node_span[0] <= token_span[0] and token_span[0] < node_span[1]) \\\n",
    "        or (node_span[0] < token_span[1] and token_span[1] <= node_span[1]) \\\n",
    "        or (node_span[0] >= token_span[0] and token_span[1] >= node_span[1]) :\n",
    "            tree_node['bindings'].append(actual_probs[encoding_index])\n",
    "    \n",
    "    for n in node.children:\n",
    "        tree_node['children'].append(bind_bpe_tokens(n, encoding, actual_probs, lines))\n",
    "\n",
    "    return tree_node\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tokenizer.tokenizer(df_actual_ntp.iloc[0]['whole_func_string'], return_offsets_mapping=True)\n",
    "assert len(eval(df_actual_ntp.iloc[0]['model_input_ids'])) == len(encoding['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-01 14:14:40.106907: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-01 14:14:42.325073: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.6/lib64\n",
      "2023-03-01 14:14:42.325181: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.6/lib64\n",
      "2023-03-01 14:14:42.325190: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "binded_tree_col = []\n",
    "for index, row in df_actual_ntp.iterrows():\n",
    "    tree = tokenizer.parser.parse(bytes(row['whole_func_string'], \"utf8\"))\n",
    "    encoding = tokenizer.tokenizer(row['whole_func_string'], return_offsets_mapping=True)\n",
    "    actual_logits = eval(row['actual_prob_case'])\n",
    "    actual_logits.insert(0,(tokenizer.tokenizer.decode(eval(row['model_input_ids'])[0]),'FIRST_TOKEN'))\n",
    "    binded_tree = bind_bpe_tokens(tree.root_node, encoding, actual_logits, row['whole_func_string'].split('\\n'))\n",
    "    binded_tree_col.append(binded_tree)\n",
    "df_actual_ntp['binded_tree'] = binded_tree_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_bindings(\n",
    "    node: dict,     #Binded AST tree with actual probabilities\n",
    ") -> None:\n",
    "    node_actual_probs = [binding[1] for binding in node['bindings'] if isinstance(binding[1], float)]\n",
    "    node['median_prob'] = node['max_prob'] = node['min_prob'] = node['avg_prob'] =  node['std'] = None\n",
    "    ## len is zero if node correspond to FIRST_TOKEN = 'def' \n",
    "    if(len(node_actual_probs) > 0):\n",
    "        ## BOOTSTRAPPING-> \n",
    "        node_actual_probs = utils.bootstrapping(node_actual_probs, np.mean, size=500).tolist()\n",
    "        ##\n",
    "        node['median_prob'] = median(node_actual_probs) \n",
    "        node['max_prob'] = max(node_actual_probs) \n",
    "        node['min_prob'] = min(node_actual_probs)\n",
    "        node['avg_prob'] = mean(node_actual_probs)\n",
    "        node['std'] = np.std(node_actual_probs)\n",
    "    for child in node['children']:\n",
    "        process_bindings(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0025257335510104895\n",
      "0.08677685260772705\n"
     ]
    }
   ],
   "source": [
    "df_actual_ntp['binded_tree'].apply(lambda binded_tree: process_bindings(binded_tree))\n",
    "print(df_actual_ntp.iloc[0]['binded_tree']['children'][0]['children'][1]['median_prob'])\n",
    "print(df_actual_ntp.iloc[1]['binded_tree']['children'][0]['children'][1]['median_prob'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>whole_func_string</th>\n",
       "      <th>ast_concepts</th>\n",
       "      <th>model_tokenizer_concepts</th>\n",
       "      <th>model_input_ids</th>\n",
       "      <th>model_total_input_ids</th>\n",
       "      <th>max_prob_case</th>\n",
       "      <th>min_prob_case</th>\n",
       "      <th>actual_prob_case</th>\n",
       "      <th>binded_tree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>def get_node(self, label):\\n        \"\"\"\\n     ...</td>\n",
       "      <td>[('def', 'def', 'function_definition'), ('get_...</td>\n",
       "      <td>[(4299, 'def', 'function_definition'), (651, '...</td>\n",
       "      <td>[4299, 651, 62, 17440, 7, 944, 11, 6167, 2599,...</td>\n",
       "      <td>115</td>\n",
       "      <td>[('ers', 0.03083181567490101), ('_', 0.2419087...</td>\n",
       "      <td>[('anwhile', 1.03836617568492e-16), ('ousy', 3...</td>\n",
       "      <td>[('Ġget', 0.0024285861290991306), ('_', 0.2419...</td>\n",
       "      <td>{'type': 'module', 'children': [{'type': 'func...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>def execute_pipeline(pipeline, environment_dic...</td>\n",
       "      <td>[('def', 'def', 'function_definition'), ('exec...</td>\n",
       "      <td>[(4299, 'def', 'function_definition'), (12260,...</td>\n",
       "      <td>[4299, 12260, 62, 79, 541, 4470, 7, 79, 541, 4...</td>\n",
       "      <td>492</td>\n",
       "      <td>[('ers', 0.03083181567490101), ('_', 0.1853068...</td>\n",
       "      <td>[('anwhile', 1.03836617568492e-16), ('icester'...</td>\n",
       "      <td>[('Ġexecute', 5.97450380155351e-05), ('_', 0.1...</td>\n",
       "      <td>{'type': 'module', 'children': [{'type': 'func...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>def _decode(self, data):\\n        '''\\n       ...</td>\n",
       "      <td>[('def', 'def', 'function_definition'), ('_dec...</td>\n",
       "      <td>[(4299, 'def', 'function_definition'), (4808, ...</td>\n",
       "      <td>[4299, 4808, 12501, 1098, 7, 944, 11, 1366, 25...</td>\n",
       "      <td>583</td>\n",
       "      <td>[('ers', 0.03083181567490101), ('(', 0.0166473...</td>\n",
       "      <td>[('anwhile', 1.03836617568492e-16), ('ousy', 4...</td>\n",
       "      <td>[('Ġ_', 0.001834857277572155), ('dec', 0.00133...</td>\n",
       "      <td>{'type': 'module', 'children': [{'type': 'func...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>def _repr_html_(self):\\n        \"\"\"\\n        J...</td>\n",
       "      <td>[('def', 'def', 'function_definition'), ('_rep...</td>\n",
       "      <td>[(4299, 'def', 'function_definition'), (4808, ...</td>\n",
       "      <td>[4299, 4808, 260, 1050, 62, 6494, 41052, 944, ...</td>\n",
       "      <td>221</td>\n",
       "      <td>[('ers', 0.03083181567490101), ('(', 0.0166473...</td>\n",
       "      <td>[('anwhile', 1.03836617568492e-16), ('ousy', 4...</td>\n",
       "      <td>[('Ġ_', 0.001834857277572155), ('re', 0.001378...</td>\n",
       "      <td>{'type': 'module', 'children': [{'type': 'func...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>def build_shape(relation, nodes, ways):\\n    \"...</td>\n",
       "      <td>[('def', 'def', 'function_definition'), ('buil...</td>\n",
       "      <td>[(4299, 'def', 'function_definition'), (1382, ...</td>\n",
       "      <td>[4299, 1382, 62, 43358, 7, 49501, 11, 13760, 1...</td>\n",
       "      <td>454</td>\n",
       "      <td>[('ers', 0.03083181567490101), ('_', 0.2842166...</td>\n",
       "      <td>[('anwhile', 1.03836617568492e-16), ('buquerqu...</td>\n",
       "      <td>[('Ġbuild', 0.0005856865900568664), ('_', 0.28...</td>\n",
       "      <td>{'type': 'module', 'children': [{'type': 'func...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   whole_func_string  \\\n",
       "0  def get_node(self, label):\\n        \"\"\"\\n     ...   \n",
       "1  def execute_pipeline(pipeline, environment_dic...   \n",
       "2  def _decode(self, data):\\n        '''\\n       ...   \n",
       "3  def _repr_html_(self):\\n        \"\"\"\\n        J...   \n",
       "4  def build_shape(relation, nodes, ways):\\n    \"...   \n",
       "\n",
       "                                        ast_concepts  \\\n",
       "0  [('def', 'def', 'function_definition'), ('get_...   \n",
       "1  [('def', 'def', 'function_definition'), ('exec...   \n",
       "2  [('def', 'def', 'function_definition'), ('_dec...   \n",
       "3  [('def', 'def', 'function_definition'), ('_rep...   \n",
       "4  [('def', 'def', 'function_definition'), ('buil...   \n",
       "\n",
       "                            model_tokenizer_concepts  \\\n",
       "0  [(4299, 'def', 'function_definition'), (651, '...   \n",
       "1  [(4299, 'def', 'function_definition'), (12260,...   \n",
       "2  [(4299, 'def', 'function_definition'), (4808, ...   \n",
       "3  [(4299, 'def', 'function_definition'), (4808, ...   \n",
       "4  [(4299, 'def', 'function_definition'), (1382, ...   \n",
       "\n",
       "                                     model_input_ids  model_total_input_ids  \\\n",
       "0  [4299, 651, 62, 17440, 7, 944, 11, 6167, 2599,...                    115   \n",
       "1  [4299, 12260, 62, 79, 541, 4470, 7, 79, 541, 4...                    492   \n",
       "2  [4299, 4808, 12501, 1098, 7, 944, 11, 1366, 25...                    583   \n",
       "3  [4299, 4808, 260, 1050, 62, 6494, 41052, 944, ...                    221   \n",
       "4  [4299, 1382, 62, 43358, 7, 49501, 11, 13760, 1...                    454   \n",
       "\n",
       "                                       max_prob_case  \\\n",
       "0  [('ers', 0.03083181567490101), ('_', 0.2419087...   \n",
       "1  [('ers', 0.03083181567490101), ('_', 0.1853068...   \n",
       "2  [('ers', 0.03083181567490101), ('(', 0.0166473...   \n",
       "3  [('ers', 0.03083181567490101), ('(', 0.0166473...   \n",
       "4  [('ers', 0.03083181567490101), ('_', 0.2842166...   \n",
       "\n",
       "                                       min_prob_case  \\\n",
       "0  [('anwhile', 1.03836617568492e-16), ('ousy', 3...   \n",
       "1  [('anwhile', 1.03836617568492e-16), ('icester'...   \n",
       "2  [('anwhile', 1.03836617568492e-16), ('ousy', 4...   \n",
       "3  [('anwhile', 1.03836617568492e-16), ('ousy', 4...   \n",
       "4  [('anwhile', 1.03836617568492e-16), ('buquerqu...   \n",
       "\n",
       "                                    actual_prob_case  \\\n",
       "0  [('Ġget', 0.0024285861290991306), ('_', 0.2419...   \n",
       "1  [('Ġexecute', 5.97450380155351e-05), ('_', 0.1...   \n",
       "2  [('Ġ_', 0.001834857277572155), ('dec', 0.00133...   \n",
       "3  [('Ġ_', 0.001834857277572155), ('re', 0.001378...   \n",
       "4  [('Ġbuild', 0.0005856865900568664), ('_', 0.28...   \n",
       "\n",
       "                                         binded_tree  \n",
       "0  {'type': 'module', 'children': [{'type': 'func...  \n",
       "1  {'type': 'module', 'children': [{'type': 'func...  \n",
       "2  {'type': 'module', 'children': [{'type': 'func...  \n",
       "3  {'type': 'module', 'children': [{'type': 'func...  \n",
       "4  {'type': 'module', 'children': [{'type': 'func...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_actual_ntp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Convert to JSON Object\n",
    "df_actual_ntp['binded_tree'] = df_actual_ntp['binded_tree'].map(lambda binded_tree: json.dumps(binded_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_actual_ntp.to_csv(aggregates_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "49b68b9c38357b2088122ab1ddc655dffe83bd2309642e44c64d6d94a1d66aec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
