{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(filename=\"../datax/log.log\", format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from statistics import NormalDist\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.1+cu113'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Apr 22 03:58:27 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 530.30.02              Driver Version: 530.30.02    CUDA Version: 12.1     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                  Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA TITAN RTX                On | 00000000:02:00.0 Off |                  N/A |\n",
      "| 41%   38C    P8               15W / 280W|     20MiB / 24576MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logits Extractor\n",
    ">\n",
    "> Extracting Tensor Logits from a given Neural Code Model @xxxxxp\n",
    ">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def c_eleuther( model_type, returnModel = False, cache_path = \"../datax/cache\"):\n",
    "    ''' Eleuther and Salesforce and Parrot uses the same importation'''\n",
    "    from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_type, cache_dir = cache_path )\n",
    "    model = []\n",
    "    logging.info(\"Tokenizer Loaded\")\n",
    "    if returnModel:\n",
    "        model = AutoModelForCausalLM.from_pretrained(model_type, cache_dir = cache_path)\n",
    "        logging.info(\"Model Loaded\")        \n",
    "    \n",
    "    logging.info(model_type)\n",
    "    return tokenizer, model\n",
    "    \n",
    "    \n",
    "\n",
    "def init_model_args( current_case, returnModel = False ): \n",
    "    \n",
    "    code_models = {\n",
    "        'c1':('EleutherAI/gpt-neo-125m', ), # Basic (on Pile) GPT-3/J\n",
    "        'c2':('EleutherAI/gpt-neo-1.3B', ),\n",
    "        'c3':('EleutherAI/gpt-neo-2.7B', ),\n",
    "        'c4':('EleutherAI/gpt-j-6b', ),\n",
    "        'c5':('Salesforce/codegen-350M-nl', ), #Basic (on Pile) codegen\n",
    "        'c6':('Salesforce/codegen-2B-nl', ),\n",
    "        'c7':('Salesforce/codegen-6B-nl', ),\n",
    "        'c8':('Salesforce/codegen-16B-nl', ),\n",
    "        'c9':('codeparrot/codeparrot-small-multi', ), #multi-Language\n",
    "        'c10':('Salesforce/codegen-350M-multi', ),\n",
    "        'c11':('Salesforce/codegen-2B-multi', ),\n",
    "        'c12':('Salesforce/codegen-6B-multi', ),\n",
    "        'c13':('Salesforce/codegen-16B-multi', ),\n",
    "        'c14':('codeparrot/codeparrot-small', ), #mono-Language\n",
    "        'c15':('codeparrot/codeparrot', ),\n",
    "        'c16':('Salesforce/codegen-350M-mono', ),\n",
    "        'c17':('Salesforce/codegen-2B-mono', ),\n",
    "        'c18':('Salesforce/codegen-6B-mono', ),\n",
    "        'c19':('Salesforce/codegen-16B-mono', ),\n",
    "    }\n",
    "    \n",
    "    model_type = code_models[current_case][0]\n",
    "    tokenizer, model =  c_eleuther( returnModel = returnModel,  model_type = model_type ) \n",
    "    \n",
    "    \n",
    "    return model_type, tokenizer, model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init Parameters\n",
    "> Loading Models and Testbeds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [WARNING] Hyperparameters changes, please tune them up\n",
    "params = {\n",
    "    'codemodel' : 'c1',\n",
    "    'numpy_files_logits_path': '../datax/1_numpy_files_logits/c1',\n",
    "    'testbeds_path' : '../data/testbeds/AstEvalVerticalFiltered.json',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "      <th>ids</th>\n",
       "      <th>m_name</th>\n",
       "      <th>code</th>\n",
       "      <th>ast_errors</th>\n",
       "      <th>n_ast_errors</th>\n",
       "      <th>ast_levels</th>\n",
       "      <th>n_whitespaces_</th>\n",
       "      <th>complexity</th>\n",
       "      <th>nloc</th>\n",
       "      <th>token_counts</th>\n",
       "      <th>n_ast_nodes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>280</td>\n",
       "      <td>[4299, 1057, 62, 29412, 62, 41989, 7, 9288, 62...</td>\n",
       "      <td>c1</td>\n",
       "      <td>def run_python_tests(test_modules, parallelism...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>67</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>120</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   size                                                ids m_name   \n",
       "0   280  [4299, 1057, 62, 29412, 62, 41989, 7, 9288, 62...     c1  \\\n",
       "\n",
       "                                                code ast_errors  n_ast_errors   \n",
       "0  def run_python_tests(test_modules, parallelism...         []             0  \\\n",
       "\n",
       "   ast_levels  n_whitespaces_  complexity  nloc  token_counts  n_ast_nodes  \n",
       "0          13              67           7    15           120          154  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing data loads\n",
    "data_pd = pd.read_json( params['testbeds_path'] )\n",
    "data_pd.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "968449\n"
     ]
    }
   ],
   "source": [
    "print(len(data_pd.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "968449"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pd.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uploading Model UnderAnalisys\n",
    "name, tokenizer, model = init_model_args(\n",
    "    current_case = params['codemodel'], \n",
    "    returnModel = True #[WARNING!] Check the parameters before calling it. \n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Logits From a Given Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating data tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_prompts_ids = data_pd[data_pd['m_name']==params['codemodel']]['ids'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50971"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_prompts_ids.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Casting Integers to Tensor Integers. Make sure the tesor is created in a device\n",
    "#We ignored the parameter attention_mask since we are not using masking here [https://huggingface.co/transformers/v4.10.1/glossary.html#attention-mask]\n",
    "\n",
    "tf_input_ids = [torch.tensor(  input_ids, dtype = torch.int, device=device ) for input_ids in filtered_prompts_ids ]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Model to Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTNeoForCausalLM(\n",
       "  (transformer): GPTNeoModel(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(2048, 768)\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to( device ) #WARNING, Verify the device before assigning to memory"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executing Logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def create_folder(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit_extractor(batch, input, from_index=0):\n",
    "    \"\"\"\n",
    "    Output is the class CausalLMOutputWithPast (https://huggingface.co/transformers/v4.10.1/main_classes/output.html?highlight=causallmoutputwithpast)\"\n",
    "    logits (torch.FloatTensor of shape (batch_size, sequence_length, config.vocab_size)) – Prediction scores of the language modeling head (scores for each vocabulary token before SoftMax).\n",
    "    The expression i.type(torch.LongTensor).to(device) is for casting labels for the loss\n",
    "    \"\"\"\n",
    "    #Output is in CausalLMOutputWithPast\n",
    "    CODEMODEL =  params['codemodel']\n",
    "    create_folder(params['numpy_files_logits_path'])\n",
    "    for idx, n in enumerate( range( from_index, len(input), batch) ):\n",
    "        output = [ model( \n",
    "            input_ids = i, \n",
    "            labels = i.to(torch.long).to(device) \n",
    "            ) for i in input[n:n+batch] ] #Labels must be provided to compute loss\n",
    "    \n",
    "        output_logits = [ o.logits.detach().to('cpu').numpy() for o in output ]  #Logits Extraction\n",
    "        output_loss = np.array([ o.loss.detach().to('cpu').numpy() for o in output ])  #Language modeling loss (for next-token prediction).\n",
    "\n",
    "        #Saving Callbacks\n",
    "        current_batch = idx + (from_index//batch)\n",
    "        for jdx, o_logits in enumerate( output_logits ):\n",
    "            np.save( params['numpy_files_logits_path']+ '/'+ f'logits_tensor[{jdx+n}]_batch[{current_batch}]_model[{CODEMODEL}].npy', o_logits) #Saving LOGITS\n",
    "        np.save( params['numpy_files_logits_path']+ '/'+f'loss_batch[{current_batch}]_model[{CODEMODEL}].npy', output_loss) #Saving LOSS\n",
    "        \n",
    "        logging.info(f\"Batch [{current_batch}] Completed\")\n",
    "        \n",
    "        #Memory Released\n",
    "        for out in output:\n",
    "            del out.logits\n",
    "            del out.loss\n",
    "            del out\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "        for out in output_logits:\n",
    "            del out\n",
    "            torch.cuda.empty_cache()\n",
    "        for out in output_loss:\n",
    "            del out\n",
    "            torch.cuda.empty_cache()\n",
    "        del output\n",
    "        del output_logits\n",
    "        del output_loss\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Not enough free space to write 38999432 bytes",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/CodeSyntaxConcept/experimental_notebooks/1_logits_extractor_gpu_v1.2.ipynb Cell 27\u001b[0m in \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f736372617463682f64616e69656c72632f436f646553796e746178436f6e63657074222c226c6f63616c446f636b6572223a66616c73652c2273657474696e6773223a7b22686f7374223a227373683a2f2f53656d6572755f5432227d2c22636f6e66696746696c65223a7b22246d6964223a312c2270617468223a222f736372617463682f64616e69656c72632f436f646553796e746178436f6e636570742f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a227673636f64652d66696c65486f7374227d7d/workspaces/CodeSyntaxConcept/experimental_notebooks/1_logits_extractor_gpu_v1.2.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m## ACTUAL EXPERIMENT\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f736372617463682f64616e69656c72632f436f646553796e746178436f6e63657074222c226c6f63616c446f636b6572223a66616c73652c2273657474696e6773223a7b22686f7374223a227373683a2f2f53656d6572755f5432227d2c22636f6e66696746696c65223a7b22246d6964223a312c2270617468223a222f736372617463682f64616e69656c72632f436f646553796e746178436f6e636570742f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a227673636f64652d66696c65486f7374227d7d/workspaces/CodeSyntaxConcept/experimental_notebooks/1_logits_extractor_gpu_v1.2.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m## TIME AND MEMORY CONSUMING\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f736372617463682f64616e69656c72632f436f646553796e746178436f6e63657074222c226c6f63616c446f636b6572223a66616c73652c2273657474696e6773223a7b22686f7374223a227373683a2f2f53656d6572755f5432227d2c22636f6e66696746696c65223a7b22246d6964223a312c2270617468223a222f736372617463682f64616e69656c72632f436f646553796e746178436f6e636570742f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a227673636f64652d66696c65486f7374227d7d/workspaces/CodeSyntaxConcept/experimental_notebooks/1_logits_extractor_gpu_v1.2.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m logit_extractor(\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f736372617463682f64616e69656c72632f436f646553796e746178436f6e63657074222c226c6f63616c446f636b6572223a66616c73652c2273657474696e6773223a7b22686f7374223a227373683a2f2f53656d6572755f5432227d2c22636f6e66696746696c65223a7b22246d6964223a312c2270617468223a222f736372617463682f64616e69656c72632f436f646553796e746178436f6e636570742f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a227673636f64652d66696c65486f7374227d7d/workspaces/CodeSyntaxConcept/experimental_notebooks/1_logits_extractor_gpu_v1.2.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     batch \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m, \n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f736372617463682f64616e69656c72632f436f646553796e746178436f6e63657074222c226c6f63616c446f636b6572223a66616c73652c2273657474696e6773223a7b22686f7374223a227373683a2f2f53656d6572755f5432227d2c22636f6e66696746696c65223a7b22246d6964223a312c2270617468223a222f736372617463682f64616e69656c72632f436f646553796e746178436f6e636570742f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a227673636f64652d66696c65486f7374227d7d/workspaces/CodeSyntaxConcept/experimental_notebooks/1_logits_extractor_gpu_v1.2.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39minput\u001b[39;49m \u001b[39m=\u001b[39;49m tf_input_ids, \n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f736372617463682f64616e69656c72632f436f646553796e746178436f6e63657074222c226c6f63616c446f636b6572223a66616c73652c2273657474696e6773223a7b22686f7374223a227373683a2f2f53656d6572755f5432227d2c22636f6e66696746696c65223a7b22246d6964223a312c2270617468223a222f736372617463682f64616e69656c72632f436f646553796e746178436f6e636570742f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a227673636f64652d66696c65486f7374227d7d/workspaces/CodeSyntaxConcept/experimental_notebooks/1_logits_extractor_gpu_v1.2.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     from_index\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f736372617463682f64616e69656c72632f436f646553796e746178436f6e63657074222c226c6f63616c446f636b6572223a66616c73652c2273657474696e6773223a7b22686f7374223a227373683a2f2f53656d6572755f5432227d2c22636f6e66696746696c65223a7b22246d6964223a312c2270617468223a222f736372617463682f64616e69656c72632f436f646553796e746178436f6e636570742f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a227673636f64652d66696c65486f7374227d7d/workspaces/CodeSyntaxConcept/experimental_notebooks/1_logits_extractor_gpu_v1.2.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m )\n",
      "\u001b[1;32m/workspaces/CodeSyntaxConcept/experimental_notebooks/1_logits_extractor_gpu_v1.2.ipynb Cell 27\u001b[0m in \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f736372617463682f64616e69656c72632f436f646553796e746178436f6e63657074222c226c6f63616c446f636b6572223a66616c73652c2273657474696e6773223a7b22686f7374223a227373683a2f2f53656d6572755f5432227d2c22636f6e66696746696c65223a7b22246d6964223a312c2270617468223a222f736372617463682f64616e69656c72632f436f646553796e746178436f6e636570742f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a227673636f64652d66696c65486f7374227d7d/workspaces/CodeSyntaxConcept/experimental_notebooks/1_logits_extractor_gpu_v1.2.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m current_batch \u001b[39m=\u001b[39m idx \u001b[39m+\u001b[39m (from_index\u001b[39m/\u001b[39m\u001b[39m/\u001b[39mbatch)\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f736372617463682f64616e69656c72632f436f646553796e746178436f6e63657074222c226c6f63616c446f636b6572223a66616c73652c2273657474696e6773223a7b22686f7374223a227373683a2f2f53656d6572755f5432227d2c22636f6e66696746696c65223a7b22246d6964223a312c2270617468223a222f736372617463682f64616e69656c72632f436f646553796e746178436f6e636570742f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a227673636f64652d66696c65486f7374227d7d/workspaces/CodeSyntaxConcept/experimental_notebooks/1_logits_extractor_gpu_v1.2.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mfor\u001b[39;00m jdx, o_logits \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m( output_logits ):\n\u001b[0;32m---> <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f736372617463682f64616e69656c72632f436f646553796e746178436f6e63657074222c226c6f63616c446f636b6572223a66616c73652c2273657474696e6773223a7b22686f7374223a227373683a2f2f53656d6572755f5432227d2c22636f6e66696746696c65223a7b22246d6964223a312c2270617468223a222f736372617463682f64616e69656c72632f436f646553796e746178436f6e636570742f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a227673636f64652d66696c65486f7374227d7d/workspaces/CodeSyntaxConcept/experimental_notebooks/1_logits_extractor_gpu_v1.2.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m     np\u001b[39m.\u001b[39;49msave( params[\u001b[39m'\u001b[39;49m\u001b[39mnumpy_files_logits_path\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m+\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39m/\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m+\u001b[39;49m \u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mlogits_tensor[\u001b[39;49m\u001b[39m{\u001b[39;49;00mjdx\u001b[39m+\u001b[39;49mn\u001b[39m}\u001b[39;49;00m\u001b[39m]_batch[\u001b[39;49m\u001b[39m{\u001b[39;49;00mcurrent_batch\u001b[39m}\u001b[39;49;00m\u001b[39m]_model[\u001b[39;49m\u001b[39m{\u001b[39;49;00mCODEMODEL\u001b[39m}\u001b[39;49;00m\u001b[39m].npy\u001b[39;49m\u001b[39m'\u001b[39;49m, o_logits) \u001b[39m#Saving LOGITS\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f736372617463682f64616e69656c72632f436f646553796e746178436f6e63657074222c226c6f63616c446f636b6572223a66616c73652c2273657474696e6773223a7b22686f7374223a227373683a2f2f53656d6572755f5432227d2c22636f6e66696746696c65223a7b22246d6964223a312c2270617468223a222f736372617463682f64616e69656c72632f436f646553796e746178436f6e636570742f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a227673636f64652d66696c65486f7374227d7d/workspaces/CodeSyntaxConcept/experimental_notebooks/1_logits_extractor_gpu_v1.2.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m np\u001b[39m.\u001b[39msave( params[\u001b[39m'\u001b[39m\u001b[39mnumpy_files_logits_path\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39m\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mloss_batch[\u001b[39m\u001b[39m{\u001b[39;00mcurrent_batch\u001b[39m}\u001b[39;00m\u001b[39m]_model[\u001b[39m\u001b[39m{\u001b[39;00mCODEMODEL\u001b[39m}\u001b[39;00m\u001b[39m].npy\u001b[39m\u001b[39m'\u001b[39m, output_loss) \u001b[39m#Saving LOSS\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f736372617463682f64616e69656c72632f436f646553796e746178436f6e63657074222c226c6f63616c446f636b6572223a66616c73652c2273657474696e6773223a7b22686f7374223a227373683a2f2f53656d6572755f5432227d2c22636f6e66696746696c65223a7b22246d6964223a312c2270617468223a222f736372617463682f64616e69656c72632f436f646553796e746178436f6e636570742f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a227673636f64652d66696c65486f7374227d7d/workspaces/CodeSyntaxConcept/experimental_notebooks/1_logits_extractor_gpu_v1.2.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m logging\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBatch [\u001b[39m\u001b[39m{\u001b[39;00mcurrent_batch\u001b[39m}\u001b[39;00m\u001b[39m] Completed\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36msave\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/numpy/lib/npyio.py:502\u001b[0m, in \u001b[0;36msave\u001b[0;34m(file, arr, allow_pickle, fix_imports)\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[39mwith\u001b[39;00m file_ctx \u001b[39mas\u001b[39;00m fid:\n\u001b[1;32m    501\u001b[0m     arr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masanyarray(arr)\n\u001b[0;32m--> 502\u001b[0m     \u001b[39mformat\u001b[39;49m\u001b[39m.\u001b[39;49mwrite_array(fid, arr, allow_pickle\u001b[39m=\u001b[39;49mallow_pickle,\n\u001b[1;32m    503\u001b[0m                        pickle_kwargs\u001b[39m=\u001b[39;49m\u001b[39mdict\u001b[39;49m(fix_imports\u001b[39m=\u001b[39;49mfix_imports))\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/numpy/lib/format.py:689\u001b[0m, in \u001b[0;36mwrite_array\u001b[0;34m(fp, array, version, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    688\u001b[0m     \u001b[39mif\u001b[39;00m isfileobj(fp):\n\u001b[0;32m--> 689\u001b[0m         array\u001b[39m.\u001b[39;49mtofile(fp)\n\u001b[1;32m    690\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    691\u001b[0m         \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m numpy\u001b[39m.\u001b[39mnditer(\n\u001b[1;32m    692\u001b[0m                 array, flags\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mexternal_loop\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mbuffered\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mzerosize_ok\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m    693\u001b[0m                 buffersize\u001b[39m=\u001b[39mbuffersize, order\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mC\u001b[39m\u001b[39m'\u001b[39m):\n",
      "\u001b[0;31mOSError\u001b[0m: Not enough free space to write 38999432 bytes"
     ]
    }
   ],
   "source": [
    "## ACTUAL EXPERIMENT\n",
    "## TIME AND MEMORY CONSUMING\n",
    "logit_extractor(\n",
    "    batch = 1, \n",
    "    input = tf_input_ids, \n",
    "    from_index=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logit_extractor(batch =2, input= input_ids_list[:2]) #<---- [WARNING TIME AND MEMORY CONSUMING]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_logits = np.load('../data/callbacks/logits_tensor[0]_batch[0].npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assert output_logits.shape[0] == len(input_ids_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_loss = np.load('../data/callbacks/loss_batch[0].npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
