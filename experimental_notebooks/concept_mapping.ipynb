{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6130719e",
   "metadata": {},
   "source": [
    "# Step 0 - Install Tree Sitter Languages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f70ca289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "fatal: destination path 'tree-sitter-java' already exists and is not an empty directory.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "fatal: destination path 'tree-sitter-python' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/tree-sitter/tree-sitter-java.git\n",
    "!git clone https://github.com/tree-sitter/tree-sitter-python.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28de2f9",
   "metadata": {},
   "source": [
    "# Step 1 - Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a9a53d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2TokenizerFast\n",
    "from CodeSyntaxConcept.core.parsers.tree_sitter_parser import TreeSitterParser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc51d143",
   "metadata": {},
   "source": [
    "# Step 2 - Concept Location - Using Model Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fe03d681",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Select a Tokenizer (It has to be PreTrainedTokenizerFast)\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1a169fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        token   node_type     parent_node_type\n",
      "0         def         def  function_definition\n",
      "1    multiply  identifier  function_definition\n",
      "2           _  identifier  function_definition\n",
      "3           n  identifier  function_definition\n",
      "4      umbers  identifier  function_definition\n",
      "5           (           (           parameters\n",
      "6           a  identifier           parameters\n",
      "7           ,           ,           parameters\n",
      "8           b  identifier           parameters\n",
      "9          ):           )           parameters\n",
      "10         \\n        Node                 None\n",
      "11          #     comment  function_definition\n",
      "12       mult     comment  function_definition\n",
      "13         ip     comment  function_definition\n",
      "14         ly     comment  function_definition\n",
      "15        two     comment  function_definition\n",
      "16    numbers     comment  function_definition\n",
      "17        and     comment  function_definition\n",
      "18     return     comment  function_definition\n",
      "19        the     comment  function_definition\n",
      "20     result     comment  function_definition\n",
      "21         \\n        Node                 None\n",
      "22     return      return     return_statement\n",
      "23          a  identifier      binary_operator\n",
      "24          *           *      binary_operator\n",
      "25          b  identifier      binary_operator\n"
     ]
    }
   ],
   "source": [
    "source_code = \"def multiply_numbers(a,b):\\n #multiply two numbers and return the result\\n return a*b\"\n",
    "source_code_concepts = TreeSitterParser.process_model_source_code(source_code, 'python', tokenizer)\n",
    "print(source_code_concepts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa20a0d",
   "metadata": {},
   "source": [
    "# Step 2 - Concept Location - Using AST Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f5b950ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          token   node_type  \\\n",
      "0                                           def         def   \n",
      "1                              multiply_numbers  identifier   \n",
      "2                                             (           (   \n",
      "3                                             a  identifier   \n",
      "4                                             ,           ,   \n",
      "5                                             b  identifier   \n",
      "6                                             )           )   \n",
      "7                                             :           :   \n",
      "8   #multiply two numbers and return the result     comment   \n",
      "9                                        return      return   \n",
      "10                                            a  identifier   \n",
      "11                                            *           *   \n",
      "12                                            b  identifier   \n",
      "\n",
      "       parent_node_type  \n",
      "0   function_definition  \n",
      "1   function_definition  \n",
      "2            parameters  \n",
      "3            parameters  \n",
      "4            parameters  \n",
      "5            parameters  \n",
      "6            parameters  \n",
      "7   function_definition  \n",
      "8   function_definition  \n",
      "9      return_statement  \n",
      "10      binary_operator  \n",
      "11      binary_operator  \n",
      "12      binary_operator  \n"
     ]
    }
   ],
   "source": [
    "source_code = \"def multiply_numbers(a,b):\\n #multiply two numbers and return the result\\n return a*b\"\n",
    "source_code_concepts = TreeSitterParser.process_source_code(source_code, 'python')\n",
    "print(source_code_concepts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cea75ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
