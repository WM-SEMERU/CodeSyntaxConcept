{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/66116155/how-to-tell-pytorch-which-cuda-version-to-take\n",
    "# https://github.com/pytorch/pytorch/issues/75992\n",
    "\n",
    "# Previous Versions of Pytorch avaiable here: https://pytorch.org/get-started/previous-versions/\n",
    "#! pip install --upgrade torch==1.11.0 torchvision==0.12.0 torchaudio==0.11.0\n",
    "#! pip install --upgrade torch==1.12.0 torchvision==0.13.0 torchaudio==0.12.0\n",
    "#! pip install --upgrade torch==1.12.1 --extra-index-url https://download.pytorch.org/whl/cu113 #<--This version works for CUDA 11.4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from statistics import NormalDist\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.1+cu113'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__\n",
    "#'1.12.0+cu111'\n",
    "#'1.9.0+cu111' This is the version by default\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#physical_devices = tf.config.list_physical_devices('CPU')\n",
    "physical_devices = tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)\n",
    "physical_devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n",
    "#device = 'cpu'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0510, 0.3781, 0.2525],\n",
      "        [0.0787, 0.9913, 0.4952],\n",
      "        [0.6603, 0.7436, 0.1571],\n",
      "        [0.1668, 0.8830, 0.7608],\n",
      "        [0.5752, 0.5757, 0.8556]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "x = torch.rand(5, 3, \n",
    "               device=device#'cpu'\n",
    "               )\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deleting tensor to free memory\n",
    "del x\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Feb 18 01:55:31 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.103.01   Driver Version: 470.103.01   CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100-PCI...  Off  | 00000000:61:00.0 Off |                    0 |\n",
      "| N/A   31C    P0    35W / 250W |   1190MiB / 40536MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "#! conda install pytorch torchvision torchaudio cudatoolkit=10.1 -c pytorch\n",
    "#! pip3 install torch==1.7.0 torchvision==0.8.1 -f https://download.pytorch.org/whl/cu101/torch_stable.html\n",
    "#! pip install tensorflow\n",
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logits Extractor\n",
    ">\n",
    "> Extracting Tensor Logits from a given Neural Code Model @danaderp\n",
    ">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Available Datasets\n",
    "# Case1: codesearch_tesbed_EleutherAI-gpt-neo-125M_10000 for the model 'EleutherAI/gpt-neo-125M' \n",
    "# Case2: codesearch_tesbed_EleutherAI-gpt-neo-2.7B_10000 for the model 'EleutherAI/gpt-neo-2.7B' <-- MEMORY CONSTRAINTS\n",
    "# Case3: codesearch_tesbed_EleutherAI-gpt-neo-1.3B_10000 for the model 'EleutherAI/gpt-neo-1.3B'\n",
    "# Case4: codesearch_tesbed_microsoft-CodeGPT-small-py_10000 for the model 'microsoft/CodeGPT-small-py-adaptedGPT2'\n",
    "def params(): \n",
    "    return {\n",
    "            'big_table_path' : '../data/concept_tables/codesearch_tesbed_microsoft-CodeGPT-small-py_10000.csv',\n",
    "            'hf_model' : 'microsoft/CodeGPT-small-py-adaptedGPT2',\n",
    "            'model_name': 'CodeGPT-small-py_10000_',\n",
    "            'callbacks' : '../data/callbacks-CodeGPT-small-py_10000',\n",
    "            'batch': 1 \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/concept_tables/codesearch_tesbed_microsoft-CodeGPT-small-py_10000.csv'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pwd\n",
    "parameters = params()\n",
    "parameters['big_table_path']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pd = pd.read_csv( \n",
    "                      parameters['big_table_path'] , \n",
    "                      index_col=0\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_total_input_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>459.550200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>583.826137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>41.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>161.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>278.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>529.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>16454.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       model_total_input_ids\n",
       "count           10000.000000\n",
       "mean              459.550200\n",
       "std               583.826137\n",
       "min                41.000000\n",
       "25%               161.750000\n",
       "50%               278.000000\n",
       "75%               529.000000\n",
       "max             16454.000000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pd.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>whole_func_string</th>\n",
       "      <th>ast_concepts</th>\n",
       "      <th>model_tokenizer_concepts</th>\n",
       "      <th>model_input_ids</th>\n",
       "      <th>model_total_input_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>def find_function(self, context, funname):\\n  ...</td>\n",
       "      <td>[('def', 'def', 'function_definition'), ('find...</td>\n",
       "      <td>[(1336, 'def', 'function_definition'), (1766, ...</td>\n",
       "      <td>[1336, 1766, 65, 1590, 10, 270, 14, 1245, 14, ...</td>\n",
       "      <td>477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>def serialCmdPwdAuth(self, password_str):\\n   ...</td>\n",
       "      <td>[('def', 'def', 'function_definition'), ('seri...</td>\n",
       "      <td>[(1336, 'def', 'function_definition'), (2603, ...</td>\n",
       "      <td>[1336, 2603, 8644, 50, 2409, 3084, 10, 270, 14...</td>\n",
       "      <td>520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>def email(cls, invoice, kind):\\n        ''' Se...</td>\n",
       "      <td>[('def', 'def', 'function_definition'), ('emai...</td>\n",
       "      <td>[(1336, 'def', 'function_definition'), (3306, ...</td>\n",
       "      <td>[1336, 3306, 10, 1173, 14, 14699, 14, 4033, 29...</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>def resolve(cursor, key):\\n    \"\"\"\\n    Get en...</td>\n",
       "      <td>[('def', 'def', 'function_definition'), ('reso...</td>\n",
       "      <td>[(1336, 'def', 'function_definition'), (5179, ...</td>\n",
       "      <td>[1336, 5179, 10, 2882, 14, 570, 298, 201, 223,...</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>def _get_new_csv_writers(trans_title, meta_tit...</td>\n",
       "      <td>[('def', 'def', 'function_definition'), ('_get...</td>\n",
       "      <td>[(1336, 'def', 'function_definition'), (440, '...</td>\n",
       "      <td>[1336, 440, 344, 65, 1073, 65, 3046, 65, 23630...</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   whole_func_string  \\\n",
       "0  def find_function(self, context, funname):\\n  ...   \n",
       "1  def serialCmdPwdAuth(self, password_str):\\n   ...   \n",
       "2  def email(cls, invoice, kind):\\n        ''' Se...   \n",
       "3  def resolve(cursor, key):\\n    \"\"\"\\n    Get en...   \n",
       "4  def _get_new_csv_writers(trans_title, meta_tit...   \n",
       "\n",
       "                                        ast_concepts  \\\n",
       "0  [('def', 'def', 'function_definition'), ('find...   \n",
       "1  [('def', 'def', 'function_definition'), ('seri...   \n",
       "2  [('def', 'def', 'function_definition'), ('emai...   \n",
       "3  [('def', 'def', 'function_definition'), ('reso...   \n",
       "4  [('def', 'def', 'function_definition'), ('_get...   \n",
       "\n",
       "                            model_tokenizer_concepts  \\\n",
       "0  [(1336, 'def', 'function_definition'), (1766, ...   \n",
       "1  [(1336, 'def', 'function_definition'), (2603, ...   \n",
       "2  [(1336, 'def', 'function_definition'), (3306, ...   \n",
       "3  [(1336, 'def', 'function_definition'), (5179, ...   \n",
       "4  [(1336, 'def', 'function_definition'), (440, '...   \n",
       "\n",
       "                                     model_input_ids  model_total_input_ids  \n",
       "0  [1336, 1766, 65, 1590, 10, 270, 14, 1245, 14, ...                    477  \n",
       "1  [1336, 2603, 8644, 50, 2409, 3084, 10, 270, 14...                    520  \n",
       "2  [1336, 3306, 10, 1173, 14, 14699, 14, 4033, 29...                    108  \n",
       "3  [1336, 5179, 10, 2882, 14, 570, 298, 201, 223,...                    178  \n",
       "4  [1336, 440, 344, 65, 1073, 65, 3046, 65, 23630...                    157  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pd.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pd_to_compare = pd.read_csv( \n",
    "                      '../data/concept_tables/codesearch_tesbed_EleutherAI-gpt-neo-1.3B_10000.csv' , \n",
    "                      index_col=0\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>whole_func_string</th>\n",
       "      <th>ast_concepts</th>\n",
       "      <th>model_tokenizer_concepts</th>\n",
       "      <th>model_input_ids</th>\n",
       "      <th>model_total_input_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>def child_object(self):\\n        \"\"\" Get Task ...</td>\n",
       "      <td>[('def', 'def', 'function_definition'), ('chil...</td>\n",
       "      <td>[(4299, 'def', 'function_definition'), (1200, ...</td>\n",
       "      <td>[4299, 1200, 62, 15252, 7, 944, 2599, 198, 220...</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>def manual_run(turn_into_run=True, store_meta_...</td>\n",
       "      <td>[('def', 'def', 'function_definition'), ('manu...</td>\n",
       "      <td>[(4299, 'def', 'function_definition'), (10107,...</td>\n",
       "      <td>[4299, 10107, 62, 5143, 7, 15344, 62, 20424, 6...</td>\n",
       "      <td>484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>def connectionLost(self, reason):\\n        \"\"\"...</td>\n",
       "      <td>[('def', 'def', 'function_definition'), ('conn...</td>\n",
       "      <td>[(4299, 'def', 'function_definition'), (4637, ...</td>\n",
       "      <td>[4299, 4637, 31042, 7, 944, 11, 1738, 2599, 19...</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>def as_thing_description(self):\\n        \"\"\"\\n...</td>\n",
       "      <td>[('def', 'def', 'function_definition'), ('as_t...</td>\n",
       "      <td>[(4299, 'def', 'function_definition'), (355, '...</td>\n",
       "      <td>[4299, 355, 62, 1197, 62, 11213, 7, 944, 2599,...</td>\n",
       "      <td>1080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>def sample_uniform_initial_state(parameter,\\n ...</td>\n",
       "      <td>[('def', 'def', 'function_definition'), ('samp...</td>\n",
       "      <td>[(4299, 'def', 'function_definition'), (6291, ...</td>\n",
       "      <td>[4299, 6291, 62, 403, 6933, 62, 36733, 62, 521...</td>\n",
       "      <td>570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   whole_func_string  \\\n",
       "0  def child_object(self):\\n        \"\"\" Get Task ...   \n",
       "1  def manual_run(turn_into_run=True, store_meta_...   \n",
       "2  def connectionLost(self, reason):\\n        \"\"\"...   \n",
       "3  def as_thing_description(self):\\n        \"\"\"\\n...   \n",
       "4  def sample_uniform_initial_state(parameter,\\n ...   \n",
       "\n",
       "                                        ast_concepts  \\\n",
       "0  [('def', 'def', 'function_definition'), ('chil...   \n",
       "1  [('def', 'def', 'function_definition'), ('manu...   \n",
       "2  [('def', 'def', 'function_definition'), ('conn...   \n",
       "3  [('def', 'def', 'function_definition'), ('as_t...   \n",
       "4  [('def', 'def', 'function_definition'), ('samp...   \n",
       "\n",
       "                            model_tokenizer_concepts  \\\n",
       "0  [(4299, 'def', 'function_definition'), (1200, ...   \n",
       "1  [(4299, 'def', 'function_definition'), (10107,...   \n",
       "2  [(4299, 'def', 'function_definition'), (4637, ...   \n",
       "3  [(4299, 'def', 'function_definition'), (355, '...   \n",
       "4  [(4299, 'def', 'function_definition'), (6291, ...   \n",
       "\n",
       "                                     model_input_ids  model_total_input_ids  \n",
       "0  [4299, 1200, 62, 15252, 7, 944, 2599, 198, 220...                     92  \n",
       "1  [4299, 10107, 62, 5143, 7, 15344, 62, 20424, 6...                    484  \n",
       "2  [4299, 4637, 31042, 7, 944, 11, 1738, 2599, 19...                     94  \n",
       "3  [4299, 355, 62, 1197, 62, 11213, 7, 944, 2599,...                   1080  \n",
       "4  [4299, 6291, 62, 403, 6933, 62, 36733, 62, 521...                    570  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pd_to_compare.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip list\n",
    "#! pip install git+https://github.com/huggingface/transfomers.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer = AutoTokenizer.from_pretrained(\"Salesforce/codegen-2B-mono\")\n",
    "#tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-j-6B\")\n",
    "#generator = pipeline('text-generation', model='EleutherAI/gpt-neo-1.3B')\n",
    "#model = AutoModelForCausalLM.from_pretrained(\"EleutherAI/gpt-j-6B\")\n",
    "\n",
    "\n",
    "def testing_1():\n",
    "    # This is for 'EleutherAI/gpt-neo-125M'\n",
    "    tokenizer = AutoTokenizer.from_pretrained(parameters['hf_model'])\n",
    "    generator = pipeline(\n",
    "        'text-generation', \n",
    "        model= parameters['hf_model'] )\n",
    "    \n",
    "    #TEST: Example 1: generation\n",
    "    generator(\n",
    "        \"EleutherAI has\", \n",
    "        do_sample=True, \n",
    "        max_new_tokens=20, \n",
    "        pad_token_id = tokenizer.eos_token_id\n",
    "        )\n",
    "    \n",
    "    #TEST: Example 2: generation\n",
    "\n",
    "    generator( \n",
    "        data_pd.whole_func_string.values[0][:100], #<-- Code data\n",
    "        do_sample=True, \n",
    "        max_new_tokens=20,\n",
    "        pad_token_id = tokenizer.eos_token_id \n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Logits From a Given Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code works for GPT-Neo\n",
    "from transformers import GPTNeoForCausalLM, GPT2Tokenizer\n",
    "model = GPTNeoForCausalLM.from_pretrained( parameters['hf_model'] )\n",
    "tokenizer = GPT2Tokenizer.from_pretrained( parameters['hf_model'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'microsoft/CodeGPT-small-py-adaptedGPT2'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters['hf_model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "#This code works for CodeGPT\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(parameters['hf_model'])\n",
    "model = AutoModelForCausalLM.from_pretrained(parameters['hf_model'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer.get_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len( tokenizer.get_vocab() ) #todo an assert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prompts = data_pd.whole_func_string.values[:2]\n",
    "prompts = data_pd.whole_func_string.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def find_function(self, context, funname):\\n        \"\"\"Find a function in the given context by name.\\n\\n        This function will first search the list of builtins and if the\\n        desired function is not a builtin, it will continue to search\\n        the given context.\\n\\n        Args:\\n            context (object): A dict or class that is a typedargs context\\n            funname (str): The name of the function to find\\n\\n        Returns:\\n            callable: The found function.\\n        \"\"\"\\n\\n        if funname in self.builtins:\\n            return self.builtins[funname]\\n\\n        func = None\\n        if isinstance(context, dict):\\n            if funname in context:\\n                func = context[funname]\\n\\n                #Allowed lazy loading of functions\\n                if isinstance(func, str):\\n                    func = self._deferred_add(func)\\n                    context[funname] = func\\n        elif hasattr(context, funname):\\n            func = getattr(context, funname)\\n\\n        if func is None:\\n            raise NotFoundError(\"Function not found\", function=funname)\\n\\n        return func'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making space for the tensors\n",
    "#input_ids_list = tokenizer.batch_encode_plus( prompts ) #<-- Do not return as a Tensor\n",
    "input_ids_list = tokenizer.batch_encode_plus( list(prompts) ) #<-- Do not return as a Tensor [cast to list]\n",
    "#input_ids_list = tokenizer.batch_encode_plus( prompts , return_tensors=\"pt\") #<-- \"pt\" returns as a Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Casting Integers to Tensor Integers. Make sure the tesor is created in a device\n",
    "#We ignored the parameter attention_mask since we are not using masking here [https://huggingface.co/transformers/v4.10.1/glossary.html#attention-mask]\n",
    "\n",
    "#input_ids_list = [torch.Tensor( np.array( input_ids ) ) for input_ids in input_ids_list.input_ids if len(input_ids) <= 2048]\n",
    "#input_ids_list = [ input_ids for input_ids in input_ids_list.input_ids if len(input_ids) <= 2048]\n",
    "input_ids_list = [torch.tensor(  input_ids, dtype = torch.int, device=device ) for input_ids in input_ids_list.input_ids if len(input_ids) <= 2048]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4299,  1064,    62,  8818,     7,   944,    11,  4732,    11,  1257,\n",
       "         3672,  2599,   198,   220,   220,   220,   220,   220,   220,   220,\n",
       "        37227, 16742,   257,  2163,   287,   262,  1813,  4732,   416,  1438,\n",
       "           13,   628,   220,   220,   220,   220,   220,   220,   220,   770,\n",
       "         2163,   481,   717,  2989,   262,  1351,   286,  3170,  1040,   290,\n",
       "          611,   262,   198,   220,   220,   220,   220,   220,   220,   220,\n",
       "        10348,  2163,   318,   407,   257,  3170,   259,    11,   340,   481,\n",
       "         2555,   284,  2989,   198,   220,   220,   220,   220,   220,   220,\n",
       "          220,   262,  1813,  4732,    13,   628,   220,   220,   220,   220,\n",
       "          220,   220,   220,   943, 14542,    25,   198,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,  4732,   357,\n",
       "        15252,  2599,   317,  8633,   393,  1398,   326,   318,   257, 25683,\n",
       "        22046,  4732,   198,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,  1257,  3672,   357,  2536,  2599,   383,\n",
       "         1438,   286,   262,  2163,   284,  1064,   628,   220,   220,   220,\n",
       "          220,   220,   220,   220, 16409,    25,   198,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   869,   540,\n",
       "           25,   383,  1043,  2163,    13,   198,   220,   220,   220,   220,\n",
       "          220,   220,   220, 37227,   628,   220,   220,   220,   220,   220,\n",
       "          220,   220,   611,  1257,  3672,   287,  2116,    13, 18780,  1040,\n",
       "           25,   198,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,  1441,  2116,    13, 18780,  1040,    58, 12543,\n",
       "         3672,    60,   628,   220,   220,   220,   220,   220,   220,   220,\n",
       "        25439,   796,  6045,   198,   220,   220,   220,   220,   220,   220,\n",
       "          220,   611,   318, 39098,     7, 22866,    11,  8633,  2599,   198,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   611,  1257,  3672,   287,  4732,    25,   198,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220, 25439,   796,  4732,    58, 12543,  3672,    60,\n",
       "          628,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,  1303,  3237,  6972, 16931,\n",
       "        11046,   286,  5499,   198,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   611,\n",
       "          318, 39098,     7, 20786,    11,   965,  2599,   198,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220, 25439,   796,  2116,\n",
       "        13557,  4299, 17436,    62,  2860,     7, 20786,     8,   198,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,  4732,    58,\n",
       "        12543,  3672,    60,   796, 25439,   198,   220,   220,   220,   220,\n",
       "          220,   220,   220,  1288,   361,   468, 35226,     7, 22866,    11,\n",
       "         1257,  3672,  2599,   198,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220, 25439,   796,   651, 35226,     7,\n",
       "        22866,    11,  1257,  3672,     8,   628,   220,   220,   220,   220,\n",
       "          220,   220,   220,   611, 25439,   318,  6045,    25,   198,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "         5298,  1892, 21077, 12331,  7203, 22203,   407,  1043,  1600,  2163,\n",
       "           28, 12543,  3672,     8,   628,   220,   220,   220,   220,   220,\n",
       "          220,   220,  1441, 25439], device='cuda:0', dtype=torch.int32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9726 10000\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [56], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#It should be same size\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(input_ids_list),\u001b[39mlen\u001b[39m(prompts))\n\u001b[0;32m----> 3\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(input_ids_list) \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(prompts)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#It should be same size\n",
    "print(len(input_ids_list),len(prompts))\n",
    "assert len(input_ids_list) == len(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[4299, 37773, 62, 17566, 7, 18982, 62, 11600, 2599, 198, 220, 220, 220, 37227, 65, 2414, 12, 12685, 4147, 4263, 287, 257, 3359, 12984, 5794, 8633, 198, 220, 220, 220, 220, 198, 220, 220, 220, 8673, 428, 815, 307, 12118, 287, 33918, 62, 27773, 2346, 30, 198, 220, 220, 220, 220, 198, 220, 220, 220, 40117, 198, 220, 220, 220, 24200, 438, 198, 220, 220, 220, 220, 198, 220, 220, 220, 5794, 62, 11600, 1058, 8633, 198, 220, 220, 220, 220, 220, 220, 220, 317, 22155, 286, 3359, 1366, 1994, 276, 416, 285, 524, 12, 4906, 198, 220, 220, 220, 220, 198, 220, 220, 220, 16409, 198, 220, 220, 220, 35656, 198, 220, 220, 220, 220, 198, 220, 220, 220, 5794, 62, 11600, 1058, 8633, 198, 220, 220, 220, 220, 220, 220, 220, 317, 4866, 286, 262, 976, 22155, 11, 198, 220, 220, 220, 220, 220, 220, 220, 475, 13934, 2939, 1366, 19203, 9060, 14, 11134, 6, 393, 705, 9060, 14, 73, 22071, 11537, 198, 220, 220, 220, 220, 220, 220, 220, 318, 2779, 2414, 12, 12685, 9043, 13, 198, 220, 220, 220, 220, 198, 220, 220, 220, 37227, 198, 220, 220, 220, 30240, 796, 5794, 62, 11600, 13, 30073, 3419, 198, 220, 220, 220, 279, 782, 7890, 796, 5794, 62, 11600, 13, 1136, 10786, 9060, 14, 11134, 11537, 198, 220, 220, 220, 611, 318, 39098, 7, 11134, 7890, 11, 9881, 8, 290, 279, 782, 7890, 58, 25, 23, 60, 6624, 36182, 25, 198, 220, 220, 220, 220, 220, 220, 220, 30240, 17816, 9060, 14, 11134, 20520, 796, 2207, 375, 395, 1806, 7, 11134, 7890, 737, 12501, 1098, 10786, 292, 979, 72, 11537, 198, 220, 220, 220, 474, 22071, 7890, 796, 5794, 62, 11600, 13, 1136, 10786, 9060, 14, 73, 22071, 11537, 198, 220, 220, 220, 611, 318, 39098, 7, 73, 22071, 7890, 11, 9881, 8, 290, 474, 22071, 7890, 58, 25, 17, 60, 6624, 48561, 25, 198, 220, 220, 220, 220, 220, 220, 220, 30240, 17816, 9060, 14, 73, 22071, 20520, 796, 2207, 375, 395, 1806, 7, 73, 22071, 7890, 737, 12501, 1098, 10786, 292, 979, 72, 11537, 198, 220, 220, 220, 1441, 30240]'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pd.model_input_ids.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4299, 37773,    62, 17566,     7, 18982,    62, 11600,  2599,   198,\n",
       "          220,   220,   220, 37227,    65,  2414,    12, 12685,  4147,  4263,\n",
       "          287,   257,  3359, 12984,  5794,  8633,   198,   220,   220,   220,\n",
       "          220,   198,   220,   220,   220,  8673,   428,   815,   307, 12118,\n",
       "          287, 33918,    62, 27773,  2346,    30,   198,   220,   220,   220,\n",
       "          220,   198,   220,   220,   220, 40117,   198,   220,   220,   220,\n",
       "        24200,   438,   198,   220,   220,   220,   220,   198,   220,   220,\n",
       "          220,  5794,    62, 11600,  1058,  8633,   198,   220,   220,   220,\n",
       "          220,   220,   220,   220,   317, 22155,   286,  3359,  1366,  1994,\n",
       "          276,   416,   285,   524,    12,  4906,   198,   220,   220,   220,\n",
       "          220,   198,   220,   220,   220, 16409,   198,   220,   220,   220,\n",
       "        35656,   198,   220,   220,   220,   220,   198,   220,   220,   220,\n",
       "         5794,    62, 11600,  1058,  8633,   198,   220,   220,   220,   220,\n",
       "          220,   220,   220,   317,  4866,   286,   262,   976, 22155,    11,\n",
       "          198,   220,   220,   220,   220,   220,   220,   220,   475, 13934,\n",
       "         2939,  1366, 19203,  9060,    14, 11134,     6,   393,   705,  9060,\n",
       "           14,    73, 22071, 11537,   198,   220,   220,   220,   220,   220,\n",
       "          220,   220,   318,  2779,  2414,    12, 12685,  9043,    13,   198,\n",
       "          220,   220,   220,   220,   198,   220,   220,   220, 37227,   198,\n",
       "          220,   220,   220, 30240,   796,  5794,    62, 11600,    13, 30073,\n",
       "         3419,   198,   220,   220,   220,   279,   782,  7890,   796,  5794,\n",
       "           62, 11600,    13,  1136, 10786,  9060,    14, 11134, 11537,   198,\n",
       "          220,   220,   220,   611,   318, 39098,     7, 11134,  7890,    11,\n",
       "         9881,     8,   290,   279,   782,  7890,    58,    25,    23,    60,\n",
       "         6624, 36182,    25,   198,   220,   220,   220,   220,   220,   220,\n",
       "          220, 30240, 17816,  9060,    14, 11134, 20520,   796,  2207,   375,\n",
       "          395,  1806,     7, 11134,  7890,   737, 12501,  1098, 10786,   292,\n",
       "          979,    72, 11537,   198,   220,   220,   220,   474, 22071,  7890,\n",
       "          796,  5794,    62, 11600,    13,  1136, 10786,  9060,    14,    73,\n",
       "        22071, 11537,   198,   220,   220,   220,   611,   318, 39098,     7,\n",
       "           73, 22071,  7890,    11,  9881,     8,   290,   474, 22071,  7890,\n",
       "           58,    25,    17,    60,  6624, 48561,    25,   198,   220,   220,\n",
       "          220,   220,   220,   220,   220, 30240, 17816,  9060,    14,    73,\n",
       "        22071, 20520,   796,  2207,   375,   395,  1806,     7,    73, 22071,\n",
       "         7890,   737, 12501,  1098, 10786,   292,   979,    72, 11537,   198,\n",
       "          220,   220,   220,  1441, 30240], dtype=torch.int32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.decode( input_ids_list[0] ) #Decoding IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTNeoForCausalLM(\n",
       "  (transformer): GPTNeoModel(\n",
       "    (wte): Embedding(50257, 2560)\n",
       "    (wpe): Embedding(2048, 2560)\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (12): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (13): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (14): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (15): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (16): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (17): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (18): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (19): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (20): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (21): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (22): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (23): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (24): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (25): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (26): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (27): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (28): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (29): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (30): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (31): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n",
       "            (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (c_proj): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2560, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.to( 'cpu' ) #WARNING, \n",
    "model.to( device ) #WARNING, Verify the device before assigning to memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'big_table_path': '../data/concept_tables/codesearch_tesbed_EleutherAI-gpt-neo-2.7B_10000.csv',\n",
       " 'hf_model': 'EleutherAI/gpt-neo-2.7B',\n",
       " 'model_name': 'EleutherAI-gpt-neo-2.7B_10000_',\n",
       " 'callbacks': '../data/callbacks',\n",
       " 'batch': 1}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters #Verification Point of Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit_extractor(batch, input, from_index=0):\n",
    "    \"\"\"\n",
    "    Output is the class CausalLMOutputWithPast (https://huggingface.co/transformers/v4.10.1/main_classes/output.html?highlight=causallmoutputwithpast)\"\n",
    "    logits (torch.FloatTensor of shape (batch_size, sequence_length, config.vocab_size))  Prediction scores of the language modeling head (scores for each vocabulary token before SoftMax).\n",
    "    The expression i.type(torch.LongTensor).to(device) is for casting labels for the loss\n",
    "    \"\"\"\n",
    "    #Output is in CausalLMOutputWithPast\n",
    "\n",
    "    for idx, n in enumerate( range( from_index, len(input), batch) ):\n",
    "        output = [ model( \n",
    "            input_ids = i, \n",
    "            labels = i.type(torch.LongTensor).to(device) \n",
    "            ) for i in input[n:n+batch] ] #Labels must be provided to compute loss\n",
    "    \n",
    "        output_logits = [ o.logits.detach().to('cpu').numpy() for o in output ]  #Logits Extraction\n",
    "        output_loss = np.array([ o.loss.detach().to('cpu').numpy() for o in output ])  #Language modeling loss (for next-token prediction).\n",
    "\n",
    "        #Saving Callbacks\n",
    "        current_batch = idx + (from_index//batch)\n",
    "        for jdx, o_logits in enumerate( output_logits ):\n",
    "            np.save( parameters['callbacks']+ '/'+parameters['model_name']  + f'_logits_tensor[{jdx+n}]_batch[{current_batch}].npy', o_logits)\n",
    "        np.save( parameters['callbacks']+ '/'+parameters['model_name']+f'_loss_batch[{current_batch}].npy', output_loss)\n",
    "        \n",
    "        print(f\"Batch [{current_batch}] Completed\")\n",
    "        \n",
    "        #Memory Released\n",
    "        for out in output:\n",
    "            del out.logits\n",
    "            torch.cuda.empty_cache()\n",
    "            del out.loss\n",
    "            torch.cuda.empty_cache()\n",
    "        for out in output_logits:\n",
    "            del out\n",
    "            torch.cuda.empty_cache()\n",
    "        for out in output_loss:\n",
    "            del out\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logit_extractor(batch =2, input= input_ids_list[:2]) #<---- [WARNING TIME AND MEMORY CONSUMING]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_logits = np.load('../data/callbacks/logits_tensor[0]_batch[0].npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assert output_logits.shape[0] == len(input_ids_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_loss = np.load('../data/callbacks/loss_batch[0].npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [2] Completed\n",
      "Batch [3] Completed\n",
      "Batch [4] Completed\n",
      "Batch [5] Completed\n",
      "Batch [6] Completed\n",
      "Batch [7] Completed\n",
      "Batch [8] Completed\n",
      "Batch [9] Completed\n",
      "Batch [10] Completed\n",
      "Batch [11] Completed\n",
      "Batch [12] Completed\n",
      "Batch [13] Completed\n",
      "Batch [14] Completed\n",
      "Batch [15] Completed\n",
      "Batch [16] Completed\n",
      "Batch [17] Completed\n",
      "Batch [18] Completed\n",
      "Batch [19] Completed\n",
      "Batch [20] Completed\n",
      "Batch [21] Completed\n",
      "Batch [22] Completed\n",
      "Batch [23] Completed\n",
      "Batch [24] Completed\n",
      "Batch [25] Completed\n",
      "Batch [26] Completed\n",
      "Batch [27] Completed\n",
      "Batch [28] Completed\n",
      "Batch [29] Completed\n",
      "Batch [30] Completed\n"
     ]
    }
   ],
   "source": [
    "## ACTUAL EXPERIMENT\n",
    "## TIME AND MEMORY CONSUMING\n",
    "logit_extractor(batch = 1, input= input_ids_list, from_index=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
