{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset \n",
    "import CodeSyntaxConcept.utils as utils\n",
    "from CodeSyntaxConcept.tokenizer import CodeTokenizer\n",
    "from CodeSyntaxConcept.parser import TreeSitterParser\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: code_search_net/all\n",
      "Found cached dataset code_search_net (/home/svelascodimate/.cache/huggingface/datasets/code_search_net/all/1.0.0/80a244ab541c6b2125350b764dc5c2b715f65f00de7a56107a28915fac173a27)\n",
      "Loading cached processed dataset at /home/svelascodimate/.cache/huggingface/datasets/code_search_net/all/1.0.0/80a244ab541c6b2125350b764dc5c2b715f65f00de7a56107a28915fac173a27/cache-3fbe88ea46cf0b42.arrow\n"
     ]
    }
   ],
   "source": [
    "language = \"python\"\n",
    "#number_of_samples = 2\n",
    "\n",
    "test_set = load_dataset(\"code_search_net\", split='test')\n",
    "test_set = test_set.filter(lambda sample: True if \n",
    "                sample['language']== language \n",
    "            else False, num_proc=1)\n",
    "\n",
    "#test_set = utils.get_random_sub_set_test_set(test_set, number_of_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping Sample Concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checkpoint loading just to use the parser in CodeTokenizer,\n",
    "checkpoint = \"EleutherAI/gpt-neo-125M\"\n",
    "parser = TreeSitterParser(CodeTokenizer.from_pretrained(checkpoint,language))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_node_counts = [[]]*len(parser.tokenizer.node_types)\n",
    "for sample in test_set:\n",
    "    tree = parser.tokenizer.parser.parse(bytes(sample['whole_func_string'], \"utf8\"))\n",
    "    for ast_element in parser.tokenizer.node_types:\n",
    "        ast_element_ocurrences = []\n",
    "        utils.find_nodes(tree.root_node, ast_element, ast_element_ocurrences)\n",
    "        test_set_node_counts[parser.tokenizer.node_types.index(ast_element)] = test_set_node_counts[parser.tokenizer.node_types.index(ast_element)] + [len(ast_element_ocurrences)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_node_frequencies = [sum(ast_frequency)/len(ast_frequency) for ast_frequency in test_set_node_counts]\n",
    "assert test_set_node_frequencies[180] == sum(test_set_node_counts[180])/len(test_set_node_counts[180])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_frequencies_dataframe = pd.DataFrame([], columns=['ast_element', 'average'])\n",
    "for node_id, node_frequency in enumerate(test_set_node_frequencies):\n",
    "    node_frequencies_dataframe.loc[len(node_frequencies_dataframe.index)] = [parser.tokenizer.node_types[node_id], node_frequency]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_frequencies_dataframe.to_csv('output/node_frequencies_dataframe.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ast_element</th>\n",
       "      <th>average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>identifier</td>\n",
       "      <td>40.608451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>\"</td>\n",
       "      <td>11.048250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>.</td>\n",
       "      <td>9.292614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>(</td>\n",
       "      <td>9.148629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>)</td>\n",
       "      <td>9.148629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>expression</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>match_statement</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>@=</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>case</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>_simple_statement</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ast_element    average\n",
       "180         identifier  40.608451\n",
       "69                   \"  11.048250\n",
       "40                   .   9.292614\n",
       "108                  (   9.148629\n",
       "183                  )   9.148629\n",
       "..                 ...        ...\n",
       "150         expression   0.000000\n",
       "152    match_statement   0.000000\n",
       "163                 @=   0.000000\n",
       "157               case   0.000000\n",
       "111  _simple_statement   0.000000\n",
       "\n",
       "[195 rows x 2 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_frequencies_dataframe.sort_values(by=['average'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "49b68b9c38357b2088122ab1ddc655dffe83bd2309642e44c64d6d94a1d66aec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
