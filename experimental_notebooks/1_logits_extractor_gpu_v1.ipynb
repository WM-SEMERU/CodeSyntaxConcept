{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from statistics import NormalDist\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.1+cu113'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3478, 0.4097, 0.3891],\n",
      "        [0.7176, 0.8822, 0.0272],\n",
      "        [0.8784, 0.1918, 0.7899],\n",
      "        [0.4318, 0.0703, 0.1718],\n",
      "        [0.5152, 0.7167, 0.1274]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "x = torch.rand(5, 3, \n",
    "               device=device#'cpu'\n",
    "               )\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deleting tensor to free memory\n",
    "del x\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Apr 19 19:01:38 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.103.01   Driver Version: 470.103.01   CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100-PCI...  Off  | 00000000:61:00.0 Off |                    0 |\n",
      "| N/A   31C    P0    33W / 250W |      7MiB / 40536MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logits Extractor\n",
    ">\n",
    "> Extracting Tensor Logits from a given Neural Code Model @danaderp\n",
    ">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def c_eleuther( returnModel = False, model_type =  'EleutherAI/gpt-neo-125m'):\n",
    "    ''' Eleuther and Salesforce and Parrot uses the same importation'''\n",
    "    from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_type)\n",
    "    if returnModel:\n",
    "        print(\"Uploading:\",model_type)\n",
    "        model = AutoModelForCausalLM.from_pretrained(model_type)\n",
    "    else:\n",
    "        model = []\n",
    "    return (tokenizer, model)\n",
    "    \n",
    "    \n",
    "\n",
    "def init_model_args( current_case = 'c1', returnModel = False ): \n",
    "    \n",
    "    code_models = {\n",
    "        'c1':('gpt-neo-125m',) + c_eleuther( returnModel = returnModel,  model_type = 'EleutherAI/gpt-neo-125m' ), # Basic (on Pile) GPT-3/J\n",
    "        'c2':('gpt-neo-1.3B',) + c_eleuther( returnModel = returnModel,  model_type = 'EleutherAI/gpt-neo-1.3B' ),\n",
    "        'c3':('gpt-neo-2.7B',) + c_eleuther( returnModel = returnModel,  model_type = 'EleutherAI/gpt-neo-2.7B' ),\n",
    "        'c4':('gpt-j-6b',) + c_eleuther( returnModel = returnModel,  model_type = 'EleutherAI/gpt-j-6b' ),\n",
    "        'c5':('codegen-350M-nl',) + c_eleuther( returnModel = returnModel,  model_type = 'Salesforce/codegen-350M-nl' ), #Basic (on Pile) codegen\n",
    "        'c6':('codegen-2B-nl',) + c_eleuther( returnModel = returnModel,  model_type = 'Salesforce/codegen-2B-nl' ),\n",
    "        'c7':('codegen-6B-nl',) + c_eleuther( returnModel = returnModel,  model_type = 'Salesforce/codegen-6B-nl' ),\n",
    "        'c8':('codegen-16B-nl',) + c_eleuther( returnModel = returnModel,  model_type = 'Salesforce/codegen-16B-nl' ),\n",
    "        'c9':('codeparrot-small-multi',) + c_eleuther( returnModel = returnModel,  model_type = 'codeparrot/codeparrot-small-multi' ), #multi-Language\n",
    "        'c10':('codegen-350M-multi',) + c_eleuther( returnModel = returnModel,  model_type = 'Salesforce/codegen-350M-multi' ),\n",
    "        'c11':('codegen-2B-multi',) + c_eleuther( returnModel = returnModel,  model_type = 'Salesforce/codegen-2B-multi' ),\n",
    "        'c12':('codegen-6B-multi',) + c_eleuther( returnModel = returnModel,  model_type = 'Salesforce/codegen-6B-multi' ),\n",
    "        'c13':('codegen-16B-multi',) + c_eleuther( returnModel = returnModel,  model_type = 'Salesforce/codegen-16B-multi' ),\n",
    "        'c14':('codeparrot-small',) + c_eleuther( returnModel = returnModel,  model_type = 'codeparrot/codeparrot-small' ), #mono-Language\n",
    "        'c15':('codeparrot',) + c_eleuther( returnModel = returnModel,  model_type = 'codeparrot/codeparrot' ),\n",
    "        'c16':('codegen-350M-mono',) + c_eleuther( returnModel = returnModel,  model_type = 'Salesforce/codegen-350M-mono' ),\n",
    "        'c17':('codegen-2B-mono',) + c_eleuther( returnModel = returnModel,  model_type = 'Salesforce/codegen-2B-mono' ),\n",
    "        'c18':('codegen-6B-mono',) + c_eleuther( returnModel = returnModel,  model_type = 'Salesforce/codegen-6B-mono' ),\n",
    "        'c19':('codegen-16B-mono',) + c_eleuther( returnModel = returnModel,  model_type = 'Salesforce/codegen-16B-mono' ),\n",
    "    }\n",
    "    \n",
    "    r = code_models[current_case]\n",
    "    \n",
    "    data_path ='../datax/testbeds/AstEvalFilteredV1.json' #<-- HYPER AstEvalFilteredV1\n",
    "    pd_data = pd.read_json( data_path ) #Data Uploading\n",
    "    \n",
    "    numpy_files_logits_path = '../datax/1_numpy_files_logits/' + current_case #outputpath\n",
    "    return r[0], r[1], r[2], pd_data, numpy_files_logits_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Available Datasets\n",
    "# Case1: codesearch_tesbed_EleutherAI-gpt-neo-125M_10000 for the model 'EleutherAI/gpt-neo-125M' \n",
    "# Case2: codesearch_tesbed_EleutherAI-gpt-neo-2.7B_10000 for the model 'EleutherAI/gpt-neo-2.7B' <-- MEMORY CONSTRAINTS\n",
    "\n",
    "def params(): \n",
    "    \n",
    "    code_models = {\n",
    "        'Case3':('EleutherAI/gpt-neo-1.3B','codesearch_tesbed_EleutherAI-gpt-neo-1.3B_10000.csv','EleutherAI-gpt-neo-1.3B_10000_','callbacks-EleutherAI-gpt-neo-1.3B_10000_'),\n",
    "        'Case4':('microsoft/CodeGPT-small-py','codesearch_tesbed_microsoft-CodeGPT-small-py_1024_10000.csv','CodeGPT-small-py_10000_','callbacks-CodeGPT-small-py_10000_'),\n",
    "        'Case5':('microsoft/CodeGPT-small-py-adaptedGPT2','codesearch_tesbed_microsoft-CodeGPT-small-py-adaptedGPT2_1024_10000.csv','CodeGPT-small-py-adaptedGPT2_10000_','callbacks-CodeGPT-small-py-adaptedGPT2_10000_'),\n",
    "        'Case6':('Salesforce/codegen-2B-multi','codesearch_tesbed_Salesforce-codegen-2B-multi_10000.csv','Salesforce-codegen-2B-multi_10000_','callbacks-Salesforce-codegen-2B-multi_10000_')\n",
    "    }\n",
    "    current_case = 'Case4' #<----[Hyper]\n",
    "    \n",
    "    #print(code_models[current_case][1])\n",
    "    \n",
    "    return {\n",
    "            'big_table_path' : '../data/concept_tables/' + code_models[current_case][1],\n",
    "            'hf_model' :  code_models[current_case][0],\n",
    "            'model_name': code_models[current_case][2],\n",
    "            'callbacks' : '../data/' + code_models[current_case][3],\n",
    "            'wpe':1024  #<----[Hyper]\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init Parameters\n",
    "> Loading Models and Testbeds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CODEMODEL = 'c1' #Hyper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de4a3af5a1874b27b03c6643bba1de88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/526M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c60b00978f2f43b18bce9847488ff928",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/930 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab31028af73f41e487ef27033014a6cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/24.2G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65184d3776be4e98834fbb9d63a2b364",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/997 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27a9033b54fa40e084dc2020bbd4cafb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/797M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b72a95fbcbc4afa875d2bf27d5b4be4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/995 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "872126fd62374d8fabe730b65029b924",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/11.3G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "722c1b2b35e947e7bfa2b9629f4f26fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/995 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d359448a1e1d472dac042d76c244a8ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/14.3G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e41b5a5a78f4ca29da731c7be426cb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/996 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdbf311d91aa4ed289d4ea78206c12aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/32.2G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7df2adbf23714b6aa9c4e8261ea2f9a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/247M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60a9ec423b4740929449bcf12cdb834b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.00k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff6cd99567fa4c2a9a46c94016f444c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/797M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62cd8d03ddec45b19a33b8d2a31d2e29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/998 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bed57051255045feb1a06c59c0185da4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/14.3G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5b3f1402b4e4d70821d638494fd6dc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/999 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e733622103624ad4a2bc3c3f7b432b59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/32.2G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b1f517c47434d99a0f254259ae78ba6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/903 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c344a35cc78e4980a3a78dc4ecd05284",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/457M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db160ac5609d4588990a53ff2d144dd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/927 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41428e45eec34c48a89dc420902bc15a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/6.17G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "645a227be5ab4318b3cf7fbb458a65ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/999 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e8b6880ae2c491c8c64949caa219a1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/797M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec88bb7d7ef34890a3440f258839e40c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/997 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b04e863b231c48b7b466e0ff95f36c17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/5.69G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61dc1cd4b36d4fe7b2b1b297fbb09ad4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/997 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "342e38a3b70149dd838ed3a82161ed91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/14.3G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">init_model_args</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">c_eleuther</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.8/dist-packages/transformers/models/auto/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">auto_factory.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">464</span> in           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">from_pretrained</span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">461 │   │   │   </span>)                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">462 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">elif</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">type</span>(config) <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">cls</span>._model_mapping.keys():                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">463 │   │   │   </span>model_class = _get_model_class(config, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">cls</span>._model_mapping)                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>464 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> model_class.from_pretrained(                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">465 │   │   │   │   </span>pretrained_model_name_or_path, *model_args, config=config, **hub_kwargs,   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">466 │   │   │   </span>)                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">467 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">ValueError</span>(                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.8/dist-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2208</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">from_pretrained</span>    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2205 │   │   │   │   │   │   </span>_raise_exceptions_for_missing_entries=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>,                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2206 │   │   │   │   │   │   </span>_commit_hash=commit_hash,                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2207 │   │   │   │   │   </span>)                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>2208 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>resolved_archive_file = cached_file(pretrained_model_name_or_path, f  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2209 │   │   │   │   │   </span>                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2210 │   │   │   │   │   # Since we set _raise_exceptions_for_missing_entries=False, we don't</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2211 │   │   │   │   │   # result when internet is up, the repo and revision exist, but the f</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.8/dist-packages/transformers/utils/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">hub.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">409</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">cached_file</span>              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 406 │   </span>user_agent = http_user_agent(user_agent)                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 407 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 408 │   │   # Load from URL or cache if already cached</span>                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 409 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>resolved_file = hf_hub_download(                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 410 │   │   │   </span>path_or_repo_id,                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 411 │   │   │   </span>filename,                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 412 │   │   │   </span>subfolder=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(subfolder) == <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> subfolder,                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.8/dist-packages/huggingface_hub/utils/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_validators.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">124</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_inner_fn</span>     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">121 │   │   │   │   </span>fn_name=fn.<span style=\"color: #ff0000; text-decoration-color: #ff0000\">__name__</span>, has_token=has_token, kwargs=kwargs                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">122 │   │   │   </span>)                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">123 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>124 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> fn(*args, **kwargs)                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">125 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">126 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> _inner_fn  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># type: ignore</span>                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">127 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.8/dist-packages/huggingface_hub/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">file_download.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1283</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">hf_hub_download</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1280 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> temp_file_manager() <span style=\"color: #0000ff; text-decoration-color: #0000ff\">as</span> temp_file:                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1281 │   │   │   </span>logger.info(<span style=\"color: #808000; text-decoration-color: #808000\">\"downloading %s to %s\"</span>, url, temp_file.name)                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1282 │   │   │   </span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1283 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>http_get(                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1284 │   │   │   │   </span>url_to_download,                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1285 │   │   │   │   </span>temp_file,                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1286 │   │   │   │   </span>proxies=proxies,                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.8/dist-packages/huggingface_hub/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">file_download.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">533</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">http_get</span>          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 530 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> chunk <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> r.iter_content(chunk_size=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">10</span> * <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1024</span> * <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1024</span>):                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 531 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> chunk:  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># filter out keep-alive new chunks</span>                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 532 │   │   │   </span>progress.update(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(chunk))                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 533 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>temp_file.write(chunk)                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 534 │   </span>progress.close()                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 535 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 536 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/lib/python3.8/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">tempfile.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">612</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">func_wrapper</span>                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">609 │   │   │   </span>func = a                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">610 │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">@_functools</span>.wraps(func)                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">611 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">func_wrapper</span>(*args, **kwargs):                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>612 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> func(*args, **kwargs)                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">613 │   │   │   # Avoid closing the file as long as the wrapper is alive,</span>                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">614 │   │   │   # see issue #18879.</span>                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">615 │   │   │   </span>func_wrapper._closer = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._closer                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">OSError: </span><span style=\"font-weight: bold\">[</span>Errno <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28</span><span style=\"font-weight: bold\">]</span> No space left on device\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92minit_model_args\u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92mc_eleuther\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.8/dist-packages/transformers/models/auto/\u001b[0m\u001b[1;33mauto_factory.py\u001b[0m:\u001b[94m464\u001b[0m in           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mfrom_pretrained\u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m461 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m462 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melif\u001b[0m \u001b[96mtype\u001b[0m(config) \u001b[95min\u001b[0m \u001b[96mcls\u001b[0m._model_mapping.keys():                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m463 \u001b[0m\u001b[2m│   │   │   \u001b[0mmodel_class = _get_model_class(config, \u001b[96mcls\u001b[0m._model_mapping)                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m464 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m model_class.from_pretrained(                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m465 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mpretrained_model_name_or_path, *model_args, config=config, **hub_kwargs,   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m466 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m467 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mValueError\u001b[0m(                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.8/dist-packages/transformers/\u001b[0m\u001b[1;33mmodeling_utils.py\u001b[0m:\u001b[94m2208\u001b[0m in \u001b[92mfrom_pretrained\u001b[0m    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2205 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0m_raise_exceptions_for_missing_entries=\u001b[94mFalse\u001b[0m,                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2206 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0m_commit_hash=commit_hash,                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2207 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m)                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2208 \u001b[2m│   │   │   │   │   \u001b[0mresolved_archive_file = cached_file(pretrained_model_name_or_path, f  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2209 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2210 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[2m# Since we set _raise_exceptions_for_missing_entries=False, we don't\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2211 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[2m# result when internet is up, the repo and revision exist, but the f\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.8/dist-packages/transformers/utils/\u001b[0m\u001b[1;33mhub.py\u001b[0m:\u001b[94m409\u001b[0m in \u001b[92mcached_file\u001b[0m              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 406 \u001b[0m\u001b[2m│   \u001b[0muser_agent = http_user_agent(user_agent)                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 407 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mtry\u001b[0m:                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 408 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Load from URL or cache if already cached\u001b[0m                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 409 \u001b[2m│   │   \u001b[0mresolved_file = hf_hub_download(                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 410 \u001b[0m\u001b[2m│   │   │   \u001b[0mpath_or_repo_id,                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 411 \u001b[0m\u001b[2m│   │   │   \u001b[0mfilename,                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 412 \u001b[0m\u001b[2m│   │   │   \u001b[0msubfolder=\u001b[94mNone\u001b[0m \u001b[94mif\u001b[0m \u001b[96mlen\u001b[0m(subfolder) == \u001b[94m0\u001b[0m \u001b[94melse\u001b[0m subfolder,                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.8/dist-packages/huggingface_hub/utils/\u001b[0m\u001b[1;33m_validators.py\u001b[0m:\u001b[94m124\u001b[0m in \u001b[92m_inner_fn\u001b[0m     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m121 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mfn_name=fn.\u001b[91m__name__\u001b[0m, has_token=has_token, kwargs=kwargs                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m122 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m123 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m124 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m fn(*args, **kwargs)                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m125 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m126 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m _inner_fn  \u001b[2m# type: ignore\u001b[0m                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m127 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.8/dist-packages/huggingface_hub/\u001b[0m\u001b[1;33mfile_download.py\u001b[0m:\u001b[94m1283\u001b[0m in \u001b[92mhf_hub_download\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1280 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mwith\u001b[0m temp_file_manager() \u001b[94mas\u001b[0m temp_file:                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1281 \u001b[0m\u001b[2m│   │   │   \u001b[0mlogger.info(\u001b[33m\"\u001b[0m\u001b[33mdownloading \u001b[0m\u001b[33m%s\u001b[0m\u001b[33m to \u001b[0m\u001b[33m%s\u001b[0m\u001b[33m\"\u001b[0m, url, temp_file.name)                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1282 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1283 \u001b[2m│   │   │   \u001b[0mhttp_get(                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1284 \u001b[0m\u001b[2m│   │   │   │   \u001b[0murl_to_download,                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1285 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mtemp_file,                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1286 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mproxies=proxies,                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.8/dist-packages/huggingface_hub/\u001b[0m\u001b[1;33mfile_download.py\u001b[0m:\u001b[94m533\u001b[0m in \u001b[92mhttp_get\u001b[0m          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 530 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mfor\u001b[0m chunk \u001b[95min\u001b[0m r.iter_content(chunk_size=\u001b[94m10\u001b[0m * \u001b[94m1024\u001b[0m * \u001b[94m1024\u001b[0m):                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 531 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m chunk:  \u001b[2m# filter out keep-alive new chunks\u001b[0m                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 532 \u001b[0m\u001b[2m│   │   │   \u001b[0mprogress.update(\u001b[96mlen\u001b[0m(chunk))                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 533 \u001b[2m│   │   │   \u001b[0mtemp_file.write(chunk)                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 534 \u001b[0m\u001b[2m│   \u001b[0mprogress.close()                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 535 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 536 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/usr/lib/python3.8/\u001b[0m\u001b[1;33mtempfile.py\u001b[0m:\u001b[94m612\u001b[0m in \u001b[92mfunc_wrapper\u001b[0m                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m609 \u001b[0m\u001b[2m│   │   │   \u001b[0mfunc = a                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m610 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[1;95m@_functools\u001b[0m.wraps(func)                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m611 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mfunc_wrapper\u001b[0m(*args, **kwargs):                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m612 \u001b[2m│   │   │   │   \u001b[0m\u001b[94mreturn\u001b[0m func(*args, **kwargs)                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m613 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# Avoid closing the file as long as the wrapper is alive,\u001b[0m                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m614 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# see issue #18879.\u001b[0m                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m615 \u001b[0m\u001b[2m│   │   │   \u001b[0mfunc_wrapper._closer = \u001b[96mself\u001b[0m._closer                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mOSError: \u001b[0m\u001b[1m[\u001b[0mErrno \u001b[1;36m28\u001b[0m\u001b[1m]\u001b[0m No space left on device\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "name, tokenizer, model, pd_data, numpy_files_logits_path = init_model_args(current_case = CODEMODEL, returnModel = True) #[WARNING!] Check the parameters before calling it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing name and output_path\n",
    "print( name, numpy_files_logits_path )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_total_input_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>322.230000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>220.374923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>41.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>156.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>253.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>436.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1022.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       model_total_input_ids\n",
       "count           10000.000000\n",
       "mean              322.230000\n",
       "std               220.374923\n",
       "min                41.000000\n",
       "25%               156.000000\n",
       "50%               253.000000\n",
       "75%               436.000000\n",
       "max              1022.000000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing data loads\n",
    "pd_data.describe() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Logits From a Given Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = pd_data[CODEMODEL + '_ids'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating preprocessed ids\n",
    "input_ids_list =  [eval(ids_vector) for ids_vector in prompts] #<-- Do not return as a Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Casting Integers to Tensor Integers. Make sure the tesor is created in a device\n",
    "#We ignored the parameter attention_mask since we are not using masking here [https://huggingface.co/transformers/v4.10.1/glossary.html#attention-mask]\n",
    "\n",
    "tf_input_ids = [torch.tensor(  input_ids, dtype = torch.int, device=device ) for input_ids in input_ids_list ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#It should be same size\n",
    "assert len(input_ids_list) == len(prompts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Model to Memoery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50001, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50001, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to( device ) #WARNING, Verify the device before assigning to memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'big_table_path': '../data/concept_tables/codesearch_tesbed_microsoft-CodeGPT-small-py_1024_10000.csv',\n",
       " 'hf_model': 'microsoft/CodeGPT-small-py',\n",
       " 'model_name': 'CodeGPT-small-py_10000_',\n",
       " 'callbacks': '../data/callbacks-CodeGPT-small-py_10000_',\n",
       " 'wpe': 1024}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters #Verification Point of Parameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executing Logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit_extractor(batch, input, from_index=0):\n",
    "    \"\"\"\n",
    "    Output is the class CausalLMOutputWithPast (https://huggingface.co/transformers/v4.10.1/main_classes/output.html?highlight=causallmoutputwithpast)\"\n",
    "    logits (torch.FloatTensor of shape (batch_size, sequence_length, config.vocab_size)) – Prediction scores of the language modeling head (scores for each vocabulary token before SoftMax).\n",
    "    The expression i.type(torch.LongTensor).to(device) is for casting labels for the loss\n",
    "    \"\"\"\n",
    "    #Output is in CausalLMOutputWithPast\n",
    "\n",
    "    for idx, n in enumerate( range( from_index, len(input), batch) ):\n",
    "        output = [ model( \n",
    "            input_ids = i, \n",
    "            labels = i.type(torch.LongTensor).to(device) \n",
    "            ) for i in input[n:n+batch] ] #Labels must be provided to compute loss\n",
    "    \n",
    "        output_logits = [ o.logits.detach().to('cpu').numpy() for o in output ]  #Logits Extraction\n",
    "        output_loss = np.array([ o.loss.detach().to('cpu').numpy() for o in output ])  #Language modeling loss (for next-token prediction).\n",
    "\n",
    "        #Saving Callbacks\n",
    "        current_batch = idx + (from_index//batch)\n",
    "        for jdx, o_logits in enumerate( output_logits ):\n",
    "            np.save( numpy_files_logits_path+ '/'+ f'logits_tensor[{jdx+n}]_batch[{current_batch}]_model[{CODEMODEL}].npy', o_logits) #Saving LOGITS\n",
    "        np.save( numpy_files_logits_path+ '/'+f'loss_batch[{current_batch}]_model[{CODEMODEL}].npy', output_loss) #Saving LOSS\n",
    "        \n",
    "        print(f\"Batch [{current_batch}] Completed\")\n",
    "        \n",
    "        #Memory Released\n",
    "        for out in output:\n",
    "            del out.logits\n",
    "            torch.cuda.empty_cache()\n",
    "            del out.loss\n",
    "            torch.cuda.empty_cache()\n",
    "        for out in output_logits:\n",
    "            del out\n",
    "            torch.cuda.empty_cache()\n",
    "        for out in output_loss:\n",
    "            del out\n",
    "            torch.cuda.empty_cache()\n",
    "        del output\n",
    "        del output_logits\n",
    "        del output_loss\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [0] Completed\n",
      "Batch [1] Completed\n",
      "Batch [2] Completed\n",
      "Batch [3] Completed\n",
      "Batch [4] Completed\n",
      "Batch [5] Completed\n",
      "Batch [6] Completed\n",
      "Batch [7] Completed\n",
      "Batch [8] Completed\n",
      "Batch [9] Completed\n",
      "Batch [10] Completed\n",
      "Batch [11] Completed\n",
      "Batch [12] Completed\n",
      "Batch [13] Completed\n",
      "Batch [14] Completed\n",
      "Batch [15] Completed\n",
      "Batch [16] Completed\n",
      "Batch [17] Completed\n",
      "Batch [18] Completed\n",
      "Batch [19] Completed\n",
      "Batch [20] Completed\n",
      "Batch [21] Completed\n",
      "Batch [22] Completed\n",
      "Batch [23] Completed\n",
      "Batch [24] Completed\n",
      "Batch [25] Completed\n",
      "Batch [26] Completed\n",
      "Batch [27] Completed\n",
      "Batch [28] Completed\n",
      "Batch [29] Completed\n",
      "Batch [30] Completed\n",
      "Batch [31] Completed\n",
      "Batch [32] Completed\n",
      "Batch [33] Completed\n",
      "Batch [34] Completed\n",
      "Batch [35] Completed\n",
      "Batch [36] Completed\n",
      "Batch [37] Completed\n",
      "Batch [38] Completed\n",
      "Batch [39] Completed\n",
      "Batch [40] Completed\n",
      "Batch [41] Completed\n",
      "Batch [42] Completed\n",
      "Batch [43] Completed\n",
      "Batch [44] Completed\n",
      "Batch [45] Completed\n",
      "Batch [46] Completed\n",
      "Batch [47] Completed\n",
      "Batch [48] Completed\n",
      "Batch [49] Completed\n",
      "Batch [50] Completed\n",
      "Batch [51] Completed\n",
      "Batch [52] Completed\n",
      "Batch [53] Completed\n",
      "Batch [54] Completed\n",
      "Batch [55] Completed\n",
      "Batch [56] Completed\n",
      "Batch [57] Completed\n",
      "Batch [58] Completed\n",
      "Batch [59] Completed\n",
      "Batch [60] Completed\n",
      "Batch [61] Completed\n",
      "Batch [62] Completed\n",
      "Batch [63] Completed\n",
      "Batch [64] Completed\n",
      "Batch [65] Completed\n",
      "Batch [66] Completed\n",
      "Batch [67] Completed\n",
      "Batch [68] Completed\n",
      "Batch [69] Completed\n",
      "Batch [70] Completed\n",
      "Batch [71] Completed\n",
      "Batch [72] Completed\n",
      "Batch [73] Completed\n",
      "Batch [74] Completed\n",
      "Batch [75] Completed\n",
      "Batch [76] Completed\n",
      "Batch [77] Completed\n",
      "Batch [78] Completed\n",
      "Batch [79] Completed\n",
      "Batch [80] Completed\n",
      "Batch [81] Completed\n",
      "Batch [82] Completed\n",
      "Batch [83] Completed\n",
      "Batch [84] Completed\n",
      "Batch [85] Completed\n",
      "Batch [86] Completed\n",
      "Batch [87] Completed\n",
      "Batch [88] Completed\n",
      "Batch [89] Completed\n",
      "Batch [90] Completed\n",
      "Batch [91] Completed\n",
      "Batch [92] Completed\n",
      "Batch [93] Completed\n",
      "Batch [94] Completed\n",
      "Batch [95] Completed\n",
      "Batch [96] Completed\n",
      "Batch [97] Completed\n",
      "Batch [98] Completed\n",
      "Batch [99] Completed\n",
      "Batch [100] Completed\n",
      "Batch [101] Completed\n",
      "Batch [102] Completed\n",
      "Batch [103] Completed\n",
      "Batch [104] Completed\n",
      "Batch [105] Completed\n",
      "Batch [106] Completed\n",
      "Batch [107] Completed\n",
      "Batch [108] Completed\n",
      "Batch [109] Completed\n",
      "Batch [110] Completed\n",
      "Batch [111] Completed\n",
      "Batch [112] Completed\n",
      "Batch [113] Completed\n",
      "Batch [114] Completed\n",
      "Batch [115] Completed\n",
      "Batch [116] Completed\n",
      "Batch [117] Completed\n",
      "Batch [118] Completed\n",
      "Batch [119] Completed\n",
      "Batch [120] Completed\n",
      "Batch [121] Completed\n",
      "Batch [122] Completed\n",
      "Batch [123] Completed\n",
      "Batch [124] Completed\n",
      "Batch [125] Completed\n",
      "Batch [126] Completed\n",
      "Batch [127] Completed\n",
      "Batch [128] Completed\n",
      "Batch [129] Completed\n",
      "Batch [130] Completed\n",
      "Batch [131] Completed\n",
      "Batch [132] Completed\n",
      "Batch [133] Completed\n",
      "Batch [134] Completed\n",
      "Batch [135] Completed\n",
      "Batch [136] Completed\n",
      "Batch [137] Completed\n",
      "Batch [138] Completed\n",
      "Batch [139] Completed\n",
      "Batch [140] Completed\n",
      "Batch [141] Completed\n",
      "Batch [142] Completed\n",
      "Batch [143] Completed\n",
      "Batch [144] Completed\n",
      "Batch [145] Completed\n",
      "Batch [146] Completed\n",
      "Batch [147] Completed\n",
      "Batch [148] Completed\n",
      "Batch [149] Completed\n",
      "Batch [150] Completed\n",
      "Batch [151] Completed\n",
      "Batch [152] Completed\n",
      "Batch [153] Completed\n",
      "Batch [154] Completed\n",
      "Batch [155] Completed\n",
      "Batch [156] Completed\n",
      "Batch [157] Completed\n",
      "Batch [158] Completed\n",
      "Batch [159] Completed\n",
      "Batch [160] Completed\n",
      "Batch [161] Completed\n",
      "Batch [162] Completed\n",
      "Batch [163] Completed\n",
      "Batch [164] Completed\n",
      "Batch [165] Completed\n",
      "Batch [166] Completed\n",
      "Batch [167] Completed\n",
      "Batch [168] Completed\n",
      "Batch [169] Completed\n",
      "Batch [170] Completed\n",
      "Batch [171] Completed\n",
      "Batch [172] Completed\n",
      "Batch [173] Completed\n",
      "Batch [174] Completed\n",
      "Batch [175] Completed\n",
      "Batch [176] Completed\n",
      "Batch [177] Completed\n",
      "Batch [178] Completed\n",
      "Batch [179] Completed\n",
      "Batch [180] Completed\n",
      "Batch [181] Completed\n",
      "Batch [182] Completed\n",
      "Batch [183] Completed\n",
      "Batch [184] Completed\n",
      "Batch [185] Completed\n",
      "Batch [186] Completed\n",
      "Batch [187] Completed\n",
      "Batch [188] Completed\n",
      "Batch [189] Completed\n",
      "Batch [190] Completed\n",
      "Batch [191] Completed\n",
      "Batch [192] Completed\n",
      "Batch [193] Completed\n",
      "Batch [194] Completed\n",
      "Batch [195] Completed\n",
      "Batch [196] Completed\n",
      "Batch [197] Completed\n",
      "Batch [198] Completed\n",
      "Batch [199] Completed\n",
      "Batch [200] Completed\n",
      "Batch [201] Completed\n",
      "Batch [202] Completed\n",
      "Batch [203] Completed\n",
      "Batch [204] Completed\n",
      "Batch [205] Completed\n",
      "Batch [206] Completed\n",
      "Batch [207] Completed\n",
      "Batch [208] Completed\n",
      "Batch [209] Completed\n",
      "Batch [210] Completed\n",
      "Batch [211] Completed\n",
      "Batch [212] Completed\n",
      "Batch [213] Completed\n",
      "Batch [214] Completed\n",
      "Batch [215] Completed\n",
      "Batch [216] Completed\n",
      "Batch [217] Completed\n",
      "Batch [218] Completed\n",
      "Batch [219] Completed\n",
      "Batch [220] Completed\n",
      "Batch [221] Completed\n",
      "Batch [222] Completed\n",
      "Batch [223] Completed\n",
      "Batch [224] Completed\n",
      "Batch [225] Completed\n",
      "Batch [226] Completed\n",
      "Batch [227] Completed\n",
      "Batch [228] Completed\n",
      "Batch [229] Completed\n",
      "Batch [230] Completed\n",
      "Batch [231] Completed\n",
      "Batch [232] Completed\n",
      "Batch [233] Completed\n",
      "Batch [234] Completed\n",
      "Batch [235] Completed\n",
      "Batch [236] Completed\n",
      "Batch [237] Completed\n",
      "Batch [238] Completed\n",
      "Batch [239] Completed\n",
      "Batch [240] Completed\n",
      "Batch [241] Completed\n",
      "Batch [242] Completed\n",
      "Batch [243] Completed\n",
      "Batch [244] Completed\n",
      "Batch [245] Completed\n",
      "Batch [246] Completed\n",
      "Batch [247] Completed\n",
      "Batch [248] Completed\n",
      "Batch [249] Completed\n",
      "Batch [250] Completed\n",
      "Batch [251] Completed\n",
      "Batch [252] Completed\n",
      "Batch [253] Completed\n",
      "Batch [254] Completed\n",
      "Batch [255] Completed\n",
      "Batch [256] Completed\n",
      "Batch [257] Completed\n",
      "Batch [258] Completed\n",
      "Batch [259] Completed\n",
      "Batch [260] Completed\n",
      "Batch [261] Completed\n",
      "Batch [262] Completed\n",
      "Batch [263] Completed\n",
      "Batch [264] Completed\n",
      "Batch [265] Completed\n",
      "Batch [266] Completed\n",
      "Batch [267] Completed\n",
      "Batch [268] Completed\n",
      "Batch [269] Completed\n",
      "Batch [270] Completed\n",
      "Batch [271] Completed\n",
      "Batch [272] Completed\n",
      "Batch [273] Completed\n",
      "Batch [274] Completed\n",
      "Batch [275] Completed\n",
      "Batch [276] Completed\n",
      "Batch [277] Completed\n",
      "Batch [278] Completed\n",
      "Batch [279] Completed\n",
      "Batch [280] Completed\n",
      "Batch [281] Completed\n",
      "Batch [282] Completed\n",
      "Batch [283] Completed\n",
      "Batch [284] Completed\n",
      "Batch [285] Completed\n",
      "Batch [286] Completed\n",
      "Batch [287] Completed\n",
      "Batch [288] Completed\n",
      "Batch [289] Completed\n",
      "Batch [290] Completed\n",
      "Batch [291] Completed\n",
      "Batch [292] Completed\n",
      "Batch [293] Completed\n",
      "Batch [294] Completed\n",
      "Batch [295] Completed\n",
      "Batch [296] Completed\n",
      "Batch [297] Completed\n",
      "Batch [298] Completed\n",
      "Batch [299] Completed\n",
      "Batch [300] Completed\n",
      "Batch [301] Completed\n",
      "Batch [302] Completed\n",
      "Batch [303] Completed\n",
      "Batch [304] Completed\n",
      "Batch [305] Completed\n",
      "Batch [306] Completed\n",
      "Batch [307] Completed\n",
      "Batch [308] Completed\n",
      "Batch [309] Completed\n",
      "Batch [310] Completed\n",
      "Batch [311] Completed\n",
      "Batch [312] Completed\n",
      "Batch [313] Completed\n",
      "Batch [314] Completed\n",
      "Batch [315] Completed\n",
      "Batch [316] Completed\n",
      "Batch [317] Completed\n",
      "Batch [318] Completed\n",
      "Batch [319] Completed\n",
      "Batch [320] Completed\n",
      "Batch [321] Completed\n",
      "Batch [322] Completed\n",
      "Batch [323] Completed\n",
      "Batch [324] Completed\n",
      "Batch [325] Completed\n",
      "Batch [326] Completed\n",
      "Batch [327] Completed\n",
      "Batch [328] Completed\n",
      "Batch [329] Completed\n",
      "Batch [330] Completed\n",
      "Batch [331] Completed\n",
      "Batch [332] Completed\n",
      "Batch [333] Completed\n",
      "Batch [334] Completed\n",
      "Batch [335] Completed\n",
      "Batch [336] Completed\n",
      "Batch [337] Completed\n",
      "Batch [338] Completed\n",
      "Batch [339] Completed\n",
      "Batch [340] Completed\n",
      "Batch [341] Completed\n",
      "Batch [342] Completed\n",
      "Batch [343] Completed\n",
      "Batch [344] Completed\n",
      "Batch [345] Completed\n",
      "Batch [346] Completed\n",
      "Batch [347] Completed\n",
      "Batch [348] Completed\n",
      "Batch [349] Completed\n",
      "Batch [350] Completed\n",
      "Batch [351] Completed\n",
      "Batch [352] Completed\n",
      "Batch [353] Completed\n",
      "Batch [354] Completed\n",
      "Batch [355] Completed\n",
      "Batch [356] Completed\n",
      "Batch [357] Completed\n",
      "Batch [358] Completed\n",
      "Batch [359] Completed\n",
      "Batch [360] Completed\n",
      "Batch [361] Completed\n",
      "Batch [362] Completed\n",
      "Batch [363] Completed\n",
      "Batch [364] Completed\n",
      "Batch [365] Completed\n",
      "Batch [366] Completed\n",
      "Batch [367] Completed\n",
      "Batch [368] Completed\n",
      "Batch [369] Completed\n",
      "Batch [370] Completed\n",
      "Batch [371] Completed\n",
      "Batch [372] Completed\n",
      "Batch [373] Completed\n",
      "Batch [374] Completed\n",
      "Batch [375] Completed\n",
      "Batch [376] Completed\n",
      "Batch [377] Completed\n",
      "Batch [378] Completed\n",
      "Batch [379] Completed\n",
      "Batch [380] Completed\n",
      "Batch [381] Completed\n",
      "Batch [382] Completed\n",
      "Batch [383] Completed\n",
      "Batch [384] Completed\n",
      "Batch [385] Completed\n",
      "Batch [386] Completed\n",
      "Batch [387] Completed\n",
      "Batch [388] Completed\n",
      "Batch [389] Completed\n",
      "Batch [390] Completed\n",
      "Batch [391] Completed\n",
      "Batch [392] Completed\n",
      "Batch [393] Completed\n",
      "Batch [394] Completed\n",
      "Batch [395] Completed\n",
      "Batch [396] Completed\n",
      "Batch [397] Completed\n",
      "Batch [398] Completed\n",
      "Batch [399] Completed\n",
      "Batch [400] Completed\n",
      "Batch [401] Completed\n",
      "Batch [402] Completed\n",
      "Batch [403] Completed\n",
      "Batch [404] Completed\n",
      "Batch [405] Completed\n",
      "Batch [406] Completed\n",
      "Batch [407] Completed\n",
      "Batch [408] Completed\n",
      "Batch [409] Completed\n",
      "Batch [410] Completed\n",
      "Batch [411] Completed\n",
      "Batch [412] Completed\n",
      "Batch [413] Completed\n",
      "Batch [414] Completed\n",
      "Batch [415] Completed\n",
      "Batch [416] Completed\n",
      "Batch [417] Completed\n",
      "Batch [418] Completed\n",
      "Batch [419] Completed\n",
      "Batch [420] Completed\n",
      "Batch [421] Completed\n",
      "Batch [422] Completed\n",
      "Batch [423] Completed\n",
      "Batch [424] Completed\n",
      "Batch [425] Completed\n",
      "Batch [426] Completed\n",
      "Batch [427] Completed\n",
      "Batch [428] Completed\n",
      "Batch [429] Completed\n",
      "Batch [430] Completed\n",
      "Batch [431] Completed\n",
      "Batch [432] Completed\n",
      "Batch [433] Completed\n",
      "Batch [434] Completed\n",
      "Batch [435] Completed\n",
      "Batch [436] Completed\n",
      "Batch [437] Completed\n",
      "Batch [438] Completed\n",
      "Batch [439] Completed\n",
      "Batch [440] Completed\n",
      "Batch [441] Completed\n",
      "Batch [442] Completed\n",
      "Batch [443] Completed\n",
      "Batch [444] Completed\n",
      "Batch [445] Completed\n",
      "Batch [446] Completed\n",
      "Batch [447] Completed\n",
      "Batch [448] Completed\n",
      "Batch [449] Completed\n",
      "Batch [450] Completed\n",
      "Batch [451] Completed\n",
      "Batch [452] Completed\n",
      "Batch [453] Completed\n",
      "Batch [454] Completed\n",
      "Batch [455] Completed\n",
      "Batch [456] Completed\n",
      "Batch [457] Completed\n",
      "Batch [458] Completed\n",
      "Batch [459] Completed\n",
      "Batch [460] Completed\n",
      "Batch [461] Completed\n",
      "Batch [462] Completed\n",
      "Batch [463] Completed\n",
      "Batch [464] Completed\n",
      "Batch [465] Completed\n",
      "Batch [466] Completed\n",
      "Batch [467] Completed\n",
      "Batch [468] Completed\n",
      "Batch [469] Completed\n",
      "Batch [470] Completed\n",
      "Batch [471] Completed\n",
      "Batch [472] Completed\n",
      "Batch [473] Completed\n",
      "Batch [474] Completed\n",
      "Batch [475] Completed\n",
      "Batch [476] Completed\n",
      "Batch [477] Completed\n",
      "Batch [478] Completed\n",
      "Batch [479] Completed\n",
      "Batch [480] Completed\n",
      "Batch [481] Completed\n",
      "Batch [482] Completed\n",
      "Batch [483] Completed\n",
      "Batch [484] Completed\n",
      "Batch [485] Completed\n",
      "Batch [486] Completed\n",
      "Batch [487] Completed\n",
      "Batch [488] Completed\n",
      "Batch [489] Completed\n",
      "Batch [490] Completed\n",
      "Batch [491] Completed\n",
      "Batch [492] Completed\n",
      "Batch [493] Completed\n",
      "Batch [494] Completed\n",
      "Batch [495] Completed\n",
      "Batch [496] Completed\n",
      "Batch [497] Completed\n",
      "Batch [498] Completed\n",
      "Batch [499] Completed\n",
      "Batch [500] Completed\n",
      "Batch [501] Completed\n",
      "Batch [502] Completed\n",
      "Batch [503] Completed\n",
      "Batch [504] Completed\n",
      "Batch [505] Completed\n",
      "Batch [506] Completed\n",
      "Batch [507] Completed\n",
      "Batch [508] Completed\n",
      "Batch [509] Completed\n",
      "Batch [510] Completed\n",
      "Batch [511] Completed\n",
      "Batch [512] Completed\n",
      "Batch [513] Completed\n",
      "Batch [514] Completed\n",
      "Batch [515] Completed\n",
      "Batch [516] Completed\n",
      "Batch [517] Completed\n",
      "Batch [518] Completed\n",
      "Batch [519] Completed\n",
      "Batch [520] Completed\n",
      "Batch [521] Completed\n",
      "Batch [522] Completed\n",
      "Batch [523] Completed\n",
      "Batch [524] Completed\n",
      "Batch [525] Completed\n",
      "Batch [526] Completed\n",
      "Batch [527] Completed\n",
      "Batch [528] Completed\n",
      "Batch [529] Completed\n",
      "Batch [530] Completed\n",
      "Batch [531] Completed\n",
      "Batch [532] Completed\n",
      "Batch [533] Completed\n",
      "Batch [534] Completed\n",
      "Batch [535] Completed\n",
      "Batch [536] Completed\n",
      "Batch [537] Completed\n",
      "Batch [538] Completed\n",
      "Batch [539] Completed\n",
      "Batch [540] Completed\n",
      "Batch [541] Completed\n",
      "Batch [542] Completed\n",
      "Batch [543] Completed\n",
      "Batch [544] Completed\n",
      "Batch [545] Completed\n",
      "Batch [546] Completed\n",
      "Batch [547] Completed\n",
      "Batch [548] Completed\n",
      "Batch [549] Completed\n",
      "Batch [550] Completed\n",
      "Batch [551] Completed\n",
      "Batch [552] Completed\n",
      "Batch [553] Completed\n",
      "Batch [554] Completed\n",
      "Batch [555] Completed\n",
      "Batch [556] Completed\n",
      "Batch [557] Completed\n",
      "Batch [558] Completed\n",
      "Batch [559] Completed\n",
      "Batch [560] Completed\n",
      "Batch [561] Completed\n",
      "Batch [562] Completed\n",
      "Batch [563] Completed\n",
      "Batch [564] Completed\n",
      "Batch [565] Completed\n",
      "Batch [566] Completed\n",
      "Batch [567] Completed\n",
      "Batch [568] Completed\n",
      "Batch [569] Completed\n",
      "Batch [570] Completed\n",
      "Batch [571] Completed\n",
      "Batch [572] Completed\n",
      "Batch [573] Completed\n",
      "Batch [574] Completed\n",
      "Batch [575] Completed\n",
      "Batch [576] Completed\n",
      "Batch [577] Completed\n",
      "Batch [578] Completed\n",
      "Batch [579] Completed\n",
      "Batch [580] Completed\n",
      "Batch [581] Completed\n",
      "Batch [582] Completed\n",
      "Batch [583] Completed\n",
      "Batch [584] Completed\n",
      "Batch [585] Completed\n",
      "Batch [586] Completed\n",
      "Batch [587] Completed\n",
      "Batch [588] Completed\n",
      "Batch [589] Completed\n",
      "Batch [590] Completed\n",
      "Batch [591] Completed\n",
      "Batch [592] Completed\n",
      "Batch [593] Completed\n",
      "Batch [594] Completed\n",
      "Batch [595] Completed\n",
      "Batch [596] Completed\n",
      "Batch [597] Completed\n",
      "Batch [598] Completed\n",
      "Batch [599] Completed\n",
      "Batch [600] Completed\n",
      "Batch [601] Completed\n",
      "Batch [602] Completed\n",
      "Batch [603] Completed\n",
      "Batch [604] Completed\n",
      "Batch [605] Completed\n",
      "Batch [606] Completed\n",
      "Batch [607] Completed\n",
      "Batch [608] Completed\n",
      "Batch [609] Completed\n",
      "Batch [610] Completed\n",
      "Batch [611] Completed\n",
      "Batch [612] Completed\n",
      "Batch [613] Completed\n",
      "Batch [614] Completed\n",
      "Batch [615] Completed\n",
      "Batch [616] Completed\n",
      "Batch [617] Completed\n",
      "Batch [618] Completed\n",
      "Batch [619] Completed\n",
      "Batch [620] Completed\n",
      "Batch [621] Completed\n",
      "Batch [622] Completed\n",
      "Batch [623] Completed\n",
      "Batch [624] Completed\n",
      "Batch [625] Completed\n",
      "Batch [626] Completed\n",
      "Batch [627] Completed\n",
      "Batch [628] Completed\n",
      "Batch [629] Completed\n",
      "Batch [630] Completed\n",
      "Batch [631] Completed\n",
      "Batch [632] Completed\n",
      "Batch [633] Completed\n",
      "Batch [634] Completed\n",
      "Batch [635] Completed\n",
      "Batch [636] Completed\n",
      "Batch [637] Completed\n",
      "Batch [638] Completed\n",
      "Batch [639] Completed\n",
      "Batch [640] Completed\n",
      "Batch [641] Completed\n",
      "Batch [642] Completed\n",
      "Batch [643] Completed\n",
      "Batch [644] Completed\n",
      "Batch [645] Completed\n",
      "Batch [646] Completed\n",
      "Batch [647] Completed\n",
      "Batch [648] Completed\n",
      "Batch [649] Completed\n",
      "Batch [650] Completed\n",
      "Batch [651] Completed\n",
      "Batch [652] Completed\n",
      "Batch [653] Completed\n",
      "Batch [654] Completed\n",
      "Batch [655] Completed\n",
      "Batch [656] Completed\n",
      "Batch [657] Completed\n",
      "Batch [658] Completed\n",
      "Batch [659] Completed\n",
      "Batch [660] Completed\n",
      "Batch [661] Completed\n",
      "Batch [662] Completed\n",
      "Batch [663] Completed\n",
      "Batch [664] Completed\n",
      "Batch [665] Completed\n",
      "Batch [666] Completed\n",
      "Batch [667] Completed\n",
      "Batch [668] Completed\n",
      "Batch [669] Completed\n",
      "Batch [670] Completed\n",
      "Batch [671] Completed\n",
      "Batch [672] Completed\n",
      "Batch [673] Completed\n",
      "Batch [674] Completed\n",
      "Batch [675] Completed\n",
      "Batch [676] Completed\n",
      "Batch [677] Completed\n",
      "Batch [678] Completed\n",
      "Batch [679] Completed\n",
      "Batch [680] Completed\n",
      "Batch [681] Completed\n",
      "Batch [682] Completed\n",
      "Batch [683] Completed\n",
      "Batch [684] Completed\n",
      "Batch [685] Completed\n",
      "Batch [686] Completed\n",
      "Batch [687] Completed\n",
      "Batch [688] Completed\n",
      "Batch [689] Completed\n",
      "Batch [690] Completed\n",
      "Batch [691] Completed\n",
      "Batch [692] Completed\n",
      "Batch [693] Completed\n",
      "Batch [694] Completed\n",
      "Batch [695] Completed\n",
      "Batch [696] Completed\n",
      "Batch [697] Completed\n",
      "Batch [698] Completed\n",
      "Batch [699] Completed\n",
      "Batch [700] Completed\n",
      "Batch [701] Completed\n",
      "Batch [702] Completed\n",
      "Batch [703] Completed\n",
      "Batch [704] Completed\n",
      "Batch [705] Completed\n",
      "Batch [706] Completed\n",
      "Batch [707] Completed\n",
      "Batch [708] Completed\n",
      "Batch [709] Completed\n",
      "Batch [710] Completed\n",
      "Batch [711] Completed\n",
      "Batch [712] Completed\n",
      "Batch [713] Completed\n",
      "Batch [714] Completed\n",
      "Batch [715] Completed\n",
      "Batch [716] Completed\n",
      "Batch [717] Completed\n",
      "Batch [718] Completed\n",
      "Batch [719] Completed\n",
      "Batch [720] Completed\n",
      "Batch [721] Completed\n",
      "Batch [722] Completed\n",
      "Batch [723] Completed\n",
      "Batch [724] Completed\n",
      "Batch [725] Completed\n",
      "Batch [726] Completed\n",
      "Batch [727] Completed\n",
      "Batch [728] Completed\n",
      "Batch [729] Completed\n",
      "Batch [730] Completed\n",
      "Batch [731] Completed\n",
      "Batch [732] Completed\n",
      "Batch [733] Completed\n",
      "Batch [734] Completed\n",
      "Batch [735] Completed\n",
      "Batch [736] Completed\n",
      "Batch [737] Completed\n",
      "Batch [738] Completed\n",
      "Batch [739] Completed\n",
      "Batch [740] Completed\n",
      "Batch [741] Completed\n",
      "Batch [742] Completed\n",
      "Batch [743] Completed\n",
      "Batch [744] Completed\n",
      "Batch [745] Completed\n",
      "Batch [746] Completed\n",
      "Batch [747] Completed\n",
      "Batch [748] Completed\n",
      "Batch [749] Completed\n",
      "Batch [750] Completed\n",
      "Batch [751] Completed\n",
      "Batch [752] Completed\n",
      "Batch [753] Completed\n",
      "Batch [754] Completed\n",
      "Batch [755] Completed\n",
      "Batch [756] Completed\n",
      "Batch [757] Completed\n",
      "Batch [758] Completed\n",
      "Batch [759] Completed\n",
      "Batch [760] Completed\n",
      "Batch [761] Completed\n",
      "Batch [762] Completed\n",
      "Batch [763] Completed\n",
      "Batch [764] Completed\n",
      "Batch [765] Completed\n",
      "Batch [766] Completed\n",
      "Batch [767] Completed\n",
      "Batch [768] Completed\n",
      "Batch [769] Completed\n",
      "Batch [770] Completed\n",
      "Batch [771] Completed\n",
      "Batch [772] Completed\n",
      "Batch [773] Completed\n",
      "Batch [774] Completed\n",
      "Batch [775] Completed\n",
      "Batch [776] Completed\n",
      "Batch [777] Completed\n",
      "Batch [778] Completed\n",
      "Batch [779] Completed\n",
      "Batch [780] Completed\n",
      "Batch [781] Completed\n",
      "Batch [782] Completed\n",
      "Batch [783] Completed\n",
      "Batch [784] Completed\n",
      "Batch [785] Completed\n",
      "Batch [786] Completed\n",
      "Batch [787] Completed\n",
      "Batch [788] Completed\n",
      "Batch [789] Completed\n",
      "Batch [790] Completed\n",
      "Batch [791] Completed\n",
      "Batch [792] Completed\n",
      "Batch [793] Completed\n",
      "Batch [794] Completed\n",
      "Batch [795] Completed\n",
      "Batch [796] Completed\n",
      "Batch [797] Completed\n",
      "Batch [798] Completed\n",
      "Batch [799] Completed\n",
      "Batch [800] Completed\n",
      "Batch [801] Completed\n",
      "Batch [802] Completed\n",
      "Batch [803] Completed\n",
      "Batch [804] Completed\n",
      "Batch [805] Completed\n",
      "Batch [806] Completed\n",
      "Batch [807] Completed\n",
      "Batch [808] Completed\n",
      "Batch [809] Completed\n",
      "Batch [810] Completed\n",
      "Batch [811] Completed\n",
      "Batch [812] Completed\n",
      "Batch [813] Completed\n",
      "Batch [814] Completed\n",
      "Batch [815] Completed\n",
      "Batch [816] Completed\n",
      "Batch [817] Completed\n",
      "Batch [818] Completed\n",
      "Batch [819] Completed\n",
      "Batch [820] Completed\n",
      "Batch [821] Completed\n",
      "Batch [822] Completed\n",
      "Batch [823] Completed\n",
      "Batch [824] Completed\n",
      "Batch [825] Completed\n",
      "Batch [826] Completed\n",
      "Batch [827] Completed\n",
      "Batch [828] Completed\n",
      "Batch [829] Completed\n",
      "Batch [830] Completed\n",
      "Batch [831] Completed\n",
      "Batch [832] Completed\n",
      "Batch [833] Completed\n",
      "Batch [834] Completed\n",
      "Batch [835] Completed\n",
      "Batch [836] Completed\n",
      "Batch [837] Completed\n",
      "Batch [838] Completed\n",
      "Batch [839] Completed\n",
      "Batch [840] Completed\n",
      "Batch [841] Completed\n",
      "Batch [842] Completed\n",
      "Batch [843] Completed\n",
      "Batch [844] Completed\n",
      "Batch [845] Completed\n",
      "Batch [846] Completed\n",
      "Batch [847] Completed\n",
      "Batch [848] Completed\n",
      "Batch [849] Completed\n",
      "Batch [850] Completed\n",
      "Batch [851] Completed\n",
      "Batch [852] Completed\n",
      "Batch [853] Completed\n",
      "Batch [854] Completed\n",
      "Batch [855] Completed\n",
      "Batch [856] Completed\n",
      "Batch [857] Completed\n",
      "Batch [858] Completed\n",
      "Batch [859] Completed\n",
      "Batch [860] Completed\n",
      "Batch [861] Completed\n",
      "Batch [862] Completed\n",
      "Batch [863] Completed\n",
      "Batch [864] Completed\n",
      "Batch [865] Completed\n",
      "Batch [866] Completed\n",
      "Batch [867] Completed\n",
      "Batch [868] Completed\n",
      "Batch [869] Completed\n",
      "Batch [870] Completed\n",
      "Batch [871] Completed\n",
      "Batch [872] Completed\n",
      "Batch [873] Completed\n",
      "Batch [874] Completed\n",
      "Batch [875] Completed\n",
      "Batch [876] Completed\n",
      "Batch [877] Completed\n",
      "Batch [878] Completed\n",
      "Batch [879] Completed\n",
      "Batch [880] Completed\n",
      "Batch [881] Completed\n",
      "Batch [882] Completed\n",
      "Batch [883] Completed\n",
      "Batch [884] Completed\n",
      "Batch [885] Completed\n",
      "Batch [886] Completed\n",
      "Batch [887] Completed\n",
      "Batch [888] Completed\n",
      "Batch [889] Completed\n",
      "Batch [890] Completed\n",
      "Batch [891] Completed\n",
      "Batch [892] Completed\n",
      "Batch [893] Completed\n",
      "Batch [894] Completed\n",
      "Batch [895] Completed\n",
      "Batch [896] Completed\n",
      "Batch [897] Completed\n",
      "Batch [898] Completed\n",
      "Batch [899] Completed\n",
      "Batch [900] Completed\n",
      "Batch [901] Completed\n",
      "Batch [902] Completed\n",
      "Batch [903] Completed\n",
      "Batch [904] Completed\n",
      "Batch [905] Completed\n",
      "Batch [906] Completed\n",
      "Batch [907] Completed\n",
      "Batch [908] Completed\n",
      "Batch [909] Completed\n",
      "Batch [910] Completed\n",
      "Batch [911] Completed\n",
      "Batch [912] Completed\n",
      "Batch [913] Completed\n",
      "Batch [914] Completed\n",
      "Batch [915] Completed\n",
      "Batch [916] Completed\n",
      "Batch [917] Completed\n",
      "Batch [918] Completed\n",
      "Batch [919] Completed\n",
      "Batch [920] Completed\n",
      "Batch [921] Completed\n",
      "Batch [922] Completed\n",
      "Batch [923] Completed\n",
      "Batch [924] Completed\n",
      "Batch [925] Completed\n",
      "Batch [926] Completed\n",
      "Batch [927] Completed\n",
      "Batch [928] Completed\n",
      "Batch [929] Completed\n",
      "Batch [930] Completed\n",
      "Batch [931] Completed\n",
      "Batch [932] Completed\n",
      "Batch [933] Completed\n",
      "Batch [934] Completed\n",
      "Batch [935] Completed\n",
      "Batch [936] Completed\n",
      "Batch [937] Completed\n",
      "Batch [938] Completed\n",
      "Batch [939] Completed\n",
      "Batch [940] Completed\n",
      "Batch [941] Completed\n",
      "Batch [942] Completed\n",
      "Batch [943] Completed\n",
      "Batch [944] Completed\n",
      "Batch [945] Completed\n",
      "Batch [946] Completed\n",
      "Batch [947] Completed\n",
      "Batch [948] Completed\n",
      "Batch [949] Completed\n",
      "Batch [950] Completed\n",
      "Batch [951] Completed\n",
      "Batch [952] Completed\n",
      "Batch [953] Completed\n",
      "Batch [954] Completed\n",
      "Batch [955] Completed\n",
      "Batch [956] Completed\n",
      "Batch [957] Completed\n",
      "Batch [958] Completed\n",
      "Batch [959] Completed\n",
      "Batch [960] Completed\n",
      "Batch [961] Completed\n",
      "Batch [962] Completed\n",
      "Batch [963] Completed\n",
      "Batch [964] Completed\n",
      "Batch [965] Completed\n",
      "Batch [966] Completed\n",
      "Batch [967] Completed\n",
      "Batch [968] Completed\n",
      "Batch [969] Completed\n",
      "Batch [970] Completed\n",
      "Batch [971] Completed\n",
      "Batch [972] Completed\n",
      "Batch [973] Completed\n",
      "Batch [974] Completed\n",
      "Batch [975] Completed\n",
      "Batch [976] Completed\n",
      "Batch [977] Completed\n",
      "Batch [978] Completed\n",
      "Batch [979] Completed\n",
      "Batch [980] Completed\n",
      "Batch [981] Completed\n",
      "Batch [982] Completed\n",
      "Batch [983] Completed\n",
      "Batch [984] Completed\n",
      "Batch [985] Completed\n",
      "Batch [986] Completed\n",
      "Batch [987] Completed\n",
      "Batch [988] Completed\n",
      "Batch [989] Completed\n",
      "Batch [990] Completed\n",
      "Batch [991] Completed\n",
      "Batch [992] Completed\n",
      "Batch [993] Completed\n",
      "Batch [994] Completed\n",
      "Batch [995] Completed\n",
      "Batch [996] Completed\n",
      "Batch [997] Completed\n",
      "Batch [998] Completed\n",
      "Batch [999] Completed\n",
      "Batch [1000] Completed\n",
      "Batch [1001] Completed\n",
      "Batch [1002] Completed\n",
      "Batch [1003] Completed\n",
      "Batch [1004] Completed\n",
      "Batch [1005] Completed\n",
      "Batch [1006] Completed\n",
      "Batch [1007] Completed\n",
      "Batch [1008] Completed\n",
      "Batch [1009] Completed\n",
      "Batch [1010] Completed\n",
      "Batch [1011] Completed\n",
      "Batch [1012] Completed\n",
      "Batch [1013] Completed\n",
      "Batch [1014] Completed\n",
      "Batch [1015] Completed\n",
      "Batch [1016] Completed\n",
      "Batch [1017] Completed\n",
      "Batch [1018] Completed\n",
      "Batch [1019] Completed\n",
      "Batch [1020] Completed\n",
      "Batch [1021] Completed\n",
      "Batch [1022] Completed\n",
      "Batch [1023] Completed\n",
      "Batch [1024] Completed\n",
      "Batch [1025] Completed\n",
      "Batch [1026] Completed\n",
      "Batch [1027] Completed\n",
      "Batch [1028] Completed\n",
      "Batch [1029] Completed\n",
      "Batch [1030] Completed\n",
      "Batch [1031] Completed\n",
      "Batch [1032] Completed\n",
      "Batch [1033] Completed\n",
      "Batch [1034] Completed\n",
      "Batch [1035] Completed\n",
      "Batch [1036] Completed\n",
      "Batch [1037] Completed\n",
      "Batch [1038] Completed\n",
      "Batch [1039] Completed\n",
      "Batch [1040] Completed\n",
      "Batch [1041] Completed\n",
      "Batch [1042] Completed\n",
      "Batch [1043] Completed\n",
      "Batch [1044] Completed\n",
      "Batch [1045] Completed\n",
      "Batch [1046] Completed\n",
      "Batch [1047] Completed\n",
      "Batch [1048] Completed\n",
      "Batch [1049] Completed\n",
      "Batch [1050] Completed\n",
      "Batch [1051] Completed\n",
      "Batch [1052] Completed\n",
      "Batch [1053] Completed\n",
      "Batch [1054] Completed\n",
      "Batch [1055] Completed\n",
      "Batch [1056] Completed\n",
      "Batch [1057] Completed\n",
      "Batch [1058] Completed\n",
      "Batch [1059] Completed\n",
      "Batch [1060] Completed\n",
      "Batch [1061] Completed\n",
      "Batch [1062] Completed\n",
      "Batch [1063] Completed\n",
      "Batch [1064] Completed\n",
      "Batch [1065] Completed\n",
      "Batch [1066] Completed\n",
      "Batch [1067] Completed\n",
      "Batch [1068] Completed\n",
      "Batch [1069] Completed\n",
      "Batch [1070] Completed\n",
      "Batch [1071] Completed\n",
      "Batch [1072] Completed\n",
      "Batch [1073] Completed\n",
      "Batch [1074] Completed\n",
      "Batch [1075] Completed\n",
      "Batch [1076] Completed\n",
      "Batch [1077] Completed\n",
      "Batch [1078] Completed\n",
      "Batch [1079] Completed\n",
      "Batch [1080] Completed\n",
      "Batch [1081] Completed\n",
      "Batch [1082] Completed\n",
      "Batch [1083] Completed\n",
      "Batch [1084] Completed\n",
      "Batch [1085] Completed\n",
      "Batch [1086] Completed\n",
      "Batch [1087] Completed\n",
      "Batch [1088] Completed\n",
      "Batch [1089] Completed\n",
      "Batch [1090] Completed\n",
      "Batch [1091] Completed\n",
      "Batch [1092] Completed\n",
      "Batch [1093] Completed\n",
      "Batch [1094] Completed\n",
      "Batch [1095] Completed\n",
      "Batch [1096] Completed\n",
      "Batch [1097] Completed\n",
      "Batch [1098] Completed\n",
      "Batch [1099] Completed\n",
      "Batch [1100] Completed\n",
      "Batch [1101] Completed\n",
      "Batch [1102] Completed\n",
      "Batch [1103] Completed\n",
      "Batch [1104] Completed\n",
      "Batch [1105] Completed\n",
      "Batch [1106] Completed\n",
      "Batch [1107] Completed\n",
      "Batch [1108] Completed\n",
      "Batch [1109] Completed\n",
      "Batch [1110] Completed\n",
      "Batch [1111] Completed\n",
      "Batch [1112] Completed\n",
      "Batch [1113] Completed\n",
      "Batch [1114] Completed\n",
      "Batch [1115] Completed\n",
      "Batch [1116] Completed\n",
      "Batch [1117] Completed\n",
      "Batch [1118] Completed\n",
      "Batch [1119] Completed\n",
      "Batch [1120] Completed\n",
      "Batch [1121] Completed\n",
      "Batch [1122] Completed\n",
      "Batch [1123] Completed\n",
      "Batch [1124] Completed\n",
      "Batch [1125] Completed\n",
      "Batch [1126] Completed\n",
      "Batch [1127] Completed\n",
      "Batch [1128] Completed\n",
      "Batch [1129] Completed\n",
      "Batch [1130] Completed\n",
      "Batch [1131] Completed\n",
      "Batch [1132] Completed\n",
      "Batch [1133] Completed\n",
      "Batch [1134] Completed\n",
      "Batch [1135] Completed\n",
      "Batch [1136] Completed\n",
      "Batch [1137] Completed\n",
      "Batch [1138] Completed\n",
      "Batch [1139] Completed\n",
      "Batch [1140] Completed\n",
      "Batch [1141] Completed\n",
      "Batch [1142] Completed\n",
      "Batch [1143] Completed\n",
      "Batch [1144] Completed\n",
      "Batch [1145] Completed\n",
      "Batch [1146] Completed\n",
      "Batch [1147] Completed\n",
      "Batch [1148] Completed\n",
      "Batch [1149] Completed\n",
      "Batch [1150] Completed\n",
      "Batch [1151] Completed\n",
      "Batch [1152] Completed\n",
      "Batch [1153] Completed\n",
      "Batch [1154] Completed\n",
      "Batch [1155] Completed\n",
      "Batch [1156] Completed\n",
      "Batch [1157] Completed\n",
      "Batch [1158] Completed\n",
      "Batch [1159] Completed\n",
      "Batch [1160] Completed\n",
      "Batch [1161] Completed\n",
      "Batch [1162] Completed\n",
      "Batch [1163] Completed\n",
      "Batch [1164] Completed\n",
      "Batch [1165] Completed\n",
      "Batch [1166] Completed\n",
      "Batch [1167] Completed\n",
      "Batch [1168] Completed\n",
      "Batch [1169] Completed\n",
      "Batch [1170] Completed\n",
      "Batch [1171] Completed\n",
      "Batch [1172] Completed\n",
      "Batch [1173] Completed\n",
      "Batch [1174] Completed\n",
      "Batch [1175] Completed\n",
      "Batch [1176] Completed\n",
      "Batch [1177] Completed\n",
      "Batch [1178] Completed\n",
      "Batch [1179] Completed\n",
      "Batch [1180] Completed\n",
      "Batch [1181] Completed\n",
      "Batch [1182] Completed\n",
      "Batch [1183] Completed\n",
      "Batch [1184] Completed\n",
      "Batch [1185] Completed\n",
      "Batch [1186] Completed\n",
      "Batch [1187] Completed\n",
      "Batch [1188] Completed\n",
      "Batch [1189] Completed\n",
      "Batch [1190] Completed\n",
      "Batch [1191] Completed\n",
      "Batch [1192] Completed\n",
      "Batch [1193] Completed\n",
      "Batch [1194] Completed\n",
      "Batch [1195] Completed\n",
      "Batch [1196] Completed\n",
      "Batch [1197] Completed\n",
      "Batch [1198] Completed\n",
      "Batch [1199] Completed\n",
      "Batch [1200] Completed\n",
      "Batch [1201] Completed\n",
      "Batch [1202] Completed\n",
      "Batch [1203] Completed\n",
      "Batch [1204] Completed\n",
      "Batch [1205] Completed\n",
      "Batch [1206] Completed\n",
      "Batch [1207] Completed\n",
      "Batch [1208] Completed\n",
      "Batch [1209] Completed\n",
      "Batch [1210] Completed\n",
      "Batch [1211] Completed\n",
      "Batch [1212] Completed\n",
      "Batch [1213] Completed\n",
      "Batch [1214] Completed\n",
      "Batch [1215] Completed\n",
      "Batch [1216] Completed\n",
      "Batch [1217] Completed\n",
      "Batch [1218] Completed\n",
      "Batch [1219] Completed\n",
      "Batch [1220] Completed\n",
      "Batch [1221] Completed\n",
      "Batch [1222] Completed\n",
      "Batch [1223] Completed\n",
      "Batch [1224] Completed\n",
      "Batch [1225] Completed\n",
      "Batch [1226] Completed\n",
      "Batch [1227] Completed\n",
      "Batch [1228] Completed\n",
      "Batch [1229] Completed\n",
      "Batch [1230] Completed\n",
      "Batch [1231] Completed\n",
      "Batch [1232] Completed\n",
      "Batch [1233] Completed\n",
      "Batch [1234] Completed\n",
      "Batch [1235] Completed\n",
      "Batch [1236] Completed\n",
      "Batch [1237] Completed\n",
      "Batch [1238] Completed\n",
      "Batch [1239] Completed\n",
      "Batch [1240] Completed\n",
      "Batch [1241] Completed\n",
      "Batch [1242] Completed\n",
      "Batch [1243] Completed\n",
      "Batch [1244] Completed\n",
      "Batch [1245] Completed\n",
      "Batch [1246] Completed\n",
      "Batch [1247] Completed\n",
      "Batch [1248] Completed\n",
      "Batch [1249] Completed\n",
      "Batch [1250] Completed\n",
      "Batch [1251] Completed\n",
      "Batch [1252] Completed\n",
      "Batch [1253] Completed\n",
      "Batch [1254] Completed\n",
      "Batch [1255] Completed\n",
      "Batch [1256] Completed\n",
      "Batch [1257] Completed\n",
      "Batch [1258] Completed\n",
      "Batch [1259] Completed\n",
      "Batch [1260] Completed\n",
      "Batch [1261] Completed\n",
      "Batch [1262] Completed\n",
      "Batch [1263] Completed\n",
      "Batch [1264] Completed\n",
      "Batch [1265] Completed\n",
      "Batch [1266] Completed\n",
      "Batch [1267] Completed\n",
      "Batch [1268] Completed\n",
      "Batch [1269] Completed\n",
      "Batch [1270] Completed\n",
      "Batch [1271] Completed\n",
      "Batch [1272] Completed\n",
      "Batch [1273] Completed\n",
      "Batch [1274] Completed\n",
      "Batch [1275] Completed\n",
      "Batch [1276] Completed\n",
      "Batch [1277] Completed\n",
      "Batch [1278] Completed\n",
      "Batch [1279] Completed\n",
      "Batch [1280] Completed\n",
      "Batch [1281] Completed\n",
      "Batch [1282] Completed\n",
      "Batch [1283] Completed\n",
      "Batch [1284] Completed\n",
      "Batch [1285] Completed\n",
      "Batch [1286] Completed\n",
      "Batch [1287] Completed\n",
      "Batch [1288] Completed\n",
      "Batch [1289] Completed\n",
      "Batch [1290] Completed\n",
      "Batch [1291] Completed\n",
      "Batch [1292] Completed\n",
      "Batch [1293] Completed\n",
      "Batch [1294] Completed\n",
      "Batch [1295] Completed\n",
      "Batch [1296] Completed\n",
      "Batch [1297] Completed\n",
      "Batch [1298] Completed\n",
      "Batch [1299] Completed\n",
      "Batch [1300] Completed\n",
      "Batch [1301] Completed\n",
      "Batch [1302] Completed\n",
      "Batch [1303] Completed\n",
      "Batch [1304] Completed\n",
      "Batch [1305] Completed\n",
      "Batch [1306] Completed\n",
      "Batch [1307] Completed\n",
      "Batch [1308] Completed\n",
      "Batch [1309] Completed\n",
      "Batch [1310] Completed\n",
      "Batch [1311] Completed\n",
      "Batch [1312] Completed\n",
      "Batch [1313] Completed\n",
      "Batch [1314] Completed\n",
      "Batch [1315] Completed\n",
      "Batch [1316] Completed\n",
      "Batch [1317] Completed\n",
      "Batch [1318] Completed\n",
      "Batch [1319] Completed\n",
      "Batch [1320] Completed\n",
      "Batch [1321] Completed\n",
      "Batch [1322] Completed\n",
      "Batch [1323] Completed\n",
      "Batch [1324] Completed\n",
      "Batch [1325] Completed\n",
      "Batch [1326] Completed\n",
      "Batch [1327] Completed\n",
      "Batch [1328] Completed\n",
      "Batch [1329] Completed\n",
      "Batch [1330] Completed\n",
      "Batch [1331] Completed\n",
      "Batch [1332] Completed\n",
      "Batch [1333] Completed\n",
      "Batch [1334] Completed\n",
      "Batch [1335] Completed\n",
      "Batch [1336] Completed\n",
      "Batch [1337] Completed\n",
      "Batch [1338] Completed\n",
      "Batch [1339] Completed\n",
      "Batch [1340] Completed\n",
      "Batch [1341] Completed\n",
      "Batch [1342] Completed\n",
      "Batch [1343] Completed\n",
      "Batch [1344] Completed\n",
      "Batch [1345] Completed\n",
      "Batch [1346] Completed\n",
      "Batch [1347] Completed\n",
      "Batch [1348] Completed\n",
      "Batch [1349] Completed\n",
      "Batch [1350] Completed\n",
      "Batch [1351] Completed\n",
      "Batch [1352] Completed\n",
      "Batch [1353] Completed\n",
      "Batch [1354] Completed\n",
      "Batch [1355] Completed\n",
      "Batch [1356] Completed\n",
      "Batch [1357] Completed\n",
      "Batch [1358] Completed\n",
      "Batch [1359] Completed\n",
      "Batch [1360] Completed\n",
      "Batch [1361] Completed\n",
      "Batch [1362] Completed\n",
      "Batch [1363] Completed\n",
      "Batch [1364] Completed\n",
      "Batch [1365] Completed\n",
      "Batch [1366] Completed\n",
      "Batch [1367] Completed\n",
      "Batch [1368] Completed\n",
      "Batch [1369] Completed\n",
      "Batch [1370] Completed\n",
      "Batch [1371] Completed\n",
      "Batch [1372] Completed\n",
      "Batch [1373] Completed\n",
      "Batch [1374] Completed\n",
      "Batch [1375] Completed\n",
      "Batch [1376] Completed\n",
      "Batch [1377] Completed\n",
      "Batch [1378] Completed\n",
      "Batch [1379] Completed\n",
      "Batch [1380] Completed\n",
      "Batch [1381] Completed\n",
      "Batch [1382] Completed\n",
      "Batch [1383] Completed\n",
      "Batch [1384] Completed\n",
      "Batch [1385] Completed\n",
      "Batch [1386] Completed\n",
      "Batch [1387] Completed\n",
      "Batch [1388] Completed\n",
      "Batch [1389] Completed\n",
      "Batch [1390] Completed\n",
      "Batch [1391] Completed\n",
      "Batch [1392] Completed\n",
      "Batch [1393] Completed\n",
      "Batch [1394] Completed\n",
      "Batch [1395] Completed\n",
      "Batch [1396] Completed\n",
      "Batch [1397] Completed\n",
      "Batch [1398] Completed\n",
      "Batch [1399] Completed\n",
      "Batch [1400] Completed\n",
      "Batch [1401] Completed\n",
      "Batch [1402] Completed\n",
      "Batch [1403] Completed\n",
      "Batch [1404] Completed\n",
      "Batch [1405] Completed\n",
      "Batch [1406] Completed\n",
      "Batch [1407] Completed\n",
      "Batch [1408] Completed\n",
      "Batch [1409] Completed\n",
      "Batch [1410] Completed\n",
      "Batch [1411] Completed\n",
      "Batch [1412] Completed\n",
      "Batch [1413] Completed\n",
      "Batch [1414] Completed\n",
      "Batch [1415] Completed\n",
      "Batch [1416] Completed\n",
      "Batch [1417] Completed\n",
      "Batch [1418] Completed\n",
      "Batch [1419] Completed\n",
      "Batch [1420] Completed\n",
      "Batch [1421] Completed\n",
      "Batch [1422] Completed\n",
      "Batch [1423] Completed\n",
      "Batch [1424] Completed\n",
      "Batch [1425] Completed\n",
      "Batch [1426] Completed\n",
      "Batch [1427] Completed\n",
      "Batch [1428] Completed\n",
      "Batch [1429] Completed\n",
      "Batch [1430] Completed\n",
      "Batch [1431] Completed\n",
      "Batch [1432] Completed\n",
      "Batch [1433] Completed\n",
      "Batch [1434] Completed\n",
      "Batch [1435] Completed\n",
      "Batch [1436] Completed\n",
      "Batch [1437] Completed\n",
      "Batch [1438] Completed\n",
      "Batch [1439] Completed\n",
      "Batch [1440] Completed\n",
      "Batch [1441] Completed\n",
      "Batch [1442] Completed\n",
      "Batch [1443] Completed\n",
      "Batch [1444] Completed\n",
      "Batch [1445] Completed\n",
      "Batch [1446] Completed\n",
      "Batch [1447] Completed\n",
      "Batch [1448] Completed\n",
      "Batch [1449] Completed\n",
      "Batch [1450] Completed\n",
      "Batch [1451] Completed\n",
      "Batch [1452] Completed\n",
      "Batch [1453] Completed\n",
      "Batch [1454] Completed\n",
      "Batch [1455] Completed\n",
      "Batch [1456] Completed\n",
      "Batch [1457] Completed\n",
      "Batch [1458] Completed\n",
      "Batch [1459] Completed\n",
      "Batch [1460] Completed\n",
      "Batch [1461] Completed\n",
      "Batch [1462] Completed\n",
      "Batch [1463] Completed\n",
      "Batch [1464] Completed\n",
      "Batch [1465] Completed\n",
      "Batch [1466] Completed\n",
      "Batch [1467] Completed\n",
      "Batch [1468] Completed\n",
      "Batch [1469] Completed\n",
      "Batch [1470] Completed\n",
      "Batch [1471] Completed\n",
      "Batch [1472] Completed\n",
      "Batch [1473] Completed\n",
      "Batch [1474] Completed\n",
      "Batch [1475] Completed\n",
      "Batch [1476] Completed\n",
      "Batch [1477] Completed\n",
      "Batch [1478] Completed\n",
      "Batch [1479] Completed\n",
      "Batch [1480] Completed\n",
      "Batch [1481] Completed\n",
      "Batch [1482] Completed\n",
      "Batch [1483] Completed\n",
      "Batch [1484] Completed\n",
      "Batch [1485] Completed\n",
      "Batch [1486] Completed\n",
      "Batch [1487] Completed\n",
      "Batch [1488] Completed\n",
      "Batch [1489] Completed\n",
      "Batch [1490] Completed\n",
      "Batch [1491] Completed\n",
      "Batch [1492] Completed\n",
      "Batch [1493] Completed\n",
      "Batch [1494] Completed\n",
      "Batch [1495] Completed\n",
      "Batch [1496] Completed\n",
      "Batch [1497] Completed\n",
      "Batch [1498] Completed\n",
      "Batch [1499] Completed\n",
      "Batch [1500] Completed\n",
      "Batch [1501] Completed\n",
      "Batch [1502] Completed\n",
      "Batch [1503] Completed\n",
      "Batch [1504] Completed\n",
      "Batch [1505] Completed\n",
      "Batch [1506] Completed\n",
      "Batch [1507] Completed\n",
      "Batch [1508] Completed\n",
      "Batch [1509] Completed\n",
      "Batch [1510] Completed\n",
      "Batch [1511] Completed\n",
      "Batch [1512] Completed\n",
      "Batch [1513] Completed\n",
      "Batch [1514] Completed\n",
      "Batch [1515] Completed\n",
      "Batch [1516] Completed\n",
      "Batch [1517] Completed\n",
      "Batch [1518] Completed\n",
      "Batch [1519] Completed\n",
      "Batch [1520] Completed\n",
      "Batch [1521] Completed\n",
      "Batch [1522] Completed\n",
      "Batch [1523] Completed\n",
      "Batch [1524] Completed\n",
      "Batch [1525] Completed\n",
      "Batch [1526] Completed\n",
      "Batch [1527] Completed\n",
      "Batch [1528] Completed\n",
      "Batch [1529] Completed\n",
      "Batch [1530] Completed\n",
      "Batch [1531] Completed\n",
      "Batch [1532] Completed\n",
      "Batch [1533] Completed\n",
      "Batch [1534] Completed\n",
      "Batch [1535] Completed\n",
      "Batch [1536] Completed\n",
      "Batch [1537] Completed\n",
      "Batch [1538] Completed\n",
      "Batch [1539] Completed\n",
      "Batch [1540] Completed\n",
      "Batch [1541] Completed\n",
      "Batch [1542] Completed\n",
      "Batch [1543] Completed\n",
      "Batch [1544] Completed\n",
      "Batch [1545] Completed\n",
      "Batch [1546] Completed\n",
      "Batch [1547] Completed\n",
      "Batch [1548] Completed\n",
      "Batch [1549] Completed\n",
      "Batch [1550] Completed\n",
      "Batch [1551] Completed\n",
      "Batch [1552] Completed\n",
      "Batch [1553] Completed\n",
      "Batch [1554] Completed\n",
      "Batch [1555] Completed\n",
      "Batch [1556] Completed\n",
      "Batch [1557] Completed\n",
      "Batch [1558] Completed\n",
      "Batch [1559] Completed\n",
      "Batch [1560] Completed\n",
      "Batch [1561] Completed\n",
      "Batch [1562] Completed\n",
      "Batch [1563] Completed\n",
      "Batch [1564] Completed\n",
      "Batch [1565] Completed\n",
      "Batch [1566] Completed\n",
      "Batch [1567] Completed\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 122] Disk quota exceeded",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/numpy/lib/npyio.py:502\u001b[0m, in \u001b[0;36msave\u001b[0;34m(file, arr, allow_pickle, fix_imports)\u001b[0m\n\u001b[1;32m    501\u001b[0m arr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masanyarray(arr)\n\u001b[0;32m--> 502\u001b[0m \u001b[39mformat\u001b[39;49m\u001b[39m.\u001b[39;49mwrite_array(fid, arr, allow_pickle\u001b[39m=\u001b[39;49mallow_pickle,\n\u001b[1;32m    503\u001b[0m                    pickle_kwargs\u001b[39m=\u001b[39;49m\u001b[39mdict\u001b[39;49m(fix_imports\u001b[39m=\u001b[39;49mfix_imports))\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/numpy/lib/format.py:689\u001b[0m, in \u001b[0;36mwrite_array\u001b[0;34m(fp, array, version, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[39mif\u001b[39;00m isfileobj(fp):\n\u001b[0;32m--> 689\u001b[0m     array\u001b[39m.\u001b[39;49mtofile(fp)\n\u001b[1;32m    690\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mOSError\u001b[0m: 25550511 requested and 0 written",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [23], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m## ACTUAL EXPERIMENT\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m## TIME AND MEMORY CONSUMING\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m logit_extractor(batch \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m, \u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49m input_ids_list, from_index\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn [22], line 21\u001b[0m, in \u001b[0;36mlogit_extractor\u001b[0;34m(batch, input, from_index)\u001b[0m\n\u001b[1;32m     19\u001b[0m current_batch \u001b[39m=\u001b[39m idx \u001b[39m+\u001b[39m (from_index\u001b[39m/\u001b[39m\u001b[39m/\u001b[39mbatch)\n\u001b[1;32m     20\u001b[0m \u001b[39mfor\u001b[39;00m jdx, o_logits \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m( output_logits ):\n\u001b[0;32m---> 21\u001b[0m     np\u001b[39m.\u001b[39;49msave( parameters[\u001b[39m'\u001b[39;49m\u001b[39mcallbacks\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m+\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39m/\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m+\u001b[39;49mparameters[\u001b[39m'\u001b[39;49m\u001b[39mmodel_name\u001b[39;49m\u001b[39m'\u001b[39;49m]  \u001b[39m+\u001b[39;49m \u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m_logits_tensor[\u001b[39;49m\u001b[39m{\u001b[39;49;00mjdx\u001b[39m+\u001b[39;49mn\u001b[39m}\u001b[39;49;00m\u001b[39m]_batch[\u001b[39;49m\u001b[39m{\u001b[39;49;00mcurrent_batch\u001b[39m}\u001b[39;49;00m\u001b[39m].npy\u001b[39;49m\u001b[39m'\u001b[39;49m, o_logits)\n\u001b[1;32m     22\u001b[0m np\u001b[39m.\u001b[39msave( parameters[\u001b[39m'\u001b[39m\u001b[39mcallbacks\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39mparameters[\u001b[39m'\u001b[39m\u001b[39mmodel_name\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m+\u001b[39m\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m_loss_batch[\u001b[39m\u001b[39m{\u001b[39;00mcurrent_batch\u001b[39m}\u001b[39;00m\u001b[39m].npy\u001b[39m\u001b[39m'\u001b[39m, output_loss)\n\u001b[1;32m     24\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBatch [\u001b[39m\u001b[39m{\u001b[39;00mcurrent_batch\u001b[39m}\u001b[39;00m\u001b[39m] Completed\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36msave\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/numpy/lib/npyio.py:502\u001b[0m, in \u001b[0;36msave\u001b[0;34m(file, arr, allow_pickle, fix_imports)\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[39mwith\u001b[39;00m file_ctx \u001b[39mas\u001b[39;00m fid:\n\u001b[1;32m    501\u001b[0m     arr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masanyarray(arr)\n\u001b[0;32m--> 502\u001b[0m     \u001b[39mformat\u001b[39m\u001b[39m.\u001b[39mwrite_array(fid, arr, allow_pickle\u001b[39m=\u001b[39mallow_pickle,\n\u001b[1;32m    503\u001b[0m                        pickle_kwargs\u001b[39m=\u001b[39m\u001b[39mdict\u001b[39m(fix_imports\u001b[39m=\u001b[39mfix_imports))\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 122] Disk quota exceeded"
     ]
    }
   ],
   "source": [
    "## ACTUAL EXPERIMENT\n",
    "## TIME AND MEMORY CONSUMING\n",
    "logit_extractor(\n",
    "    batch = 1, \n",
    "    input = tf_input_ids, \n",
    "    from_index=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logit_extractor(batch =2, input= input_ids_list[:2]) #<---- [WARNING TIME AND MEMORY CONSUMING]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_logits = np.load('../data/callbacks/logits_tensor[0]_batch[0].npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assert output_logits.shape[0] == len(input_ids_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_loss = np.load('../data/callbacks/loss_batch[0].npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
