{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#physical_devices = tf.config.list_physical_devices('CPU')\n",
    "physical_devices = tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)\n",
    "physical_devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8123, 0.9864, 0.4598],\n",
      "        [0.9068, 0.1735, 0.5945],\n",
      "        [0.6450, 0.6027, 0.6310],\n",
      "        [0.8930, 0.6163, 0.6383],\n",
      "        [0.3693, 0.4441, 0.9488]])\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "import torch\n",
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Nov 23 14:51:50 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.103.01   Driver Version: 470.103.01   CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100-PCI...  Off  | 00000000:61:00.0 Off |                    0 |\n",
      "| N/A   32C    P0    33W / 250W |      3MiB / 40536MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "#! pip install transformers\n",
    "#! conda install pytorch torchvision torchaudio cudatoolkit=10.1 -c pytorch\n",
    "#! pip3 install torch==1.7.0 torchvision==0.8.1 -f https://download.pytorch.org/whl/cu101/torch_stable.html\n",
    "#! pip install tensorflow\n",
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logits Extractor\n",
    ">\n",
    "> Extracting Tensor Logits from a given Neural Code Model @danaderp\n",
    ">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def params(): \n",
    "    return {\n",
    "                'big_table_path' : '/workspaces/CausalCodeCapability/data/' \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspaces/CausalCodeCapability/experimental_notebooks'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip list\n",
    "#! pip install git+https://github.com/huggingface/transfomers.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "409c5d799444446eb0f6ef4a8d536d6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/0.98k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e2e994cf62043d9b588ee39cd0ad943",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/502M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85c336a65f5d42808ac10a3234488b91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/560 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ab899287073436ba0f56dc6629451b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d413f7b681384879a91dc8500d9be3a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "598878df01e943cdaf57b6cd744735ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/357 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#tokenizer = AutoTokenizer.from_pretrained(\"Salesforce/codegen-2B-mono\")\n",
    "#tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-j-6B\")\n",
    "#generator = pipeline('text-generation', model='EleutherAI/gpt-neo-1.3B')\n",
    "#model = AutoModelForCausalLM.from_pretrained(\"EleutherAI/gpt-j-6B\")\n",
    "generator = pipeline('text-generation', model='EleutherAI/gpt-neo-125M')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator2 = pipeline('text-generation', model='EleutherAI/gpt-neo-1.3B')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'EleutherAI has reported that the EY-like Ewingle and B2-like E'}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\"EleutherAI has\", do_sample=True, min_length=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'for(int i=  0;  i<=i+1; i++) { '}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\"for(int i= \", do_sample=True, min_length=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'for(int i=   0; i< 3; i++) { // start of iteration 4:\\n                System.out.println(i+1);\\n '}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator2(\"for(int i= \", do_sample=True, min_length=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GPT2TokenizerFast' object has no attribute 'get_vocab_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgenerator2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_vocab_size\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GPT2TokenizerFast' object has no attribute 'get_vocab_size'"
     ]
    }
   ],
   "source": [
    "\n",
    "generator2.tokenizer.get_vocab_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.pipelines.text_generation.TextGenerationPipeline"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(generator2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPTNeoForCausalLM, GPT2Tokenizer\n",
    "model = GPTNeoForCausalLM.from_pretrained(\"EleutherAI/gpt-neo-1.3B\")\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"EleutherAI/gpt-neo-1.3B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.models.gpt_neo.modeling_gpt_neo.GPTNeoForCausalLM"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'!': 0,\n",
       " '\"': 1,\n",
       " '#': 2,\n",
       " '$': 3,\n",
       " '%': 4,\n",
       " '&': 5,\n",
       " \"'\": 6,\n",
       " '(': 7,\n",
       " ')': 8,\n",
       " '*': 9,\n",
       " '+': 10,\n",
       " ',': 11,\n",
       " '-': 12,\n",
       " '.': 13,\n",
       " '/': 14,\n",
       " '0': 15,\n",
       " '1': 16,\n",
       " '2': 17,\n",
       " '3': 18,\n",
       " '4': 19,\n",
       " '5': 20,\n",
       " '6': 21,\n",
       " '7': 22,\n",
       " '8': 23,\n",
       " '9': 24,\n",
       " ':': 25,\n",
       " ';': 26,\n",
       " '<': 27,\n",
       " '=': 28,\n",
       " '>': 29,\n",
       " '?': 30,\n",
       " '@': 31,\n",
       " 'A': 32,\n",
       " 'B': 33,\n",
       " 'C': 34,\n",
       " 'D': 35,\n",
       " 'E': 36,\n",
       " 'F': 37,\n",
       " 'G': 38,\n",
       " 'H': 39,\n",
       " 'I': 40,\n",
       " 'J': 41,\n",
       " 'K': 42,\n",
       " 'L': 43,\n",
       " 'M': 44,\n",
       " 'N': 45,\n",
       " 'O': 46,\n",
       " 'P': 47,\n",
       " 'Q': 48,\n",
       " 'R': 49,\n",
       " 'S': 50,\n",
       " 'T': 51,\n",
       " 'U': 52,\n",
       " 'V': 53,\n",
       " 'W': 54,\n",
       " 'X': 55,\n",
       " 'Y': 56,\n",
       " 'Z': 57,\n",
       " '[': 58,\n",
       " '\\\\': 59,\n",
       " ']': 60,\n",
       " '^': 61,\n",
       " '_': 62,\n",
       " '`': 63,\n",
       " 'a': 64,\n",
       " 'b': 65,\n",
       " 'c': 66,\n",
       " 'd': 67,\n",
       " 'e': 68,\n",
       " 'f': 69,\n",
       " 'g': 70,\n",
       " 'h': 71,\n",
       " 'i': 72,\n",
       " 'j': 73,\n",
       " 'k': 74,\n",
       " 'l': 75,\n",
       " 'm': 76,\n",
       " 'n': 77,\n",
       " 'o': 78,\n",
       " 'p': 79,\n",
       " 'q': 80,\n",
       " 'r': 81,\n",
       " 's': 82,\n",
       " 't': 83,\n",
       " 'u': 84,\n",
       " 'v': 85,\n",
       " 'w': 86,\n",
       " 'x': 87,\n",
       " 'y': 88,\n",
       " 'z': 89,\n",
       " '{': 90,\n",
       " '|': 91,\n",
       " '}': 92,\n",
       " '~': 93,\n",
       " '¡': 94,\n",
       " '¢': 95,\n",
       " '£': 96,\n",
       " '¤': 97,\n",
       " '¥': 98,\n",
       " '¦': 99,\n",
       " '§': 100,\n",
       " '¨': 101,\n",
       " '©': 102,\n",
       " 'ª': 103,\n",
       " '«': 104,\n",
       " '¬': 105,\n",
       " '®': 106,\n",
       " '¯': 107,\n",
       " '°': 108,\n",
       " '±': 109,\n",
       " '²': 110,\n",
       " '³': 111,\n",
       " '´': 112,\n",
       " 'µ': 113,\n",
       " '¶': 114,\n",
       " '·': 115,\n",
       " '¸': 116,\n",
       " '¹': 117,\n",
       " 'º': 118,\n",
       " '»': 119,\n",
       " '¼': 120,\n",
       " '½': 121,\n",
       " '¾': 122,\n",
       " '¿': 123,\n",
       " 'À': 124,\n",
       " 'Á': 125,\n",
       " 'Â': 126,\n",
       " 'Ã': 127,\n",
       " 'Ä': 128,\n",
       " 'Å': 129,\n",
       " 'Æ': 130,\n",
       " 'Ç': 131,\n",
       " 'È': 132,\n",
       " 'É': 133,\n",
       " 'Ê': 134,\n",
       " 'Ë': 135,\n",
       " 'Ì': 136,\n",
       " 'Í': 137,\n",
       " 'Î': 138,\n",
       " 'Ï': 139,\n",
       " 'Ð': 140,\n",
       " 'Ñ': 141,\n",
       " 'Ò': 142,\n",
       " 'Ó': 143,\n",
       " 'Ô': 144,\n",
       " 'Õ': 145,\n",
       " 'Ö': 146,\n",
       " '×': 147,\n",
       " 'Ø': 148,\n",
       " 'Ù': 149,\n",
       " 'Ú': 150,\n",
       " 'Û': 151,\n",
       " 'Ü': 152,\n",
       " 'Ý': 153,\n",
       " 'Þ': 154,\n",
       " 'ß': 155,\n",
       " 'à': 156,\n",
       " 'á': 157,\n",
       " 'â': 158,\n",
       " 'ã': 159,\n",
       " 'ä': 160,\n",
       " 'å': 161,\n",
       " 'æ': 162,\n",
       " 'ç': 163,\n",
       " 'è': 164,\n",
       " 'é': 165,\n",
       " 'ê': 166,\n",
       " 'ë': 167,\n",
       " 'ì': 168,\n",
       " 'í': 169,\n",
       " 'î': 170,\n",
       " 'ï': 171,\n",
       " 'ð': 172,\n",
       " 'ñ': 173,\n",
       " 'ò': 174,\n",
       " 'ó': 175,\n",
       " 'ô': 176,\n",
       " 'õ': 177,\n",
       " 'ö': 178,\n",
       " '÷': 179,\n",
       " 'ø': 180,\n",
       " 'ù': 181,\n",
       " 'ú': 182,\n",
       " 'û': 183,\n",
       " 'ü': 184,\n",
       " 'ý': 185,\n",
       " 'þ': 186,\n",
       " 'ÿ': 187,\n",
       " 'Ā': 188,\n",
       " 'ā': 189,\n",
       " 'Ă': 190,\n",
       " 'ă': 191,\n",
       " 'Ą': 192,\n",
       " 'ą': 193,\n",
       " 'Ć': 194,\n",
       " 'ć': 195,\n",
       " 'Ĉ': 196,\n",
       " 'ĉ': 197,\n",
       " 'Ċ': 198,\n",
       " 'ċ': 199,\n",
       " 'Č': 200,\n",
       " 'č': 201,\n",
       " 'Ď': 202,\n",
       " 'ď': 203,\n",
       " 'Đ': 204,\n",
       " 'đ': 205,\n",
       " 'Ē': 206,\n",
       " 'ē': 207,\n",
       " 'Ĕ': 208,\n",
       " 'ĕ': 209,\n",
       " 'Ė': 210,\n",
       " 'ė': 211,\n",
       " 'Ę': 212,\n",
       " 'ę': 213,\n",
       " 'Ě': 214,\n",
       " 'ě': 215,\n",
       " 'Ĝ': 216,\n",
       " 'ĝ': 217,\n",
       " 'Ğ': 218,\n",
       " 'ğ': 219,\n",
       " 'Ġ': 220,\n",
       " 'ġ': 221,\n",
       " 'Ģ': 222,\n",
       " 'ģ': 223,\n",
       " 'Ĥ': 224,\n",
       " 'ĥ': 225,\n",
       " 'Ħ': 226,\n",
       " 'ħ': 227,\n",
       " 'Ĩ': 228,\n",
       " 'ĩ': 229,\n",
       " 'Ī': 230,\n",
       " 'ī': 231,\n",
       " 'Ĭ': 232,\n",
       " 'ĭ': 233,\n",
       " 'Į': 234,\n",
       " 'į': 235,\n",
       " 'İ': 236,\n",
       " 'ı': 237,\n",
       " 'Ĳ': 238,\n",
       " 'ĳ': 239,\n",
       " 'Ĵ': 240,\n",
       " 'ĵ': 241,\n",
       " 'Ķ': 242,\n",
       " 'ķ': 243,\n",
       " 'ĸ': 244,\n",
       " 'Ĺ': 245,\n",
       " 'ĺ': 246,\n",
       " 'Ļ': 247,\n",
       " 'ļ': 248,\n",
       " 'Ľ': 249,\n",
       " 'ľ': 250,\n",
       " 'Ŀ': 251,\n",
       " 'ŀ': 252,\n",
       " 'Ł': 253,\n",
       " 'ł': 254,\n",
       " 'Ń': 255,\n",
       " 'Ġt': 256,\n",
       " 'Ġa': 257,\n",
       " 'he': 258,\n",
       " 'in': 259,\n",
       " 're': 260,\n",
       " 'on': 261,\n",
       " 'Ġthe': 262,\n",
       " 'er': 263,\n",
       " 'Ġs': 264,\n",
       " 'at': 265,\n",
       " 'Ġw': 266,\n",
       " 'Ġo': 267,\n",
       " 'en': 268,\n",
       " 'Ġc': 269,\n",
       " 'it': 270,\n",
       " 'is': 271,\n",
       " 'an': 272,\n",
       " 'or': 273,\n",
       " 'es': 274,\n",
       " 'Ġb': 275,\n",
       " 'ed': 276,\n",
       " 'Ġf': 277,\n",
       " 'ing': 278,\n",
       " 'Ġp': 279,\n",
       " 'ou': 280,\n",
       " 'Ġan': 281,\n",
       " 'al': 282,\n",
       " 'ar': 283,\n",
       " 'Ġto': 284,\n",
       " 'Ġm': 285,\n",
       " 'Ġof': 286,\n",
       " 'Ġin': 287,\n",
       " 'Ġd': 288,\n",
       " 'Ġh': 289,\n",
       " 'Ġand': 290,\n",
       " 'ic': 291,\n",
       " 'as': 292,\n",
       " 'le': 293,\n",
       " 'Ġth': 294,\n",
       " 'ion': 295,\n",
       " 'om': 296,\n",
       " 'll': 297,\n",
       " 'ent': 298,\n",
       " 'Ġn': 299,\n",
       " 'Ġl': 300,\n",
       " 'st': 301,\n",
       " 'Ġre': 302,\n",
       " 've': 303,\n",
       " 'Ġe': 304,\n",
       " 'ro': 305,\n",
       " 'ly': 306,\n",
       " 'Ġbe': 307,\n",
       " 'Ġg': 308,\n",
       " 'ĠT': 309,\n",
       " 'ct': 310,\n",
       " 'ĠS': 311,\n",
       " 'id': 312,\n",
       " 'ot': 313,\n",
       " 'ĠI': 314,\n",
       " 'ut': 315,\n",
       " 'et': 316,\n",
       " 'ĠA': 317,\n",
       " 'Ġis': 318,\n",
       " 'Ġon': 319,\n",
       " 'im': 320,\n",
       " 'am': 321,\n",
       " 'ow': 322,\n",
       " 'ay': 323,\n",
       " 'ad': 324,\n",
       " 'se': 325,\n",
       " 'Ġthat': 326,\n",
       " 'ĠC': 327,\n",
       " 'ig': 328,\n",
       " 'Ġfor': 329,\n",
       " 'ac': 330,\n",
       " 'Ġy': 331,\n",
       " 'ver': 332,\n",
       " 'ur': 333,\n",
       " 'Ġu': 334,\n",
       " 'ld': 335,\n",
       " 'Ġst': 336,\n",
       " 'ĠM': 337,\n",
       " \"'s\": 338,\n",
       " 'Ġhe': 339,\n",
       " 'Ġit': 340,\n",
       " 'ation': 341,\n",
       " 'ith': 342,\n",
       " 'ir': 343,\n",
       " 'ce': 344,\n",
       " 'Ġyou': 345,\n",
       " 'il': 346,\n",
       " 'ĠB': 347,\n",
       " 'Ġwh': 348,\n",
       " 'ol': 349,\n",
       " 'ĠP': 350,\n",
       " 'Ġwith': 351,\n",
       " 'Ġ1': 352,\n",
       " 'ter': 353,\n",
       " 'ch': 354,\n",
       " 'Ġas': 355,\n",
       " 'Ġwe': 356,\n",
       " 'Ġ(': 357,\n",
       " 'nd': 358,\n",
       " 'ill': 359,\n",
       " 'ĠD': 360,\n",
       " 'if': 361,\n",
       " 'Ġ2': 362,\n",
       " 'ag': 363,\n",
       " 'ers': 364,\n",
       " 'ke': 365,\n",
       " 'Ġ\"': 366,\n",
       " 'ĠH': 367,\n",
       " 'em': 368,\n",
       " 'Ġcon': 369,\n",
       " 'ĠW': 370,\n",
       " 'ĠR': 371,\n",
       " 'her': 372,\n",
       " 'Ġwas': 373,\n",
       " 'Ġr': 374,\n",
       " 'od': 375,\n",
       " 'ĠF': 376,\n",
       " 'ul': 377,\n",
       " 'ate': 378,\n",
       " 'Ġat': 379,\n",
       " 'ri': 380,\n",
       " 'pp': 381,\n",
       " 'ore': 382,\n",
       " 'ĠThe': 383,\n",
       " 'Ġse': 384,\n",
       " 'us': 385,\n",
       " 'Ġpro': 386,\n",
       " 'Ġha': 387,\n",
       " 'um': 388,\n",
       " 'Ġare': 389,\n",
       " 'Ġde': 390,\n",
       " 'ain': 391,\n",
       " 'and': 392,\n",
       " 'Ġor': 393,\n",
       " 'igh': 394,\n",
       " 'est': 395,\n",
       " 'ist': 396,\n",
       " 'ab': 397,\n",
       " 'rom': 398,\n",
       " 'ĠN': 399,\n",
       " 'th': 400,\n",
       " 'Ġcom': 401,\n",
       " 'ĠG': 402,\n",
       " 'un': 403,\n",
       " 'op': 404,\n",
       " '00': 405,\n",
       " 'ĠL': 406,\n",
       " 'Ġnot': 407,\n",
       " 'ess': 408,\n",
       " 'Ġex': 409,\n",
       " 'Ġv': 410,\n",
       " 'res': 411,\n",
       " 'ĠE': 412,\n",
       " 'ew': 413,\n",
       " 'ity': 414,\n",
       " 'ant': 415,\n",
       " 'Ġby': 416,\n",
       " 'el': 417,\n",
       " 'os': 418,\n",
       " 'ort': 419,\n",
       " 'oc': 420,\n",
       " 'qu': 421,\n",
       " 'Ġfrom': 422,\n",
       " 'Ġhave': 423,\n",
       " 'Ġsu': 424,\n",
       " 'ive': 425,\n",
       " 'ould': 426,\n",
       " 'Ġsh': 427,\n",
       " 'Ġthis': 428,\n",
       " 'nt': 429,\n",
       " 'ra': 430,\n",
       " 'pe': 431,\n",
       " 'ight': 432,\n",
       " 'art': 433,\n",
       " 'ment': 434,\n",
       " 'Ġal': 435,\n",
       " 'ust': 436,\n",
       " 'end': 437,\n",
       " '--': 438,\n",
       " 'all': 439,\n",
       " 'ĠO': 440,\n",
       " 'ack': 441,\n",
       " 'Ġch': 442,\n",
       " 'Ġle': 443,\n",
       " 'ies': 444,\n",
       " 'red': 445,\n",
       " 'ard': 446,\n",
       " 'âĢ': 447,\n",
       " 'out': 448,\n",
       " 'ĠJ': 449,\n",
       " 'Ġab': 450,\n",
       " 'ear': 451,\n",
       " 'iv': 452,\n",
       " 'ally': 453,\n",
       " 'our': 454,\n",
       " 'ost': 455,\n",
       " 'gh': 456,\n",
       " 'pt': 457,\n",
       " 'Ġpl': 458,\n",
       " 'ast': 459,\n",
       " 'Ġcan': 460,\n",
       " 'ak': 461,\n",
       " 'ome': 462,\n",
       " 'ud': 463,\n",
       " 'The': 464,\n",
       " 'Ġhis': 465,\n",
       " 'Ġdo': 466,\n",
       " 'Ġgo': 467,\n",
       " 'Ġhas': 468,\n",
       " 'ge': 469,\n",
       " \"'t\": 470,\n",
       " 'ĠU': 471,\n",
       " 'rou': 472,\n",
       " 'Ġsa': 473,\n",
       " 'Ġj': 474,\n",
       " 'Ġbut': 475,\n",
       " 'Ġwor': 476,\n",
       " 'Ġall': 477,\n",
       " 'ect': 478,\n",
       " 'Ġk': 479,\n",
       " 'ame': 480,\n",
       " 'Ġwill': 481,\n",
       " 'ok': 482,\n",
       " 'Ġwhe': 483,\n",
       " 'Ġthey': 484,\n",
       " 'ide': 485,\n",
       " '01': 486,\n",
       " 'ff': 487,\n",
       " 'ich': 488,\n",
       " 'pl': 489,\n",
       " 'ther': 490,\n",
       " 'Ġtr': 491,\n",
       " '..': 492,\n",
       " 'Ġint': 493,\n",
       " 'ie': 494,\n",
       " 'ure': 495,\n",
       " 'age': 496,\n",
       " 'Ġne': 497,\n",
       " 'ial': 498,\n",
       " 'ap': 499,\n",
       " 'ine': 500,\n",
       " 'ice': 501,\n",
       " 'Ġme': 502,\n",
       " 'Ġout': 503,\n",
       " 'ans': 504,\n",
       " 'one': 505,\n",
       " 'ong': 506,\n",
       " 'ions': 507,\n",
       " 'Ġwho': 508,\n",
       " 'ĠK': 509,\n",
       " 'Ġup': 510,\n",
       " 'Ġtheir': 511,\n",
       " 'Ġad': 512,\n",
       " 'Ġ3': 513,\n",
       " 'Ġus': 514,\n",
       " 'ated': 515,\n",
       " 'ous': 516,\n",
       " 'Ġmore': 517,\n",
       " 'ue': 518,\n",
       " 'og': 519,\n",
       " 'ĠSt': 520,\n",
       " 'ind': 521,\n",
       " 'ike': 522,\n",
       " 'Ġso': 523,\n",
       " 'ime': 524,\n",
       " 'per': 525,\n",
       " '.\"': 526,\n",
       " 'ber': 527,\n",
       " 'iz': 528,\n",
       " 'act': 529,\n",
       " 'Ġone': 530,\n",
       " 'Ġsaid': 531,\n",
       " 'Ġ-': 532,\n",
       " 'are': 533,\n",
       " 'Ġyour': 534,\n",
       " 'cc': 535,\n",
       " 'ĠTh': 536,\n",
       " 'Ġcl': 537,\n",
       " 'ep': 538,\n",
       " 'ake': 539,\n",
       " 'able': 540,\n",
       " 'ip': 541,\n",
       " 'Ġcont': 542,\n",
       " 'Ġwhich': 543,\n",
       " 'ia': 544,\n",
       " 'Ġim': 545,\n",
       " 'Ġabout': 546,\n",
       " 'Ġwere': 547,\n",
       " 'very': 548,\n",
       " 'ub': 549,\n",
       " 'Ġhad': 550,\n",
       " 'Ġen': 551,\n",
       " 'Ġcomp': 552,\n",
       " ',\"': 553,\n",
       " 'ĠIn': 554,\n",
       " 'Ġun': 555,\n",
       " 'Ġag': 556,\n",
       " 'ire': 557,\n",
       " 'ace': 558,\n",
       " 'au': 559,\n",
       " 'ary': 560,\n",
       " 'Ġwould': 561,\n",
       " 'ass': 562,\n",
       " 'ry': 563,\n",
       " 'ĠâĢ': 564,\n",
       " 'cl': 565,\n",
       " 'ook': 566,\n",
       " 'ere': 567,\n",
       " 'so': 568,\n",
       " 'ĠV': 569,\n",
       " 'ign': 570,\n",
       " 'ib': 571,\n",
       " 'Ġoff': 572,\n",
       " 'Ġte': 573,\n",
       " 'ven': 574,\n",
       " 'ĠY': 575,\n",
       " 'ile': 576,\n",
       " 'ose': 577,\n",
       " 'ite': 578,\n",
       " 'orm': 579,\n",
       " 'Ġ201': 580,\n",
       " 'Ġres': 581,\n",
       " 'Ġman': 582,\n",
       " 'Ġper': 583,\n",
       " 'Ġother': 584,\n",
       " 'ord': 585,\n",
       " 'ult': 586,\n",
       " 'Ġbeen': 587,\n",
       " 'Ġlike': 588,\n",
       " 'ase': 589,\n",
       " 'ance': 590,\n",
       " 'ks': 591,\n",
       " 'ays': 592,\n",
       " 'own': 593,\n",
       " 'ence': 594,\n",
       " 'Ġdis': 595,\n",
       " 'ction': 596,\n",
       " 'Ġany': 597,\n",
       " 'Ġapp': 598,\n",
       " 'Ġsp': 599,\n",
       " 'int': 600,\n",
       " 'ress': 601,\n",
       " 'ations': 602,\n",
       " 'ail': 603,\n",
       " 'Ġ4': 604,\n",
       " 'ical': 605,\n",
       " 'Ġthem': 606,\n",
       " 'Ġher': 607,\n",
       " 'ount': 608,\n",
       " 'ĠCh': 609,\n",
       " 'Ġar': 610,\n",
       " 'Ġif': 611,\n",
       " 'Ġthere': 612,\n",
       " 'Ġpe': 613,\n",
       " 'Ġyear': 614,\n",
       " 'av': 615,\n",
       " 'Ġmy': 616,\n",
       " 'Ġsome': 617,\n",
       " 'Ġwhen': 618,\n",
       " 'ough': 619,\n",
       " 'ach': 620,\n",
       " 'Ġthan': 621,\n",
       " 'ru': 622,\n",
       " 'ond': 623,\n",
       " 'ick': 624,\n",
       " 'Ġover': 625,\n",
       " 'vel': 626,\n",
       " 'Ġqu': 627,\n",
       " 'ĊĊ': 628,\n",
       " 'Ġsc': 629,\n",
       " 'reat': 630,\n",
       " 'ree': 631,\n",
       " 'ĠIt': 632,\n",
       " 'ound': 633,\n",
       " 'port': 634,\n",
       " 'Ġalso': 635,\n",
       " 'Ġpart': 636,\n",
       " 'fter': 637,\n",
       " 'Ġkn': 638,\n",
       " 'Ġbec': 639,\n",
       " 'Ġtime': 640,\n",
       " 'ens': 641,\n",
       " 'Ġ5': 642,\n",
       " 'ople': 643,\n",
       " 'Ġwhat': 644,\n",
       " 'Ġno': 645,\n",
       " 'du': 646,\n",
       " 'mer': 647,\n",
       " 'ang': 648,\n",
       " 'Ġnew': 649,\n",
       " '----': 650,\n",
       " 'Ġget': 651,\n",
       " 'ory': 652,\n",
       " 'ition': 653,\n",
       " 'ings': 654,\n",
       " 'Ġjust': 655,\n",
       " 'Ġinto': 656,\n",
       " 'Ġ0': 657,\n",
       " 'ents': 658,\n",
       " 'ove': 659,\n",
       " 'te': 660,\n",
       " 'Ġpeople': 661,\n",
       " 'Ġpre': 662,\n",
       " 'Ġits': 663,\n",
       " 'Ġrec': 664,\n",
       " 'Ġtw': 665,\n",
       " 'ian': 666,\n",
       " 'irst': 667,\n",
       " 'ark': 668,\n",
       " 'ors': 669,\n",
       " 'Ġwork': 670,\n",
       " 'ade': 671,\n",
       " 'ob': 672,\n",
       " 'Ġshe': 673,\n",
       " 'Ġour': 674,\n",
       " 'wn': 675,\n",
       " 'ink': 676,\n",
       " 'lic': 677,\n",
       " 'Ġ19': 678,\n",
       " 'ĠHe': 679,\n",
       " 'ish': 680,\n",
       " 'nder': 681,\n",
       " 'ause': 682,\n",
       " 'Ġhim': 683,\n",
       " 'ons': 684,\n",
       " 'Ġ[': 685,\n",
       " 'Ġro': 686,\n",
       " 'form': 687,\n",
       " 'ild': 688,\n",
       " 'ates': 689,\n",
       " 'vers': 690,\n",
       " 'Ġonly': 691,\n",
       " 'oll': 692,\n",
       " 'Ġspe': 693,\n",
       " 'ck': 694,\n",
       " 'ell': 695,\n",
       " 'amp': 696,\n",
       " 'Ġacc': 697,\n",
       " 'Ġbl': 698,\n",
       " 'ious': 699,\n",
       " 'urn': 700,\n",
       " 'ft': 701,\n",
       " 'ood': 702,\n",
       " 'Ġhow': 703,\n",
       " 'hed': 704,\n",
       " \"Ġ'\": 705,\n",
       " 'Ġafter': 706,\n",
       " 'aw': 707,\n",
       " 'Ġatt': 708,\n",
       " 'ov': 709,\n",
       " 'ne': 710,\n",
       " 'Ġplay': 711,\n",
       " 'erv': 712,\n",
       " 'ict': 713,\n",
       " 'Ġcould': 714,\n",
       " 'itt': 715,\n",
       " 'Ġam': 716,\n",
       " 'Ġfirst': 717,\n",
       " 'Ġ6': 718,\n",
       " 'Ġact': 719,\n",
       " 'Ġ$': 720,\n",
       " 'ec': 721,\n",
       " 'hing': 722,\n",
       " 'ual': 723,\n",
       " 'ull': 724,\n",
       " 'Ġcomm': 725,\n",
       " 'oy': 726,\n",
       " 'old': 727,\n",
       " 'ces': 728,\n",
       " 'ater': 729,\n",
       " 'Ġfe': 730,\n",
       " 'Ġbet': 731,\n",
       " 'we': 732,\n",
       " 'iff': 733,\n",
       " 'Ġtwo': 734,\n",
       " 'ock': 735,\n",
       " 'Ġback': 736,\n",
       " ').': 737,\n",
       " 'ident': 738,\n",
       " 'Ġunder': 739,\n",
       " 'rough': 740,\n",
       " 'sel': 741,\n",
       " 'xt': 742,\n",
       " 'Ġmay': 743,\n",
       " 'round': 744,\n",
       " 'Ġpo': 745,\n",
       " 'ph': 746,\n",
       " 'iss': 747,\n",
       " 'Ġdes': 748,\n",
       " 'Ġmost': 749,\n",
       " 'Ġdid': 750,\n",
       " 'Ġadd': 751,\n",
       " 'ject': 752,\n",
       " 'Ġinc': 753,\n",
       " 'fore': 754,\n",
       " 'Ġpol': 755,\n",
       " 'ont': 756,\n",
       " 'Ġagain': 757,\n",
       " 'clud': 758,\n",
       " 'tern': 759,\n",
       " 'Ġknow': 760,\n",
       " 'Ġneed': 761,\n",
       " 'Ġcons': 762,\n",
       " 'Ġco': 763,\n",
       " 'Ġ.': 764,\n",
       " 'Ġwant': 765,\n",
       " 'Ġsee': 766,\n",
       " 'Ġ7': 767,\n",
       " 'ning': 768,\n",
       " 'iew': 769,\n",
       " 'ĠThis': 770,\n",
       " 'ced': 771,\n",
       " 'Ġeven': 772,\n",
       " 'Ġind': 773,\n",
       " 'ty': 774,\n",
       " 'ĠWe': 775,\n",
       " 'ath': 776,\n",
       " 'Ġthese': 777,\n",
       " 'Ġpr': 778,\n",
       " 'Ġuse': 779,\n",
       " 'Ġbecause': 780,\n",
       " 'Ġfl': 781,\n",
       " 'ng': 782,\n",
       " 'Ġnow': 783,\n",
       " 'ĠâĢĵ': 784,\n",
       " 'com': 785,\n",
       " 'ise': 786,\n",
       " 'Ġmake': 787,\n",
       " 'Ġthen': 788,\n",
       " 'ower': 789,\n",
       " 'Ġevery': 790,\n",
       " 'ĠUn': 791,\n",
       " 'Ġsec': 792,\n",
       " 'oss': 793,\n",
       " 'uch': 794,\n",
       " 'Ġem': 795,\n",
       " 'Ġ=': 796,\n",
       " 'ĠRe': 797,\n",
       " 'ied': 798,\n",
       " 'rit': 799,\n",
       " 'Ġinv': 800,\n",
       " 'lect': 801,\n",
       " 'Ġsupp': 802,\n",
       " 'ating': 803,\n",
       " 'Ġlook': 804,\n",
       " 'man': 805,\n",
       " 'pect': 806,\n",
       " 'Ġ8': 807,\n",
       " 'row': 808,\n",
       " 'Ġbu': 809,\n",
       " 'Ġwhere': 810,\n",
       " 'ific': 811,\n",
       " 'Ġyears': 812,\n",
       " 'ily': 813,\n",
       " 'Ġdiff': 814,\n",
       " 'Ġshould': 815,\n",
       " 'Ġrem': 816,\n",
       " 'Th': 817,\n",
       " 'In': 818,\n",
       " 'Ġev': 819,\n",
       " 'day': 820,\n",
       " \"'re\": 821,\n",
       " 'rib': 822,\n",
       " 'Ġrel': 823,\n",
       " 'ss': 824,\n",
       " 'Ġdef': 825,\n",
       " 'Ġright': 826,\n",
       " 'Ġsy': 827,\n",
       " '),': 828,\n",
       " 'les': 829,\n",
       " '000': 830,\n",
       " 'hen': 831,\n",
       " 'Ġthrough': 832,\n",
       " 'ĠTr': 833,\n",
       " '__': 834,\n",
       " 'Ġway': 835,\n",
       " 'Ġdon': 836,\n",
       " 'Ġ,': 837,\n",
       " 'Ġ10': 838,\n",
       " 'ased': 839,\n",
       " 'Ġass': 840,\n",
       " 'ublic': 841,\n",
       " 'Ġreg': 842,\n",
       " 'ĠAnd': 843,\n",
       " 'ix': 844,\n",
       " 'Ġvery': 845,\n",
       " 'Ġinclud': 846,\n",
       " 'other': 847,\n",
       " 'Ġimp': 848,\n",
       " 'oth': 849,\n",
       " 'Ġsub': 850,\n",
       " 'ĠâĢĶ': 851,\n",
       " 'Ġbeing': 852,\n",
       " 'arg': 853,\n",
       " 'ĠWh': 854,\n",
       " '==': 855,\n",
       " 'ible': 856,\n",
       " 'Ġdoes': 857,\n",
       " 'ange': 858,\n",
       " 'ram': 859,\n",
       " 'Ġ9': 860,\n",
       " 'ert': 861,\n",
       " 'ps': 862,\n",
       " 'ited': 863,\n",
       " 'ational': 864,\n",
       " 'Ġbr': 865,\n",
       " 'Ġdown': 866,\n",
       " 'Ġmany': 867,\n",
       " 'aking': 868,\n",
       " 'Ġcall': 869,\n",
       " 'uring': 870,\n",
       " 'ities': 871,\n",
       " 'Ġph': 872,\n",
       " 'ics': 873,\n",
       " 'als': 874,\n",
       " 'Ġdec': 875,\n",
       " 'ative': 876,\n",
       " 'ener': 877,\n",
       " 'Ġbefore': 878,\n",
       " 'ility': 879,\n",
       " 'Ġwell': 880,\n",
       " 'Ġmuch': 881,\n",
       " 'erson': 882,\n",
       " 'Ġthose': 883,\n",
       " 'Ġsuch': 884,\n",
       " 'Ġke': 885,\n",
       " 'Ġend': 886,\n",
       " 'ĠBut': 887,\n",
       " 'ason': 888,\n",
       " 'ting': 889,\n",
       " 'Ġlong': 890,\n",
       " 'ef': 891,\n",
       " 'Ġthink': 892,\n",
       " 'ys': 893,\n",
       " 'Ġbel': 894,\n",
       " 'Ġsm': 895,\n",
       " 'its': 896,\n",
       " 'ax': 897,\n",
       " 'Ġown': 898,\n",
       " 'Ġprov': 899,\n",
       " 'Ġset': 900,\n",
       " 'ife': 901,\n",
       " 'ments': 902,\n",
       " 'ble': 903,\n",
       " 'ward': 904,\n",
       " 'Ġshow': 905,\n",
       " 'Ġpres': 906,\n",
       " 'ms': 907,\n",
       " 'omet': 908,\n",
       " 'Ġob': 909,\n",
       " 'Ġsay': 910,\n",
       " 'ĠSh': 911,\n",
       " 'ts': 912,\n",
       " 'ful': 913,\n",
       " 'Ġeff': 914,\n",
       " 'Ġgu': 915,\n",
       " 'Ġinst': 916,\n",
       " 'und': 917,\n",
       " 'ren': 918,\n",
       " 'cess': 919,\n",
       " 'Ġent': 920,\n",
       " 'ĠYou': 921,\n",
       " 'Ġgood': 922,\n",
       " 'Ġstart': 923,\n",
       " 'ince': 924,\n",
       " 'Ġmade': 925,\n",
       " 'tt': 926,\n",
       " 'stem': 927,\n",
       " 'olog': 928,\n",
       " 'up': 929,\n",
       " 'Ġ|': 930,\n",
       " 'ump': 931,\n",
       " 'Ġhel': 932,\n",
       " 'vern': 933,\n",
       " 'ular': 934,\n",
       " 'ually': 935,\n",
       " 'Ġac': 936,\n",
       " 'Ġmon': 937,\n",
       " 'Ġlast': 938,\n",
       " 'Ġ200': 939,\n",
       " '10': 940,\n",
       " 'Ġstud': 941,\n",
       " 'ures': 942,\n",
       " 'ĠAr': 943,\n",
       " 'self': 944,\n",
       " 'ars': 945,\n",
       " 'meric': 946,\n",
       " 'ues': 947,\n",
       " 'cy': 948,\n",
       " 'Ġmin': 949,\n",
       " 'ollow': 950,\n",
       " 'Ġcol': 951,\n",
       " 'io': 952,\n",
       " 'Ġmod': 953,\n",
       " 'Ġcount': 954,\n",
       " 'ĠCom': 955,\n",
       " 'hes': 956,\n",
       " 'Ġfin': 957,\n",
       " 'air': 958,\n",
       " 'ier': 959,\n",
       " 'âĢĶ': 960,\n",
       " 'read': 961,\n",
       " 'ank': 962,\n",
       " 'atch': 963,\n",
       " 'ever': 964,\n",
       " 'Ġstr': 965,\n",
       " 'Ġpoint': 966,\n",
       " 'ork': 967,\n",
       " 'ĠNew': 968,\n",
       " 'Ġsur': 969,\n",
       " 'ool': 970,\n",
       " 'alk': 971,\n",
       " 'ement': 972,\n",
       " 'Ġused': 973,\n",
       " 'ract': 974,\n",
       " 'ween': 975,\n",
       " 'Ġsame': 976,\n",
       " 'oun': 977,\n",
       " 'ĠAl': 978,\n",
       " 'ci': 979,\n",
       " 'Ġdiffere': 980,\n",
       " 'Ġwhile': 981,\n",
       " '--------': 982,\n",
       " 'Ġgame': 983,\n",
       " 'cept': 984,\n",
       " 'Ġsim': 985,\n",
       " '...': 986,\n",
       " 'Ġinter': 987,\n",
       " 'ek': 988,\n",
       " 'Ġreport': 989,\n",
       " 'Ġprodu': 990,\n",
       " 'Ġstill': 991,\n",
       " 'led': 992,\n",
       " 'ah': 993,\n",
       " 'Ġhere': 994,\n",
       " 'Ġworld': 995,\n",
       " 'Ġthough': 996,\n",
       " 'Ġnum': 997,\n",
       " 'arch': 998,\n",
       " 'imes': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.get_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50257"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.get_vocab())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"def get_mean_probs(df: pd.DataFrame, model: Model, n: Optional[int] = None): \\\n",
    "    \"\"\" \\\n",
    "    \"Get the mean probability of each token that the model\" \\\n",
    "    \"should predict for an entire pandas dataframe.\"\\\n",
    "    \"if n is None:\" \\\n",
    "        \"n = len(df)\" \\\n",
    "    \"# setup container lists for the number of occurrences and sum of probabilities for each token\" \\\n",
    "    \"counts = [0] * model.tokenizer.get_vocab_size()\" \\\n",
    "    \"sum_probs = [0.0] * model.tokenizer.get_vocab_size()\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.models.gpt_neo.modeling_gpt_neo.GPTNeoForCausalLM"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 123])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Output is the class CausalLMOutputWithPast (https://huggingface.co/transformers/v4.10.1/main_classes/output.html?highlight=causallmoutputwithpast)\n",
    "#logits (torch.FloatTensor of shape (batch_size, sequence_length, config.vocab_size)) – Prediction scores of the language modeling head (scores for each vocabulary token before SoftMax).\n",
    "output = model(input_ids=input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 123, 50257])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ -4.7163,  -4.1678,  -8.0573,  ..., -14.3003, -12.5503, -10.1957],\n",
       "         [ -9.1358,  -7.5095,  -9.0157,  ..., -19.7905, -16.6783, -11.4492],\n",
       "         [-10.6732,  -8.5573,  -7.7642,  ..., -15.8004, -16.4903, -12.3207],\n",
       "         ...,\n",
       "         [-16.9420, -15.7932, -14.1912,  ..., -23.7035, -22.8659, -20.2982],\n",
       "         [-15.1844, -11.9999,  -7.8559,  ..., -24.4472, -20.0692, -12.8104],\n",
       "         [-11.7155,  -9.0382,  -1.4850,  ..., -20.0199, -16.5161,  -8.2457]]],\n",
       "       grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Based on the response here: https://stackoverflow.com/questions/62852940/how-to-get-immediate-next-word-probability-using-gpt2-model\n",
    "next_token_logits = output[0][:, -1, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-11.7155,  -9.0382,  -1.4850,  ..., -20.0199, -16.5161,  -8.2457]],\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_token_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 50257])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_token_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-881254.1875, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(next_token_logits[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "soft = torch.nn.Softmax(dim=1)\n",
    "next_token_distribution = soft(next_token_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 50257])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_token_distribution.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9999, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(next_token_distribution[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "gen_tokens = model.generate(input_ids, do_sample=True, temperature=0.9, max_length=200,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4299,   651,    62, 32604,    62,  1676,  1443,     7,  7568,    25,\n",
       "           279,    67,    13,  6601, 19778,    11,  2746,    25,  9104,    11,\n",
       "           299,    25, 32233,    58,   600,    60,   796,  6045,  2599,   220,\n",
       "           220,   220,   220,  3497,   262,  1612, 12867,   286,  1123, 11241,\n",
       "           326,   262,  4981,    71,   426,  4331,   329,   281,  2104, 19798,\n",
       "           292,  1366, 14535,    13,   361,   299,   318,  6045,    25,    77,\n",
       "           796, 18896,     7,  7568,     8,     2,  9058,  9290,  8341,   329,\n",
       "           262,  1271,   286, 40279,   290,  2160,   286, 39522,   329,  1123,\n",
       "         11241,  9127,    82,   796,   685,    15,    60,  1635,  2746,    13,\n",
       "         30001,  7509,    13,  1136,    62, 18893,   397,    62,  7857,  3419,\n",
       "         16345,    62,  1676,  1443,   796,   685,    15,    13,    15,    60,\n",
       "          1635,  2746,    13, 30001,  7509,    13,  1136,    62, 18893,   397,\n",
       "            62,  7857,  3419,  7783,   954,    82,  1343,  2160,    62,  1676,\n",
       "          1443,     2,   954,   262,  1271,   286,  2746, 16277,   611,  2622,\n",
       "           198,   198,  4299,   651,    62, 19849,    62,  1676,  1443,     7,\n",
       "          7568,    25,   279,    67,    13,  6601, 19778,    11,  2746,    25,\n",
       "          9104,  2599,   651,    62, 19849,    62,  1676,  1443,    62,  9127,\n",
       "            82,    11,   651,    62, 32604,    62,  1676,  1443,   796,   651,\n",
       "            62,  1326,   504,    11,   651,    62,  1326,   504,    62,  1676,\n",
       "          1443,     7, 19849,     8,   198,   198,     2,  1382,   262,  1612]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_text = tokenizer.batch_decode(gen_tokens)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def get_mean_probs(df: pd.DataFrame, model: Model, n: Optional[int] = None):     Get the mean probability of each token that the modelshould predict for an entire pandas dataframe.if n is None:n = len(df)# setup container lists for the number of occurrences and sum of probabilities for each tokencounts = [0] * model.tokenizer.get_vocab_size()sum_probs = [0.0] * model.tokenizer.get_vocab_size()return counts + sum_probs# count the number of model predictions if needed\\n\\ndef get_model_probs(df: pd.DataFrame, model: Model): get_model_probs_counts, get_mean_probs = get_means, get_means_probs(model)\\n\\n# build the mean'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
